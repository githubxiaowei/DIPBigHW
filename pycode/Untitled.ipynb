{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGINFO = 1\n",
    "def log_info(*args):\n",
    "    if LOGINFO:\n",
    "        for i in args:\n",
    "            print(i,end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def input_data(npz=True):\n",
    "    if npz:\n",
    "        bird_data = np.load('bird_data.npz')\n",
    "        return bird_data['train_img'],bird_data['test_img'],bird_data['train_label'],bird_data['test_label']\n",
    "    else:      \n",
    "        data_path = os.path.join('..','data','CUB_200_2011')\n",
    "        log_info(os.listdir(data_path))\n",
    "\n",
    "        train_test_split_file = os.path.join(data_path,'train_test_split.txt')\n",
    "        with open(train_test_split_file,'r') as file:\n",
    "            train_test_split = np.array([i.split()[1] for i in file.readlines()]).astype('bool')\n",
    "        log_info(train_test_split,train_test_split.size)\n",
    "\n",
    "        img_paths_file = os.path.join(data_path,'images.txt')\n",
    "        with open(img_paths_file,'r') as file:\n",
    "            img_paths = [i.split()[1] for i in file.readlines()]\n",
    "        log_info(img_paths[:1],len(img_paths))\n",
    "\n",
    "        img_labels_file = os.path.join(data_path,'image_class_labels.txt')\n",
    "        with open(img_labels_file,'r') as file:\n",
    "            img_labels = np.array([i.split()[1] for i in file.readlines()]).astype('int')\n",
    "        log_info(img_labels,len(img_labels))\n",
    "\n",
    "        img_dir = os.path.join(data_path,'images')\n",
    "\n",
    "        img_paths_train = [os.path.join(img_dir,os.path.sep.join(path.split('/'))) for i,path in enumerate(img_paths) if train_test_split[i]]\n",
    "        log_info(img_paths_train[:1],len(img_paths_train))\n",
    "        img_paths_test = [os.path.join(img_dir,os.path.sep.join(path.split('/'))) for i,path in enumerate(img_paths) if not train_test_split[i]]\n",
    "        log_info(img_paths_test[:1],len(img_paths_test))\n",
    "\n",
    "        train_img = np.array([cv2.resize(cv2.imread(i),(64,64)) for i in img_paths_train])\n",
    "        test_img = np.array([cv2.resize(cv2.imread(i),(64,64)) for i in img_paths_test])\n",
    "        train_label = np.array([l for i,l in enumerate(img_labels) if train_test_split[i] ])\n",
    "        test_label = np.array([l for i,l in enumerate(img_labels) if not train_test_split[i]])\n",
    "        log_info(train_label,train_label.size)\n",
    "        log_info(test_label,test_label.size)\n",
    "\n",
    "        np.savez('bird_data',train_img=train_img,test_img=test_img,train_label=train_label,test_label=test_label)\n",
    "        return train_img,test_img,train_label,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'numpy.ndarray'> <class 'numpy.ndarray'> \n",
      "shape: (5994, 64, 64, 3) (5994,) \n",
      "size: 73654272 5994 \n"
     ]
    }
   ],
   "source": [
    "train_img,test_img,train_label,test_label = input_data()\n",
    "log_info('type:',type(train_img),type(train_label))\n",
    "log_info('shape:',train_img.shape,train_label.shape)\n",
    "log_info('size:',train_img.size,train_label.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'numpy.ndarray'> <class 'numpy.ndarray'> \n",
      "shape: (5994, 64, 64, 3) (5994, 200) \n",
      "size: 73654272 1198800 \n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "num_classes = 200\n",
    "model_name = 'bird.h5'\n",
    "\n",
    "# 数据预处理，把 0-255的灰度值转成 0-1 之间的浮点数\n",
    "x_train = train_img.astype('float32')/255\n",
    "x_test = test_img.astype('float32')/255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(train_label-1, num_classes)\n",
    "y_test = keras.utils.to_categorical(test_label-1, num_classes)\n",
    "log_info('type:',type(x_train),type(y_train))\n",
    "log_info('shape:',x_train.shape,y_train.shape)\n",
    "log_info('size:',x_train.size,y_train.size)\n",
    "\n",
    "# shuffle\n",
    "x_train, y_train = np.array(x_train),np.array(y_train)\n",
    "index = [i for i in range(len(y_train))]\n",
    "np.random.shuffle(index)\n",
    "x_train = x_train[index]\n",
    "y_train = y_train[index]\n",
    "\n",
    "# 拆分验证集\n",
    "(x_valid, x_train) = x_train[5000:], x_train[:5000] # 994+5000\n",
    "(y_valid, y_train) = y_train[5000:], y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "datagen_train = ImageDataGenerator(\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range = 0.1,\n",
    "horizontal_flip = True)\n",
    " \n",
    "datagen_train.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 200)               0         \n",
      "=================================================================\n",
      "Total params: 4,390,664\n",
      "Trainable params: 4,390,664\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# initiate optimizer\n",
    "opt = keras.optimizers.adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "156/156 [==============================] - 12s 74ms/step - loss: 5.3067 - acc: 0.0028 - val_loss: 5.3071 - val_acc: 0.0010\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.30711, saving model to bird.weights.best.hdf5\n",
      "Epoch 2/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 5.2967 - acc: 0.0060 - val_loss: 5.2727 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.30711 to 5.27266, saving model to bird.weights.best.hdf5\n",
      "Epoch 3/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 5.1866 - acc: 0.0080 - val_loss: 5.1030 - val_acc: 0.0050\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.27266 to 5.10302, saving model to bird.weights.best.hdf5\n",
      "Epoch 4/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.9959 - acc: 0.0142 - val_loss: 4.9295 - val_acc: 0.0171\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.10302 to 4.92945, saving model to bird.weights.best.hdf5\n",
      "Epoch 5/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.8893 - acc: 0.0204 - val_loss: 4.8523 - val_acc: 0.0111\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.92945 to 4.85227, saving model to bird.weights.best.hdf5\n",
      "Epoch 6/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.7999 - acc: 0.0266 - val_loss: 4.7392 - val_acc: 0.0272\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.85227 to 4.73924, saving model to bird.weights.best.hdf5\n",
      "Epoch 7/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.6975 - acc: 0.0377 - val_loss: 4.6745 - val_acc: 0.0423\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.73924 to 4.67451, saving model to bird.weights.best.hdf5\n",
      "Epoch 8/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.5772 - acc: 0.0421 - val_loss: 4.5564 - val_acc: 0.0392\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.67451 to 4.55639, saving model to bird.weights.best.hdf5\n",
      "Epoch 9/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.4651 - acc: 0.0557 - val_loss: 4.4803 - val_acc: 0.0573\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.55639 to 4.48027, saving model to bird.weights.best.hdf5\n",
      "Epoch 10/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.3816 - acc: 0.0667 - val_loss: 4.4013 - val_acc: 0.0694\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.48027 to 4.40133, saving model to bird.weights.best.hdf5\n",
      "Epoch 11/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.2924 - acc: 0.0735 - val_loss: 4.3633 - val_acc: 0.0744\n",
      "\n",
      "Epoch 00011: val_loss improved from 4.40133 to 4.36333, saving model to bird.weights.best.hdf5\n",
      "Epoch 12/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.1825 - acc: 0.0881 - val_loss: 4.2722 - val_acc: 0.0976\n",
      "\n",
      "Epoch 00012: val_loss improved from 4.36333 to 4.27222, saving model to bird.weights.best.hdf5\n",
      "Epoch 13/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.0984 - acc: 0.0949 - val_loss: 4.2628 - val_acc: 0.0815\n",
      "\n",
      "Epoch 00013: val_loss improved from 4.27222 to 4.26280, saving model to bird.weights.best.hdf5\n",
      "Epoch 14/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 4.0320 - acc: 0.1026 - val_loss: 4.2430 - val_acc: 0.0795\n",
      "\n",
      "Epoch 00014: val_loss improved from 4.26280 to 4.24296, saving model to bird.weights.best.hdf5\n",
      "Epoch 15/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 3.9617 - acc: 0.1156 - val_loss: 4.1616 - val_acc: 0.1006\n",
      "\n",
      "Epoch 00015: val_loss improved from 4.24296 to 4.16159, saving model to bird.weights.best.hdf5\n",
      "Epoch 16/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 3.8806 - acc: 0.1280 - val_loss: 4.1553 - val_acc: 0.1016\n",
      "\n",
      "Epoch 00016: val_loss improved from 4.16159 to 4.15527, saving model to bird.weights.best.hdf5\n",
      "Epoch 17/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 3.7842 - acc: 0.1368 - val_loss: 4.0937 - val_acc: 0.1046\n",
      "\n",
      "Epoch 00017: val_loss improved from 4.15527 to 4.09369, saving model to bird.weights.best.hdf5\n",
      "Epoch 18/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 3.7422 - acc: 0.1438 - val_loss: 4.0394 - val_acc: 0.1097\n",
      "\n",
      "Epoch 00018: val_loss improved from 4.09369 to 4.03944, saving model to bird.weights.best.hdf5\n",
      "Epoch 19/30\n",
      "156/156 [==============================] - 8s 50ms/step - loss: 3.6868 - acc: 0.1565 - val_loss: 4.0463 - val_acc: 0.0986\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.03944\n",
      "Epoch 20/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 3.5932 - acc: 0.1715 - val_loss: 4.0145 - val_acc: 0.1117\n",
      "\n",
      "Epoch 00020: val_loss improved from 4.03944 to 4.01452, saving model to bird.weights.best.hdf5\n",
      "Epoch 21/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 3.5642 - acc: 0.1653 - val_loss: 3.9914 - val_acc: 0.1247\n",
      "\n",
      "Epoch 00021: val_loss improved from 4.01452 to 3.99138, saving model to bird.weights.best.hdf5\n",
      "Epoch 22/30\n",
      "156/156 [==============================] - 8s 49ms/step - loss: 3.4872 - acc: 0.1759 - val_loss: 4.0011 - val_acc: 0.1167\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.99138\n",
      "Epoch 23/30\n",
      "156/156 [==============================] - 8s 50ms/step - loss: 3.4583 - acc: 0.1859 - val_loss: 3.9878 - val_acc: 0.1217\n",
      "\n",
      "Epoch 00023: val_loss improved from 3.99138 to 3.98781, saving model to bird.weights.best.hdf5\n",
      "Epoch 24/30\n",
      "155/156 [============================>.] - ETA: 0s - loss: 3.3984 - acc: 0.1933"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d605e75e182f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 validation_steps=x_valid.shape[0] // batch_size)\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramFilesNoSpace\\Miniconda3\\envs\\py36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFilesNoSpace\\Miniconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFilesNoSpace\\Miniconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    240\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m                             verbose=0)\n\u001b[0m\u001b[0;32m    243\u001b[0m                     \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                     \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFilesNoSpace\\Miniconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1111\u001b[0m                                          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m                                          steps=steps)\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32mD:\\ProgramFilesNoSpace\\Miniconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFilesNoSpace\\Miniconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFilesNoSpace\\Miniconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFilesNoSpace\\Miniconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# hist = model.fit(x_train, y_train, epochs=30, shuffle=True)\n",
    "# model.save(model_name)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    " \n",
    "batch_size=32\n",
    "checkpoint = ModelCheckpoint(filepath='bird.weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "hist = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=32),\n",
    "                steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                epochs = 30,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                callbacks=[checkpoint],\n",
    "                validation_data=(x_valid, y_valid),\n",
    "                validation_steps=x_valid.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('evaluate: loss:{} acc:{}'.format(loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_img:\n",
    "    cv2.imshow('img',i)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
