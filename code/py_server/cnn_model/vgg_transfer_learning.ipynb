{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考 http://www.cnblogs.com/zyly/p/9146787.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.nets import vgg\n",
    "\n",
    "IMAGE_SIZE = vgg.vgg_16.default_image_size\n",
    "print(IMAGE_SIZE)\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "shape: (5994, 224, 224, 3) (5994,)\n",
      "size: 902264832 5994\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "def input_data(npz_file):\n",
    "    if os.path.exists(npz_file) :\n",
    "        bird_data = np.load(npz_file)\n",
    "        return bird_data['train_img'],bird_data['test_img'],bird_data['train_label'],bird_data['test_label']\n",
    "    else:      \n",
    "        data_path = os.path.join('../../..','data','CUB_200_2011')\n",
    "        print(os.listdir(data_path))\n",
    "\n",
    "        train_test_split_file = os.path.join(data_path,'train_test_split.txt')\n",
    "        with open(train_test_split_file,'r') as file:\n",
    "            train_test_split = np.array([i.split()[1] for i in file.readlines()]).astype('bool')\n",
    "        print(train_test_split,train_test_split.size)\n",
    "\n",
    "        img_paths_file = os.path.join(data_path,'images.txt')\n",
    "        with open(img_paths_file,'r') as file:\n",
    "            img_paths = [i.split()[1] for i in file.readlines()]\n",
    "        print(img_paths[:1],len(img_paths))\n",
    "\n",
    "        img_labels_file = os.path.join(data_path,'image_class_labels.txt')\n",
    "        with open(img_labels_file,'r') as file:\n",
    "            img_labels = np.array([i.split()[1] for i in file.readlines()]).astype('int')\n",
    "        print(img_labels,len(img_labels))\n",
    "\n",
    "        img_dir = os.path.join(data_path,'images')\n",
    "\n",
    "        img_paths_train = [os.path.join(img_dir,os.path.sep.join(path.split('/'))) for i,path in enumerate(img_paths) if train_test_split[i]]\n",
    "        print(img_paths_train[:1],len(img_paths_train))\n",
    "        img_paths_test = [os.path.join(img_dir,os.path.sep.join(path.split('/'))) for i,path in enumerate(img_paths) if not train_test_split[i]]\n",
    "        print(img_paths_test[:1],len(img_paths_test))\n",
    "\n",
    "        train_img = np.array([cv2.resize(cv2.imread(i),(224,224)) for i in img_paths_train])\n",
    "        test_img = np.array([cv2.resize(cv2.imread(i),(224,224)) for i in img_paths_test])\n",
    "        train_label = np.array([l for i,l in enumerate(img_labels) if train_test_split[i] ])\n",
    "        test_label = np.array([l for i,l in enumerate(img_labels) if not train_test_split[i]])\n",
    "        print(train_label,train_label.size)\n",
    "        print(test_label,test_label.size)\n",
    "\n",
    "        np.savez(npz_file,train_img=train_img,test_img=test_img,train_label=train_label,test_label=test_label)\n",
    "        return train_img,test_img,train_label,test_label\n",
    "    \n",
    "x_train,x_test,y_train,y_test = input_data('bird_data_224.npz')\n",
    "\n",
    "\n",
    "num_classes = 200\n",
    "\n",
    "# 数据预处理，把 0-255的灰度值转成 0-1 之间的浮点数\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "y_train, y_test = np.array(y_train)-1, np.array(y_test)-1\n",
    "\n",
    "\n",
    "\n",
    "print('type:',type(x_train),type(y_train))\n",
    "print('shape:',x_train.shape,y_train.shape)\n",
    "print('size:',x_train.size,y_train.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 批量数据 生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "def shuffle_aligned_list(data):\n",
    "    \"\"\"Shuffle arrays in a list by shuffling each array identically.\"\"\"\n",
    "    num = data[0].shape[0]\n",
    "    p = np.random.permutation(num)\n",
    "    return [d[p] for d in data]\n",
    "\n",
    "def batch_generator(data, batch_size, shuffle=True):\n",
    "    \"\"\"Generate batches of data.\n",
    "\n",
    "    Given a list of array-like objects, generate batches of a given\n",
    "    size by yielding a list of array-like objects corresponding to the\n",
    "    same slice of each input.\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        data = shuffle_aligned_list(data)\n",
    "\n",
    "    batch_count = 0\n",
    "    while True:\n",
    "        if batch_count * batch_size + batch_size > len(data[0]):\n",
    "            batch_count = 0\n",
    "\n",
    "            if shuffle:\n",
    "                data = shuffle_aligned_list(data)\n",
    "\n",
    "        start = batch_count * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_count += 1\n",
    "        yield [d[start:end] for d in data]\n",
    "        \n",
    "data_gen_test = batch_generator([x_test,y_test], batch_size, shuffle=True)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "data_gen_train = ImageDataGenerator(\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    rotation_range=30,    #0-180\n",
    "    horizontal_flip = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 微调 VGG\n",
    "\n",
    "首先，单独训练 fc8，训练了 196 epochs\n",
    "\n",
    "然后，训练整个网络，训练了 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 200)\n",
      "INFO:tensorflow:Restoring parameters from ./vgg_16_2016_08_28/slim_fine_tune\\birds_fine_tune.ckpt-196\n",
      "从上次训练保存后的模型继续训练！\n",
      "开始训练！\n",
      "epoch: 0 batch: 0 train batch accuracy: 0.078125 loss: 4.278685569763184\n",
      "epoch: 0 batch: 1 train batch accuracy: 0.0 loss: 12.081350326538086\n",
      "epoch: 0 batch: 2 train batch accuracy: 0.0 loss: 11.747150421142578\n",
      "epoch: 0 batch: 3 train batch accuracy: 0.015625 loss: 8.02389144897461\n",
      "epoch: 0 batch: 4 train batch accuracy: 0.015625 loss: 6.392911434173584\n",
      "epoch: 0 batch: 5 train batch accuracy: 0.0 loss: 6.545704364776611\n",
      "epoch: 0 batch: 6 train batch accuracy: 0.0 loss: 6.41831111907959\n",
      "epoch: 0 batch: 7 train batch accuracy: 0.015625 loss: 5.695311069488525\n",
      "epoch: 0 batch: 8 train batch accuracy: 0.0 loss: 5.759634017944336\n",
      "epoch: 0 batch: 9 train batch accuracy: 0.03125 loss: 5.439011096954346\n",
      "epoch: 0 batch: 10 train batch accuracy: 0.015625 loss: 5.738134384155273\n",
      "epoch: 0 batch: 11 train batch accuracy: 0.0 loss: 5.372401237487793\n",
      "epoch: 0 batch: 12 train batch accuracy: 0.015625 loss: 5.554009437561035\n",
      "epoch: 0 batch: 13 train batch accuracy: 0.03125 loss: 5.421782970428467\n",
      "epoch: 0 batch: 14 train batch accuracy: 0.015625 loss: 5.222240447998047\n",
      "epoch: 0 batch: 15 train batch accuracy: 0.03125 loss: 5.3175554275512695\n",
      "epoch: 0 batch: 16 train batch accuracy: 0.03125 loss: 5.2439117431640625\n",
      "epoch: 0 batch: 17 train batch accuracy: 0.015625 loss: 5.110820770263672\n",
      "epoch: 0 batch: 18 train batch accuracy: 0.0 loss: 5.265976905822754\n",
      "epoch: 0 batch: 19 train batch accuracy: 0.0 loss: 5.255414009094238\n",
      "epoch: 0 batch: 20 train batch accuracy: 0.03125 loss: 5.166147232055664\n",
      "epoch: 0 batch: 21 train batch accuracy: 0.03125 loss: 5.013894081115723\n",
      "epoch: 0 batch: 22 train batch accuracy: 0.0 loss: 5.095332622528076\n",
      "epoch: 0 batch: 23 train batch accuracy: 0.0 loss: 5.219259262084961\n",
      "epoch: 0 batch: 24 train batch accuracy: 0.03125 loss: 5.0891947746276855\n",
      "epoch: 0 batch: 25 train batch accuracy: 0.0 loss: 5.302759647369385\n",
      "epoch: 0 batch: 26 train batch accuracy: 0.015625 loss: 5.087366104125977\n",
      "epoch: 0 batch: 27 train batch accuracy: 0.0 loss: 5.31665563583374\n",
      "epoch: 0 batch: 28 train batch accuracy: 0.0 loss: 5.280059337615967\n",
      "epoch: 0 batch: 29 train batch accuracy: 0.015625 loss: 5.135739803314209\n",
      "epoch: 0 batch: 30 train batch accuracy: 0.0 loss: 5.125214576721191\n",
      "epoch: 0 batch: 31 train batch accuracy: 0.015625 loss: 5.067646026611328\n",
      "epoch: 0 batch: 32 train batch accuracy: 0.03125 loss: 5.2018232345581055\n",
      "epoch: 0 batch: 33 train batch accuracy: 0.015625 loss: 5.032125473022461\n",
      "epoch: 0 batch: 34 train batch accuracy: 0.0 loss: 5.060834884643555\n",
      "epoch: 0 batch: 35 train batch accuracy: 0.015625 loss: 4.90577507019043\n",
      "epoch: 0 batch: 36 train batch accuracy: 0.015625 loss: 5.092044830322266\n",
      "epoch: 0 batch: 37 train batch accuracy: 0.015625 loss: 4.942096710205078\n",
      "epoch: 0 batch: 38 train batch accuracy: 0.03125 loss: 5.086694717407227\n",
      "epoch: 0 batch: 39 train batch accuracy: 0.0 loss: 5.031512260437012\n",
      "epoch: 0 batch: 40 train batch accuracy: 0.015625 loss: 4.9728288650512695\n",
      "epoch: 0 batch: 41 train batch accuracy: 0.015625 loss: 4.937001705169678\n",
      "epoch: 0 batch: 42 train batch accuracy: 0.03125 loss: 4.9890241622924805\n",
      "epoch: 0 batch: 43 train batch accuracy: 0.03125 loss: 4.990207672119141\n",
      "epoch: 0 batch: 44 train batch accuracy: 0.03125 loss: 4.830805778503418\n",
      "epoch: 0 batch: 45 train batch accuracy: 0.03125 loss: 4.996613502502441\n",
      "epoch: 0 batch: 46 train batch accuracy: 0.015625 loss: 4.984621524810791\n",
      "epoch: 0 batch: 47 train batch accuracy: 0.0 loss: 4.948249816894531\n",
      "epoch: 0 batch: 48 train batch accuracy: 0.0 loss: 4.887932300567627\n",
      "epoch: 0 batch: 49 train batch accuracy: 0.03125 loss: 4.884243011474609\n",
      "epoch: 0 batch: 50 train batch accuracy: 0.046875 loss: 4.801979064941406\n",
      "epoch: 0 batch: 51 train batch accuracy: 0.015625 loss: 4.834102153778076\n",
      "epoch: 0 batch: 52 train batch accuracy: 0.046875 loss: 4.660654067993164\n",
      "epoch: 0 batch: 53 train batch accuracy: 0.0625 loss: 4.749929904937744\n",
      "epoch: 0 batch: 54 train batch accuracy: 0.03125 loss: 4.948707580566406\n",
      "epoch: 0 batch: 55 train batch accuracy: 0.03125 loss: 4.781757354736328\n",
      "epoch: 0 batch: 56 train batch accuracy: 0.046875 loss: 4.900566577911377\n",
      "epoch: 0 batch: 57 train batch accuracy: 0.03125 loss: 4.724255561828613\n",
      "epoch: 0 batch: 58 train batch accuracy: 0.015625 loss: 4.734347820281982\n",
      "epoch: 0 batch: 59 train batch accuracy: 0.015625 loss: 4.602536201477051\n",
      "epoch: 0 batch: 60 train batch accuracy: 0.0 loss: 4.722176551818848\n",
      "epoch: 0 batch: 61 train batch accuracy: 0.046875 loss: 4.716328144073486\n",
      "epoch: 0 batch: 62 train batch accuracy: 0.0 loss: 4.751678466796875\n",
      "epoch: 0 batch: 63 train batch accuracy: 0.03125 loss: 4.58826208114624\n",
      "epoch: 0 batch: 64 train batch accuracy: 0.03125 loss: 4.691554069519043\n",
      "epoch: 0 batch: 65 train batch accuracy: 0.0 loss: 4.699366569519043\n",
      "epoch: 0 batch: 66 train batch accuracy: 0.0 loss: 4.679388999938965\n",
      "epoch: 0 batch: 67 train batch accuracy: 0.015625 loss: 4.931149482727051\n",
      "epoch: 0 batch: 68 train batch accuracy: 0.015625 loss: 4.717637538909912\n",
      "epoch: 0 batch: 69 train batch accuracy: 0.03125 loss: 4.741029739379883\n",
      "epoch: 0 batch: 70 train batch accuracy: 0.078125 loss: 4.697577953338623\n",
      "epoch: 0 batch: 71 train batch accuracy: 0.078125 loss: 4.413370609283447\n",
      "epoch: 0 batch: 72 train batch accuracy: 0.03125 loss: 4.69687032699585\n",
      "epoch: 0 batch: 73 train batch accuracy: 0.046875 loss: 4.787517547607422\n",
      "epoch: 0 batch: 74 train batch accuracy: 0.015625 loss: 4.63966178894043\n",
      "epoch: 0 batch: 75 train batch accuracy: 0.03125 loss: 4.588105201721191\n",
      "epoch: 0 batch: 76 train batch accuracy: 0.0 loss: 4.596776962280273\n",
      "epoch: 0 batch: 77 train batch accuracy: 0.015625 loss: 4.456682205200195\n",
      "epoch: 0 batch: 78 train batch accuracy: 0.015625 loss: 4.607657432556152\n",
      "epoch: 0 batch: 79 train batch accuracy: 0.03125 loss: 4.477990627288818\n",
      "epoch: 0 batch: 80 train batch accuracy: 0.0 loss: 5.026278495788574\n",
      "epoch: 0 batch: 81 train batch accuracy: 0.03125 loss: 4.422597885131836\n",
      "epoch: 0 batch: 82 train batch accuracy: 0.078125 loss: 4.377198696136475\n",
      "epoch: 0 batch: 83 train batch accuracy: 0.03125 loss: 4.704429626464844\n",
      "epoch: 0 batch: 84 train batch accuracy: 0.0625 loss: 4.477216720581055\n",
      "epoch: 0 batch: 85 train batch accuracy: 0.0 loss: 4.643838405609131\n",
      "epoch: 0 batch: 86 train batch accuracy: 0.0625 loss: 4.386173248291016\n",
      "epoch: 0 batch: 87 train batch accuracy: 0.015625 loss: 4.529472351074219\n",
      "epoch: 0 batch: 88 train batch accuracy: 0.0625 loss: 4.39861536026001\n",
      "epoch: 0 batch: 89 train batch accuracy: 0.046875 loss: 4.405492782592773\n",
      "epoch: 0 batch: 90 train batch accuracy: 0.015625 loss: 4.199024200439453\n",
      "epoch: 0 batch: 91 train batch accuracy: 0.0625 loss: 4.274016380310059\n",
      "epoch: 0 batch: 92 train batch accuracy: 0.015625 loss: 4.3597412109375\n",
      "epoch: 0 batch: 93 train batch accuracy: 0.078125 loss: 4.363041877746582\n",
      "Epoch 1/1000  average cost 5.117709241\n",
      "Epoch 1/1000  Test cost 4.203820229\n",
      "准确率: 0.09375\n",
      "Epoch 1/1000  模型保存成功\n",
      "epoch: 1 batch: 0 train batch accuracy: 0.09375 loss: 4.346219062805176\n",
      "epoch: 1 batch: 1 train batch accuracy: 0.046875 loss: 4.382928848266602\n",
      "epoch: 1 batch: 2 train batch accuracy: 0.046875 loss: 4.385618686676025\n",
      "epoch: 1 batch: 3 train batch accuracy: 0.0625 loss: 4.35394287109375\n",
      "epoch: 1 batch: 4 train batch accuracy: 0.03125 loss: 4.29597282409668\n",
      "epoch: 1 batch: 5 train batch accuracy: 0.09375 loss: 4.303200721740723\n",
      "epoch: 1 batch: 6 train batch accuracy: 0.078125 loss: 4.137423515319824\n",
      "epoch: 1 batch: 7 train batch accuracy: 0.09375 loss: 4.335266590118408\n",
      "epoch: 1 batch: 8 train batch accuracy: 0.125 loss: 3.891524314880371\n",
      "epoch: 1 batch: 9 train batch accuracy: 0.015625 loss: 4.3997697830200195\n",
      "epoch: 1 batch: 10 train batch accuracy: 0.0625 loss: 4.251358985900879\n",
      "epoch: 1 batch: 11 train batch accuracy: 0.140625 loss: 4.03497838973999\n",
      "epoch: 1 batch: 12 train batch accuracy: 0.0625 loss: 4.12689208984375\n",
      "epoch: 1 batch: 13 train batch accuracy: 0.09375 loss: 4.16771125793457\n",
      "epoch: 1 batch: 14 train batch accuracy: 0.09375 loss: 4.038116455078125\n",
      "epoch: 1 batch: 15 train batch accuracy: 0.046875 loss: 4.105932235717773\n",
      "epoch: 1 batch: 16 train batch accuracy: 0.046875 loss: 4.304262161254883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 batch: 17 train batch accuracy: 0.0625 loss: 4.156362533569336\n",
      "epoch: 1 batch: 18 train batch accuracy: 0.09375 loss: 4.019362926483154\n",
      "epoch: 1 batch: 19 train batch accuracy: 0.078125 loss: 3.889273166656494\n",
      "epoch: 1 batch: 20 train batch accuracy: 0.078125 loss: 4.165731906890869\n",
      "epoch: 1 batch: 21 train batch accuracy: 0.125 loss: 4.04695463180542\n",
      "epoch: 1 batch: 22 train batch accuracy: 0.09375 loss: 4.077465057373047\n",
      "epoch: 1 batch: 23 train batch accuracy: 0.015625 loss: 4.227624893188477\n",
      "epoch: 1 batch: 24 train batch accuracy: 0.109375 loss: 4.00766658782959\n",
      "epoch: 1 batch: 25 train batch accuracy: 0.0625 loss: 4.070629596710205\n",
      "epoch: 1 batch: 26 train batch accuracy: 0.09375 loss: 4.043320655822754\n",
      "epoch: 1 batch: 27 train batch accuracy: 0.109375 loss: 3.903799533843994\n",
      "epoch: 1 batch: 28 train batch accuracy: 0.109375 loss: 3.889280080795288\n",
      "epoch: 1 batch: 29 train batch accuracy: 0.078125 loss: 4.256725311279297\n",
      "epoch: 1 batch: 30 train batch accuracy: 0.0625 loss: 3.9579107761383057\n",
      "epoch: 1 batch: 31 train batch accuracy: 0.078125 loss: 3.9777657985687256\n",
      "epoch: 1 batch: 32 train batch accuracy: 0.03125 loss: 4.070781707763672\n",
      "epoch: 1 batch: 33 train batch accuracy: 0.09375 loss: 3.993004083633423\n",
      "epoch: 1 batch: 34 train batch accuracy: 0.09375 loss: 4.202572822570801\n",
      "epoch: 1 batch: 35 train batch accuracy: 0.078125 loss: 4.013323783874512\n",
      "epoch: 1 batch: 36 train batch accuracy: 0.125 loss: 3.9291937351226807\n",
      "epoch: 1 batch: 37 train batch accuracy: 0.125 loss: 3.8952853679656982\n",
      "epoch: 1 batch: 38 train batch accuracy: 0.078125 loss: 3.8504557609558105\n",
      "epoch: 1 batch: 39 train batch accuracy: 0.09375 loss: 3.777906656265259\n",
      "epoch: 1 batch: 40 train batch accuracy: 0.125 loss: 3.91231632232666\n",
      "epoch: 1 batch: 41 train batch accuracy: 0.15625 loss: 3.8016741275787354\n",
      "epoch: 1 batch: 42 train batch accuracy: 0.15625 loss: 3.335786819458008\n",
      "epoch: 1 batch: 43 train batch accuracy: 0.078125 loss: 3.771270275115967\n",
      "epoch: 1 batch: 44 train batch accuracy: 0.109375 loss: 3.842495918273926\n",
      "epoch: 1 batch: 45 train batch accuracy: 0.125 loss: 3.7704379558563232\n",
      "epoch: 1 batch: 46 train batch accuracy: 0.03125 loss: 4.278074741363525\n",
      "epoch: 1 batch: 47 train batch accuracy: 0.140625 loss: 3.824937105178833\n",
      "epoch: 1 batch: 48 train batch accuracy: 0.0625 loss: 3.784559726715088\n",
      "epoch: 1 batch: 49 train batch accuracy: 0.125 loss: 3.5335655212402344\n",
      "epoch: 1 batch: 50 train batch accuracy: 0.125 loss: 3.7453219890594482\n",
      "epoch: 1 batch: 51 train batch accuracy: 0.09375 loss: 3.865084648132324\n",
      "epoch: 1 batch: 52 train batch accuracy: 0.171875 loss: 3.6959104537963867\n",
      "epoch: 1 batch: 53 train batch accuracy: 0.15625 loss: 3.648221969604492\n",
      "epoch: 1 batch: 54 train batch accuracy: 0.140625 loss: 3.7491555213928223\n",
      "epoch: 1 batch: 55 train batch accuracy: 0.140625 loss: 3.865017890930176\n",
      "epoch: 1 batch: 56 train batch accuracy: 0.15625 loss: 3.539874315261841\n",
      "epoch: 1 batch: 57 train batch accuracy: 0.15625 loss: 3.505153179168701\n",
      "epoch: 1 batch: 58 train batch accuracy: 0.21875 loss: 3.5970263481140137\n",
      "epoch: 1 batch: 59 train batch accuracy: 0.125 loss: 3.7343242168426514\n",
      "epoch: 1 batch: 60 train batch accuracy: 0.15625 loss: 3.5445220470428467\n",
      "epoch: 1 batch: 61 train batch accuracy: 0.203125 loss: 3.3400535583496094\n",
      "epoch: 1 batch: 62 train batch accuracy: 0.09375 loss: 3.5929384231567383\n",
      "epoch: 1 batch: 63 train batch accuracy: 0.140625 loss: 3.5568552017211914\n",
      "epoch: 1 batch: 64 train batch accuracy: 0.15625 loss: 3.5246739387512207\n",
      "epoch: 1 batch: 65 train batch accuracy: 0.125 loss: 3.741807222366333\n",
      "epoch: 1 batch: 66 train batch accuracy: 0.203125 loss: 3.327064275741577\n",
      "epoch: 1 batch: 67 train batch accuracy: 0.125 loss: 3.7863309383392334\n",
      "epoch: 1 batch: 68 train batch accuracy: 0.21875 loss: 3.5698843002319336\n",
      "epoch: 1 batch: 69 train batch accuracy: 0.15625 loss: 3.2874865531921387\n",
      "epoch: 1 batch: 70 train batch accuracy: 0.15625 loss: 3.3493549823760986\n",
      "epoch: 1 batch: 71 train batch accuracy: 0.265625 loss: 3.1171886920928955\n",
      "epoch: 1 batch: 72 train batch accuracy: 0.203125 loss: 3.2542877197265625\n",
      "epoch: 1 batch: 73 train batch accuracy: 0.21875 loss: 3.2290589809417725\n",
      "epoch: 1 batch: 74 train batch accuracy: 0.0625 loss: 3.856736898422241\n",
      "epoch: 1 batch: 75 train batch accuracy: 0.265625 loss: 3.336576461791992\n",
      "epoch: 1 batch: 76 train batch accuracy: 0.25 loss: 3.0736327171325684\n",
      "epoch: 1 batch: 77 train batch accuracy: 0.203125 loss: 3.2750961780548096\n",
      "epoch: 1 batch: 78 train batch accuracy: 0.1875 loss: 3.1109347343444824\n",
      "epoch: 1 batch: 79 train batch accuracy: 0.1875 loss: 3.5103919506073\n",
      "epoch: 1 batch: 80 train batch accuracy: 0.15625 loss: 3.358750581741333\n",
      "epoch: 1 batch: 81 train batch accuracy: 0.171875 loss: 3.473311424255371\n",
      "epoch: 1 batch: 82 train batch accuracy: 0.234375 loss: 3.1602399349212646\n",
      "epoch: 1 batch: 83 train batch accuracy: 0.21875 loss: 3.3703761100769043\n",
      "epoch: 1 batch: 84 train batch accuracy: 0.125 loss: 3.7092692852020264\n",
      "epoch: 1 batch: 85 train batch accuracy: 0.171875 loss: 3.2226099967956543\n",
      "epoch: 1 batch: 86 train batch accuracy: 0.203125 loss: 3.0395493507385254\n",
      "epoch: 1 batch: 87 train batch accuracy: 0.359375 loss: 2.9185690879821777\n",
      "epoch: 1 batch: 88 train batch accuracy: 0.1875 loss: 3.2731387615203857\n",
      "epoch: 1 batch: 89 train batch accuracy: 0.28125 loss: 3.1935129165649414\n",
      "epoch: 1 batch: 90 train batch accuracy: 0.21875 loss: 2.8458731174468994\n",
      "epoch: 1 batch: 91 train batch accuracy: 0.28125 loss: 2.972879409790039\n",
      "epoch: 1 batch: 92 train batch accuracy: 0.21875 loss: 2.9001431465148926\n",
      "epoch: 1 batch: 93 train batch accuracy: 0.203125 loss: 3.2116341590881348\n",
      "Epoch 2/1000  average cost 3.745941045\n",
      "Epoch 2/1000  Test cost 3.459819794\n",
      "准确率: 0.15625\n",
      "Epoch 2/1000  模型保存成功\n",
      "epoch: 2 batch: 0 train batch accuracy: 0.25 loss: 2.9209184646606445\n",
      "epoch: 2 batch: 1 train batch accuracy: 0.21875 loss: 3.2022838592529297\n",
      "epoch: 2 batch: 2 train batch accuracy: 0.25 loss: 3.4969000816345215\n",
      "epoch: 2 batch: 3 train batch accuracy: 0.25 loss: 2.7930521965026855\n",
      "epoch: 2 batch: 4 train batch accuracy: 0.28125 loss: 2.8799171447753906\n",
      "epoch: 2 batch: 5 train batch accuracy: 0.25 loss: 2.8133342266082764\n",
      "epoch: 2 batch: 6 train batch accuracy: 0.296875 loss: 2.9940004348754883\n",
      "epoch: 2 batch: 7 train batch accuracy: 0.3125 loss: 2.865816593170166\n",
      "epoch: 2 batch: 8 train batch accuracy: 0.140625 loss: 3.259552001953125\n",
      "epoch: 2 batch: 9 train batch accuracy: 0.21875 loss: 3.1418888568878174\n",
      "epoch: 2 batch: 10 train batch accuracy: 0.171875 loss: 3.1997485160827637\n",
      "epoch: 2 batch: 11 train batch accuracy: 0.171875 loss: 3.224898338317871\n",
      "epoch: 2 batch: 12 train batch accuracy: 0.265625 loss: 3.214907169342041\n",
      "epoch: 2 batch: 13 train batch accuracy: 0.1875 loss: 2.9998834133148193\n",
      "epoch: 2 batch: 14 train batch accuracy: 0.328125 loss: 3.139080047607422\n",
      "epoch: 2 batch: 15 train batch accuracy: 0.15625 loss: 3.1909823417663574\n",
      "epoch: 2 batch: 16 train batch accuracy: 0.296875 loss: 2.9006690979003906\n",
      "epoch: 2 batch: 17 train batch accuracy: 0.21875 loss: 2.961859703063965\n",
      "epoch: 2 batch: 18 train batch accuracy: 0.234375 loss: 3.037576675415039\n",
      "epoch: 2 batch: 19 train batch accuracy: 0.21875 loss: 3.1471428871154785\n",
      "epoch: 2 batch: 20 train batch accuracy: 0.25 loss: 2.9678258895874023\n",
      "epoch: 2 batch: 21 train batch accuracy: 0.3125 loss: 3.0522308349609375\n",
      "epoch: 2 batch: 22 train batch accuracy: 0.328125 loss: 2.8227407932281494\n",
      "epoch: 2 batch: 23 train batch accuracy: 0.28125 loss: 2.7220611572265625\n",
      "epoch: 2 batch: 24 train batch accuracy: 0.34375 loss: 2.7310237884521484\n",
      "epoch: 2 batch: 25 train batch accuracy: 0.3125 loss: 2.7806053161621094\n",
      "epoch: 2 batch: 26 train batch accuracy: 0.296875 loss: 2.9429664611816406\n",
      "epoch: 2 batch: 27 train batch accuracy: 0.21875 loss: 2.674459218978882\n",
      "epoch: 2 batch: 28 train batch accuracy: 0.359375 loss: 2.790062665939331\n",
      "epoch: 2 batch: 29 train batch accuracy: 0.328125 loss: 2.6212165355682373\n",
      "epoch: 2 batch: 30 train batch accuracy: 0.296875 loss: 2.4843130111694336\n",
      "epoch: 2 batch: 31 train batch accuracy: 0.234375 loss: 2.783445358276367\n",
      "epoch: 2 batch: 32 train batch accuracy: 0.234375 loss: 2.9340128898620605\n",
      "epoch: 2 batch: 33 train batch accuracy: 0.328125 loss: 2.768752098083496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 batch: 34 train batch accuracy: 0.296875 loss: 2.580561637878418\n",
      "epoch: 2 batch: 35 train batch accuracy: 0.40625 loss: 2.4681506156921387\n",
      "epoch: 2 batch: 36 train batch accuracy: 0.234375 loss: 3.0198559761047363\n",
      "epoch: 2 batch: 37 train batch accuracy: 0.21875 loss: 2.9742815494537354\n",
      "epoch: 2 batch: 38 train batch accuracy: 0.1875 loss: 2.9190540313720703\n",
      "epoch: 2 batch: 39 train batch accuracy: 0.375 loss: 2.3026413917541504\n",
      "epoch: 2 batch: 40 train batch accuracy: 0.25 loss: 2.9377810955047607\n",
      "epoch: 2 batch: 41 train batch accuracy: 0.28125 loss: 2.5895156860351562\n",
      "epoch: 2 batch: 42 train batch accuracy: 0.34375 loss: 2.7876720428466797\n",
      "epoch: 2 batch: 43 train batch accuracy: 0.28125 loss: 3.0213284492492676\n",
      "epoch: 2 batch: 44 train batch accuracy: 0.28125 loss: 2.869292736053467\n",
      "epoch: 2 batch: 45 train batch accuracy: 0.3125 loss: 2.435699939727783\n",
      "epoch: 2 batch: 46 train batch accuracy: 0.265625 loss: 2.8691935539245605\n",
      "epoch: 2 batch: 47 train batch accuracy: 0.28125 loss: 2.715634822845459\n",
      "epoch: 2 batch: 48 train batch accuracy: 0.296875 loss: 2.642622947692871\n",
      "epoch: 2 batch: 49 train batch accuracy: 0.234375 loss: 2.7238929271698\n",
      "epoch: 2 batch: 50 train batch accuracy: 0.296875 loss: 2.596585273742676\n",
      "epoch: 2 batch: 51 train batch accuracy: 0.34375 loss: 2.4513869285583496\n",
      "epoch: 2 batch: 52 train batch accuracy: 0.234375 loss: 2.8428900241851807\n",
      "epoch: 2 batch: 53 train batch accuracy: 0.3125 loss: 2.815208911895752\n",
      "epoch: 2 batch: 54 train batch accuracy: 0.21875 loss: 2.9632110595703125\n",
      "epoch: 2 batch: 55 train batch accuracy: 0.25 loss: 2.831449270248413\n",
      "epoch: 2 batch: 56 train batch accuracy: 0.25 loss: 2.7634854316711426\n",
      "epoch: 2 batch: 57 train batch accuracy: 0.28125 loss: 2.722829580307007\n",
      "epoch: 2 batch: 58 train batch accuracy: 0.234375 loss: 2.9950075149536133\n",
      "epoch: 2 batch: 59 train batch accuracy: 0.34375 loss: 2.478398323059082\n",
      "epoch: 2 batch: 60 train batch accuracy: 0.1875 loss: 2.9579923152923584\n",
      "epoch: 2 batch: 61 train batch accuracy: 0.28125 loss: 2.9636032581329346\n",
      "epoch: 2 batch: 62 train batch accuracy: 0.421875 loss: 2.5613603591918945\n",
      "epoch: 2 batch: 63 train batch accuracy: 0.28125 loss: 2.611156463623047\n",
      "epoch: 2 batch: 64 train batch accuracy: 0.40625 loss: 2.414425849914551\n",
      "epoch: 2 batch: 65 train batch accuracy: 0.328125 loss: 2.3000757694244385\n",
      "epoch: 2 batch: 66 train batch accuracy: 0.234375 loss: 2.707644462585449\n",
      "epoch: 2 batch: 67 train batch accuracy: 0.25 loss: 2.8163747787475586\n",
      "epoch: 2 batch: 68 train batch accuracy: 0.34375 loss: 2.3509154319763184\n",
      "epoch: 2 batch: 69 train batch accuracy: 0.296875 loss: 2.491684913635254\n",
      "epoch: 2 batch: 70 train batch accuracy: 0.328125 loss: 2.570575714111328\n",
      "epoch: 2 batch: 71 train batch accuracy: 0.359375 loss: 2.508437156677246\n",
      "epoch: 2 batch: 72 train batch accuracy: 0.40625 loss: 2.257709264755249\n",
      "epoch: 2 batch: 73 train batch accuracy: 0.359375 loss: 2.5518054962158203\n",
      "epoch: 2 batch: 74 train batch accuracy: 0.375 loss: 2.449878692626953\n",
      "epoch: 2 batch: 75 train batch accuracy: 0.296875 loss: 2.3869123458862305\n",
      "epoch: 2 batch: 76 train batch accuracy: 0.40625 loss: 2.0701282024383545\n",
      "epoch: 2 batch: 77 train batch accuracy: 0.328125 loss: 2.551421642303467\n",
      "epoch: 2 batch: 78 train batch accuracy: 0.296875 loss: 2.723766565322876\n",
      "epoch: 2 batch: 79 train batch accuracy: 0.265625 loss: 2.8395090103149414\n",
      "epoch: 2 batch: 80 train batch accuracy: 0.453125 loss: 2.015674114227295\n",
      "epoch: 2 batch: 81 train batch accuracy: 0.421875 loss: 2.16510272026062\n",
      "epoch: 2 batch: 82 train batch accuracy: 0.390625 loss: 2.3404788970947266\n",
      "epoch: 2 batch: 83 train batch accuracy: 0.328125 loss: 2.4817538261413574\n",
      "epoch: 2 batch: 84 train batch accuracy: 0.34375 loss: 2.693235158920288\n",
      "epoch: 2 batch: 85 train batch accuracy: 0.28125 loss: 2.536487102508545\n",
      "epoch: 2 batch: 86 train batch accuracy: 0.3125 loss: 2.762387752532959\n",
      "epoch: 2 batch: 87 train batch accuracy: 0.40625 loss: 2.1961326599121094\n",
      "epoch: 2 batch: 88 train batch accuracy: 0.359375 loss: 2.2857565879821777\n",
      "epoch: 2 batch: 89 train batch accuracy: 0.40625 loss: 1.9340121746063232\n",
      "epoch: 2 batch: 90 train batch accuracy: 0.296875 loss: 2.7006821632385254\n",
      "epoch: 2 batch: 91 train batch accuracy: 0.40625 loss: 1.9213182926177979\n",
      "epoch: 2 batch: 92 train batch accuracy: 0.265625 loss: 2.5815367698669434\n",
      "epoch: 2 batch: 93 train batch accuracy: 0.359375 loss: 2.4120490550994873\n",
      "Epoch 3/1000  average cost 2.722231327\n",
      "Epoch 3/1000  Test cost 2.303371906\n",
      "准确率: 0.390625\n",
      "Epoch 3/1000  模型保存成功\n",
      "epoch: 3 batch: 0 train batch accuracy: 0.3125 loss: 2.3564984798431396\n",
      "epoch: 3 batch: 1 train batch accuracy: 0.3125 loss: 2.3771491050720215\n",
      "epoch: 3 batch: 2 train batch accuracy: 0.34375 loss: 2.4307777881622314\n",
      "epoch: 3 batch: 3 train batch accuracy: 0.328125 loss: 2.6374025344848633\n",
      "epoch: 3 batch: 4 train batch accuracy: 0.328125 loss: 2.7332310676574707\n",
      "epoch: 3 batch: 5 train batch accuracy: 0.390625 loss: 2.2028145790100098\n",
      "epoch: 3 batch: 6 train batch accuracy: 0.359375 loss: 2.592954635620117\n",
      "epoch: 3 batch: 7 train batch accuracy: 0.390625 loss: 2.2552218437194824\n",
      "epoch: 3 batch: 8 train batch accuracy: 0.265625 loss: 2.8562357425689697\n",
      "epoch: 3 batch: 9 train batch accuracy: 0.34375 loss: 2.474024772644043\n",
      "epoch: 3 batch: 10 train batch accuracy: 0.359375 loss: 2.3732943534851074\n",
      "epoch: 3 batch: 11 train batch accuracy: 0.296875 loss: 2.1547114849090576\n",
      "epoch: 3 batch: 12 train batch accuracy: 0.375 loss: 2.1712942123413086\n",
      "epoch: 3 batch: 13 train batch accuracy: 0.328125 loss: 2.574735403060913\n",
      "epoch: 3 batch: 14 train batch accuracy: 0.25 loss: 2.6053967475891113\n",
      "epoch: 3 batch: 15 train batch accuracy: 0.421875 loss: 2.067836284637451\n",
      "epoch: 3 batch: 16 train batch accuracy: 0.375 loss: 2.280496597290039\n",
      "epoch: 3 batch: 17 train batch accuracy: 0.359375 loss: 2.6025898456573486\n",
      "epoch: 3 batch: 18 train batch accuracy: 0.34375 loss: 2.3778247833251953\n",
      "epoch: 3 batch: 19 train batch accuracy: 0.40625 loss: 2.210463523864746\n",
      "epoch: 3 batch: 20 train batch accuracy: 0.484375 loss: 1.960174322128296\n",
      "epoch: 3 batch: 21 train batch accuracy: 0.359375 loss: 2.5495047569274902\n",
      "epoch: 3 batch: 22 train batch accuracy: 0.421875 loss: 2.2417941093444824\n",
      "epoch: 3 batch: 23 train batch accuracy: 0.515625 loss: 1.8730641603469849\n",
      "epoch: 3 batch: 24 train batch accuracy: 0.390625 loss: 2.0853090286254883\n",
      "epoch: 3 batch: 25 train batch accuracy: 0.3125 loss: 2.544753313064575\n",
      "epoch: 3 batch: 26 train batch accuracy: 0.390625 loss: 2.0280261039733887\n",
      "epoch: 3 batch: 27 train batch accuracy: 0.453125 loss: 2.050039291381836\n",
      "epoch: 3 batch: 28 train batch accuracy: 0.484375 loss: 2.0305676460266113\n",
      "epoch: 3 batch: 29 train batch accuracy: 0.3125 loss: 2.5821189880371094\n",
      "epoch: 3 batch: 30 train batch accuracy: 0.328125 loss: 2.4377779960632324\n",
      "epoch: 3 batch: 31 train batch accuracy: 0.359375 loss: 2.3073854446411133\n",
      "epoch: 3 batch: 32 train batch accuracy: 0.546875 loss: 1.9025696516036987\n",
      "epoch: 3 batch: 33 train batch accuracy: 0.328125 loss: 2.797354221343994\n",
      "epoch: 3 batch: 34 train batch accuracy: 0.375 loss: 2.145219087600708\n",
      "epoch: 3 batch: 35 train batch accuracy: 0.453125 loss: 2.157194137573242\n",
      "epoch: 3 batch: 36 train batch accuracy: 0.390625 loss: 2.147242546081543\n",
      "epoch: 3 batch: 37 train batch accuracy: 0.421875 loss: 2.0950517654418945\n",
      "epoch: 3 batch: 38 train batch accuracy: 0.359375 loss: 2.1279141902923584\n",
      "epoch: 3 batch: 39 train batch accuracy: 0.28125 loss: 2.3787429332733154\n",
      "epoch: 3 batch: 40 train batch accuracy: 0.40625 loss: 1.9759635925292969\n",
      "epoch: 3 batch: 41 train batch accuracy: 0.359375 loss: 2.0661516189575195\n",
      "epoch: 3 batch: 42 train batch accuracy: 0.390625 loss: 2.1748225688934326\n",
      "epoch: 3 batch: 43 train batch accuracy: 0.359375 loss: 2.3600242137908936\n",
      "epoch: 3 batch: 44 train batch accuracy: 0.34375 loss: 2.2480382919311523\n",
      "epoch: 3 batch: 45 train batch accuracy: 0.4375 loss: 2.143315315246582\n",
      "epoch: 3 batch: 46 train batch accuracy: 0.328125 loss: 2.425065517425537\n",
      "epoch: 3 batch: 47 train batch accuracy: 0.4375 loss: 2.3294448852539062\n",
      "epoch: 3 batch: 48 train batch accuracy: 0.453125 loss: 2.1645641326904297\n",
      "epoch: 3 batch: 49 train batch accuracy: 0.421875 loss: 2.0842185020446777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 batch: 50 train batch accuracy: 0.5 loss: 1.9927890300750732\n",
      "epoch: 3 batch: 51 train batch accuracy: 0.3125 loss: 2.2092509269714355\n",
      "epoch: 3 batch: 52 train batch accuracy: 0.390625 loss: 2.373884677886963\n",
      "epoch: 3 batch: 53 train batch accuracy: 0.4375 loss: 2.0283703804016113\n",
      "epoch: 3 batch: 54 train batch accuracy: 0.515625 loss: 1.7471423149108887\n",
      "epoch: 3 batch: 55 train batch accuracy: 0.453125 loss: 2.0578789710998535\n",
      "epoch: 3 batch: 56 train batch accuracy: 0.46875 loss: 2.176562786102295\n",
      "epoch: 3 batch: 57 train batch accuracy: 0.484375 loss: 2.095160484313965\n",
      "epoch: 3 batch: 58 train batch accuracy: 0.421875 loss: 2.419982433319092\n",
      "epoch: 3 batch: 59 train batch accuracy: 0.390625 loss: 2.3381826877593994\n",
      "epoch: 3 batch: 60 train batch accuracy: 0.453125 loss: 1.9605984687805176\n",
      "epoch: 3 batch: 61 train batch accuracy: 0.484375 loss: 1.9472193717956543\n",
      "epoch: 3 batch: 62 train batch accuracy: 0.515625 loss: 1.8691887855529785\n",
      "epoch: 3 batch: 63 train batch accuracy: 0.484375 loss: 1.962996006011963\n",
      "epoch: 3 batch: 64 train batch accuracy: 0.390625 loss: 2.170684814453125\n",
      "epoch: 3 batch: 65 train batch accuracy: 0.421875 loss: 1.9084091186523438\n",
      "epoch: 3 batch: 66 train batch accuracy: 0.5 loss: 2.0709640979766846\n",
      "epoch: 3 batch: 67 train batch accuracy: 0.484375 loss: 2.137995719909668\n",
      "epoch: 3 batch: 68 train batch accuracy: 0.46875 loss: 1.9619507789611816\n",
      "epoch: 3 batch: 69 train batch accuracy: 0.578125 loss: 1.653346300125122\n",
      "epoch: 3 batch: 70 train batch accuracy: 0.53125 loss: 1.9056146144866943\n",
      "epoch: 3 batch: 71 train batch accuracy: 0.5 loss: 1.9655168056488037\n",
      "epoch: 3 batch: 72 train batch accuracy: 0.515625 loss: 1.8660504817962646\n",
      "epoch: 3 batch: 73 train batch accuracy: 0.40625 loss: 2.1990861892700195\n",
      "epoch: 3 batch: 74 train batch accuracy: 0.46875 loss: 1.880004644393921\n",
      "epoch: 3 batch: 75 train batch accuracy: 0.5 loss: 1.7594040632247925\n",
      "epoch: 3 batch: 76 train batch accuracy: 0.4375 loss: 1.8985967636108398\n",
      "epoch: 3 batch: 77 train batch accuracy: 0.484375 loss: 1.5984015464782715\n",
      "epoch: 3 batch: 78 train batch accuracy: 0.46875 loss: 1.852807641029358\n",
      "epoch: 3 batch: 79 train batch accuracy: 0.484375 loss: 1.9137427806854248\n",
      "epoch: 3 batch: 80 train batch accuracy: 0.375 loss: 2.0373570919036865\n",
      "epoch: 3 batch: 81 train batch accuracy: 0.4375 loss: 2.2078604698181152\n",
      "epoch: 3 batch: 82 train batch accuracy: 0.484375 loss: 1.9184021949768066\n",
      "epoch: 3 batch: 83 train batch accuracy: 0.453125 loss: 2.0259008407592773\n",
      "epoch: 3 batch: 84 train batch accuracy: 0.421875 loss: 1.9738291501998901\n",
      "epoch: 3 batch: 85 train batch accuracy: 0.421875 loss: 2.0452895164489746\n",
      "epoch: 3 batch: 86 train batch accuracy: 0.484375 loss: 1.7356185913085938\n",
      "epoch: 3 batch: 87 train batch accuracy: 0.40625 loss: 2.252559185028076\n",
      "epoch: 3 batch: 88 train batch accuracy: 0.5 loss: 1.8705781698226929\n",
      "epoch: 3 batch: 89 train batch accuracy: 0.4375 loss: 1.8407715559005737\n",
      "epoch: 3 batch: 90 train batch accuracy: 0.421875 loss: 2.285311222076416\n",
      "epoch: 3 batch: 91 train batch accuracy: 0.421875 loss: 2.174349784851074\n",
      "epoch: 3 batch: 92 train batch accuracy: 0.515625 loss: 1.9673404693603516\n",
      "epoch: 3 batch: 93 train batch accuracy: 0.4375 loss: 1.973976969718933\n",
      "Epoch 4/1000  average cost 2.159354202\n",
      "Epoch 4/1000  Test cost 2.502544403\n",
      "准确率: 0.375\n",
      "Epoch 4/1000  模型保存成功\n",
      "epoch: 4 batch: 0 train batch accuracy: 0.421875 loss: 2.0544815063476562\n",
      "epoch: 4 batch: 1 train batch accuracy: 0.421875 loss: 1.9380806684494019\n",
      "epoch: 4 batch: 2 train batch accuracy: 0.53125 loss: 1.7225756645202637\n",
      "epoch: 4 batch: 3 train batch accuracy: 0.46875 loss: 1.922155499458313\n",
      "epoch: 4 batch: 4 train batch accuracy: 0.4375 loss: 1.8934028148651123\n",
      "epoch: 4 batch: 5 train batch accuracy: 0.46875 loss: 1.98679780960083\n",
      "epoch: 4 batch: 6 train batch accuracy: 0.484375 loss: 1.763896107673645\n",
      "epoch: 4 batch: 7 train batch accuracy: 0.453125 loss: 2.030071258544922\n",
      "epoch: 4 batch: 8 train batch accuracy: 0.5 loss: 1.9613089561462402\n",
      "epoch: 4 batch: 9 train batch accuracy: 0.484375 loss: 1.9606781005859375\n",
      "epoch: 4 batch: 10 train batch accuracy: 0.421875 loss: 2.195402145385742\n",
      "epoch: 4 batch: 11 train batch accuracy: 0.609375 loss: 1.528548002243042\n",
      "epoch: 4 batch: 12 train batch accuracy: 0.53125 loss: 1.7212775945663452\n",
      "epoch: 4 batch: 13 train batch accuracy: 0.328125 loss: 2.019829750061035\n",
      "epoch: 4 batch: 14 train batch accuracy: 0.453125 loss: 1.6540865898132324\n",
      "epoch: 4 batch: 15 train batch accuracy: 0.46875 loss: 1.7913262844085693\n",
      "epoch: 4 batch: 16 train batch accuracy: 0.40625 loss: 2.23262882232666\n",
      "epoch: 4 batch: 17 train batch accuracy: 0.609375 loss: 1.5331676006317139\n",
      "epoch: 4 batch: 18 train batch accuracy: 0.453125 loss: 1.9275873899459839\n",
      "epoch: 4 batch: 19 train batch accuracy: 0.484375 loss: 1.812651515007019\n",
      "epoch: 4 batch: 20 train batch accuracy: 0.421875 loss: 1.9330600500106812\n",
      "epoch: 4 batch: 21 train batch accuracy: 0.421875 loss: 1.9940041303634644\n",
      "epoch: 4 batch: 22 train batch accuracy: 0.453125 loss: 2.045736074447632\n",
      "epoch: 4 batch: 23 train batch accuracy: 0.53125 loss: 1.6950724124908447\n",
      "epoch: 4 batch: 24 train batch accuracy: 0.578125 loss: 1.4391816854476929\n",
      "epoch: 4 batch: 25 train batch accuracy: 0.4375 loss: 2.0646116733551025\n",
      "epoch: 4 batch: 26 train batch accuracy: 0.5625 loss: 1.4790723323822021\n",
      "epoch: 4 batch: 27 train batch accuracy: 0.46875 loss: 1.8317701816558838\n",
      "epoch: 4 batch: 28 train batch accuracy: 0.53125 loss: 1.8526064157485962\n",
      "epoch: 4 batch: 29 train batch accuracy: 0.421875 loss: 1.8822052478790283\n",
      "epoch: 4 batch: 30 train batch accuracy: 0.546875 loss: 1.770291805267334\n",
      "epoch: 4 batch: 31 train batch accuracy: 0.484375 loss: 1.9615633487701416\n",
      "epoch: 4 batch: 32 train batch accuracy: 0.53125 loss: 1.929560899734497\n",
      "epoch: 4 batch: 33 train batch accuracy: 0.421875 loss: 2.062833547592163\n",
      "epoch: 4 batch: 34 train batch accuracy: 0.421875 loss: 1.7818074226379395\n",
      "epoch: 4 batch: 35 train batch accuracy: 0.515625 loss: 1.8274750709533691\n",
      "epoch: 4 batch: 36 train batch accuracy: 0.515625 loss: 1.7093279361724854\n",
      "epoch: 4 batch: 37 train batch accuracy: 0.578125 loss: 1.5802935361862183\n",
      "epoch: 4 batch: 38 train batch accuracy: 0.515625 loss: 1.6777311563491821\n",
      "epoch: 4 batch: 39 train batch accuracy: 0.515625 loss: 1.5897181034088135\n",
      "epoch: 4 batch: 40 train batch accuracy: 0.546875 loss: 1.6855422258377075\n",
      "epoch: 4 batch: 41 train batch accuracy: 0.46875 loss: 1.7748335599899292\n",
      "epoch: 4 batch: 42 train batch accuracy: 0.515625 loss: 1.7261841297149658\n",
      "epoch: 4 batch: 43 train batch accuracy: 0.5625 loss: 1.7157090902328491\n",
      "epoch: 4 batch: 44 train batch accuracy: 0.578125 loss: 1.6137491464614868\n",
      "epoch: 4 batch: 45 train batch accuracy: 0.59375 loss: 1.4655213356018066\n",
      "epoch: 4 batch: 46 train batch accuracy: 0.53125 loss: 1.709641456604004\n",
      "epoch: 4 batch: 47 train batch accuracy: 0.484375 loss: 1.8407903909683228\n",
      "epoch: 4 batch: 48 train batch accuracy: 0.53125 loss: 1.6219031810760498\n",
      "epoch: 4 batch: 49 train batch accuracy: 0.46875 loss: 1.8754833936691284\n",
      "epoch: 4 batch: 50 train batch accuracy: 0.578125 loss: 1.6536047458648682\n",
      "epoch: 4 batch: 51 train batch accuracy: 0.5625 loss: 1.3546829223632812\n",
      "epoch: 4 batch: 52 train batch accuracy: 0.5 loss: 1.8714635372161865\n",
      "epoch: 4 batch: 53 train batch accuracy: 0.4375 loss: 1.904863715171814\n",
      "epoch: 4 batch: 54 train batch accuracy: 0.484375 loss: 1.601580023765564\n",
      "epoch: 4 batch: 55 train batch accuracy: 0.578125 loss: 1.6083836555480957\n",
      "epoch: 4 batch: 56 train batch accuracy: 0.59375 loss: 1.4486429691314697\n",
      "epoch: 4 batch: 57 train batch accuracy: 0.46875 loss: 1.8176807165145874\n",
      "epoch: 4 batch: 58 train batch accuracy: 0.453125 loss: 2.0597410202026367\n",
      "epoch: 4 batch: 59 train batch accuracy: 0.5 loss: 1.8407200574874878\n",
      "epoch: 4 batch: 60 train batch accuracy: 0.59375 loss: 1.5031647682189941\n",
      "epoch: 4 batch: 61 train batch accuracy: 0.609375 loss: 1.5378565788269043\n",
      "epoch: 4 batch: 62 train batch accuracy: 0.5625 loss: 1.7517882585525513\n",
      "epoch: 4 batch: 63 train batch accuracy: 0.4375 loss: 1.7417857646942139\n",
      "epoch: 4 batch: 64 train batch accuracy: 0.59375 loss: 1.6764295101165771\n",
      "epoch: 4 batch: 65 train batch accuracy: 0.546875 loss: 1.3592379093170166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 batch: 66 train batch accuracy: 0.515625 loss: 1.6384446620941162\n",
      "epoch: 4 batch: 67 train batch accuracy: 0.609375 loss: 1.4084529876708984\n",
      "epoch: 4 batch: 68 train batch accuracy: 0.515625 loss: 1.6832406520843506\n",
      "epoch: 4 batch: 69 train batch accuracy: 0.625 loss: 1.4368840456008911\n",
      "epoch: 4 batch: 70 train batch accuracy: 0.46875 loss: 1.9572594165802002\n",
      "epoch: 4 batch: 71 train batch accuracy: 0.46875 loss: 1.7105238437652588\n",
      "epoch: 4 batch: 72 train batch accuracy: 0.40625 loss: 1.8386842012405396\n",
      "epoch: 4 batch: 73 train batch accuracy: 0.59375 loss: 1.5296895503997803\n",
      "epoch: 4 batch: 74 train batch accuracy: 0.5 loss: 1.7907350063323975\n",
      "epoch: 4 batch: 75 train batch accuracy: 0.59375 loss: 1.2831971645355225\n",
      "epoch: 4 batch: 76 train batch accuracy: 0.484375 loss: 1.64376699924469\n",
      "epoch: 4 batch: 77 train batch accuracy: 0.5 loss: 1.5297796726226807\n",
      "epoch: 4 batch: 78 train batch accuracy: 0.484375 loss: 1.9130933284759521\n",
      "epoch: 4 batch: 79 train batch accuracy: 0.609375 loss: 1.3976083993911743\n",
      "epoch: 4 batch: 80 train batch accuracy: 0.453125 loss: 1.7954931259155273\n",
      "epoch: 4 batch: 81 train batch accuracy: 0.59375 loss: 1.4384934902191162\n",
      "epoch: 4 batch: 82 train batch accuracy: 0.609375 loss: 1.2915939092636108\n",
      "epoch: 4 batch: 83 train batch accuracy: 0.5625 loss: 1.5589823722839355\n",
      "epoch: 4 batch: 84 train batch accuracy: 0.5625 loss: 1.6672711372375488\n",
      "epoch: 4 batch: 85 train batch accuracy: 0.515625 loss: 1.4813356399536133\n",
      "epoch: 4 batch: 86 train batch accuracy: 0.5 loss: 2.050049066543579\n",
      "epoch: 4 batch: 87 train batch accuracy: 0.453125 loss: 1.7117722034454346\n",
      "epoch: 4 batch: 88 train batch accuracy: 0.609375 loss: 1.345801830291748\n",
      "epoch: 4 batch: 89 train batch accuracy: 0.578125 loss: 1.2024484872817993\n",
      "epoch: 4 batch: 90 train batch accuracy: 0.453125 loss: 2.088590621948242\n",
      "epoch: 4 batch: 91 train batch accuracy: 0.53125 loss: 1.7229530811309814\n",
      "epoch: 4 batch: 92 train batch accuracy: 0.65625 loss: 1.2391560077667236\n",
      "epoch: 4 batch: 93 train batch accuracy: 0.578125 loss: 1.3464351892471313\n",
      "Epoch 5/1000  average cost 1.725751035\n",
      "Epoch 5/1000  Test cost 2.446657181\n",
      "准确率: 0.375\n",
      "Epoch 5/1000  模型保存成功\n",
      "epoch: 5 batch: 0 train batch accuracy: 0.65625 loss: 1.3435685634613037\n",
      "epoch: 5 batch: 1 train batch accuracy: 0.5625 loss: 1.483638048171997\n",
      "epoch: 5 batch: 2 train batch accuracy: 0.53125 loss: 1.4573094844818115\n",
      "epoch: 5 batch: 3 train batch accuracy: 0.515625 loss: 1.654236078262329\n",
      "epoch: 5 batch: 4 train batch accuracy: 0.53125 loss: 1.5376144647598267\n",
      "epoch: 5 batch: 5 train batch accuracy: 0.65625 loss: 1.4309391975402832\n",
      "epoch: 5 batch: 6 train batch accuracy: 0.609375 loss: 1.2847598791122437\n",
      "epoch: 5 batch: 7 train batch accuracy: 0.484375 loss: 1.9374853372573853\n",
      "epoch: 5 batch: 8 train batch accuracy: 0.515625 loss: 1.8737415075302124\n",
      "epoch: 5 batch: 9 train batch accuracy: 0.5625 loss: 1.7526514530181885\n",
      "epoch: 5 batch: 10 train batch accuracy: 0.484375 loss: 1.7424172163009644\n",
      "epoch: 5 batch: 11 train batch accuracy: 0.5 loss: 1.894303798675537\n",
      "epoch: 5 batch: 12 train batch accuracy: 0.484375 loss: 1.6878981590270996\n",
      "epoch: 5 batch: 13 train batch accuracy: 0.59375 loss: 1.4587335586547852\n",
      "epoch: 5 batch: 14 train batch accuracy: 0.5625 loss: 1.513079285621643\n",
      "epoch: 5 batch: 15 train batch accuracy: 0.625 loss: 1.214491605758667\n",
      "epoch: 5 batch: 16 train batch accuracy: 0.59375 loss: 1.401172161102295\n",
      "epoch: 5 batch: 17 train batch accuracy: 0.609375 loss: 1.5268707275390625\n",
      "epoch: 5 batch: 18 train batch accuracy: 0.484375 loss: 1.5839811563491821\n",
      "epoch: 5 batch: 19 train batch accuracy: 0.46875 loss: 1.8227741718292236\n",
      "epoch: 5 batch: 20 train batch accuracy: 0.53125 loss: 1.5308164358139038\n",
      "epoch: 5 batch: 21 train batch accuracy: 0.59375 loss: 1.4939908981323242\n",
      "epoch: 5 batch: 22 train batch accuracy: 0.640625 loss: 1.4199885129928589\n",
      "epoch: 5 batch: 23 train batch accuracy: 0.578125 loss: 1.4684233665466309\n",
      "epoch: 5 batch: 24 train batch accuracy: 0.546875 loss: 1.436272144317627\n",
      "epoch: 5 batch: 25 train batch accuracy: 0.625 loss: 1.3606517314910889\n",
      "epoch: 5 batch: 26 train batch accuracy: 0.515625 loss: 1.6835964918136597\n",
      "epoch: 5 batch: 27 train batch accuracy: 0.53125 loss: 1.7036283016204834\n",
      "epoch: 5 batch: 28 train batch accuracy: 0.59375 loss: 1.2710176706314087\n",
      "epoch: 5 batch: 29 train batch accuracy: 0.546875 loss: 1.5169157981872559\n",
      "epoch: 5 batch: 30 train batch accuracy: 0.578125 loss: 1.5552887916564941\n",
      "epoch: 5 batch: 31 train batch accuracy: 0.53125 loss: 1.8567973375320435\n",
      "epoch: 5 batch: 32 train batch accuracy: 0.546875 loss: 1.8911590576171875\n",
      "epoch: 5 batch: 33 train batch accuracy: 0.65625 loss: 1.2473039627075195\n",
      "epoch: 5 batch: 34 train batch accuracy: 0.578125 loss: 1.3864965438842773\n",
      "epoch: 5 batch: 35 train batch accuracy: 0.578125 loss: 1.455910325050354\n",
      "epoch: 5 batch: 36 train batch accuracy: 0.578125 loss: 1.4222285747528076\n",
      "epoch: 5 batch: 37 train batch accuracy: 0.46875 loss: 1.9779387712478638\n",
      "epoch: 5 batch: 38 train batch accuracy: 0.4375 loss: 1.7943775653839111\n",
      "epoch: 5 batch: 39 train batch accuracy: 0.546875 loss: 1.5024913549423218\n",
      "epoch: 5 batch: 40 train batch accuracy: 0.578125 loss: 1.314590573310852\n",
      "epoch: 5 batch: 41 train batch accuracy: 0.59375 loss: 1.44455885887146\n",
      "epoch: 5 batch: 42 train batch accuracy: 0.578125 loss: 1.4882328510284424\n",
      "epoch: 5 batch: 43 train batch accuracy: 0.625 loss: 1.3261884450912476\n",
      "epoch: 5 batch: 44 train batch accuracy: 0.53125 loss: 1.6619179248809814\n",
      "epoch: 5 batch: 45 train batch accuracy: 0.640625 loss: 1.3853449821472168\n",
      "epoch: 5 batch: 46 train batch accuracy: 0.703125 loss: 1.2088390588760376\n",
      "epoch: 5 batch: 47 train batch accuracy: 0.625 loss: 1.383737325668335\n",
      "epoch: 5 batch: 48 train batch accuracy: 0.734375 loss: 1.1906116008758545\n",
      "epoch: 5 batch: 49 train batch accuracy: 0.5625 loss: 1.333339810371399\n",
      "epoch: 5 batch: 50 train batch accuracy: 0.546875 loss: 1.4186208248138428\n",
      "epoch: 5 batch: 51 train batch accuracy: 0.671875 loss: 1.1239397525787354\n",
      "epoch: 5 batch: 52 train batch accuracy: 0.578125 loss: 1.3212828636169434\n",
      "epoch: 5 batch: 53 train batch accuracy: 0.59375 loss: 1.3870761394500732\n",
      "epoch: 5 batch: 54 train batch accuracy: 0.609375 loss: 1.266404390335083\n",
      "epoch: 5 batch: 55 train batch accuracy: 0.578125 loss: 1.5342451333999634\n",
      "epoch: 5 batch: 56 train batch accuracy: 0.609375 loss: 1.3361880779266357\n",
      "epoch: 5 batch: 57 train batch accuracy: 0.640625 loss: 1.2566180229187012\n",
      "epoch: 5 batch: 58 train batch accuracy: 0.671875 loss: 1.354210376739502\n",
      "epoch: 5 batch: 59 train batch accuracy: 0.5625 loss: 1.3344285488128662\n",
      "epoch: 5 batch: 60 train batch accuracy: 0.703125 loss: 1.1956617832183838\n",
      "epoch: 5 batch: 61 train batch accuracy: 0.5 loss: 1.5291738510131836\n",
      "epoch: 5 batch: 62 train batch accuracy: 0.546875 loss: 1.5357437133789062\n",
      "epoch: 5 batch: 63 train batch accuracy: 0.578125 loss: 1.413198471069336\n",
      "epoch: 5 batch: 64 train batch accuracy: 0.59375 loss: 1.3463237285614014\n",
      "epoch: 5 batch: 65 train batch accuracy: 0.65625 loss: 1.1557281017303467\n",
      "epoch: 5 batch: 66 train batch accuracy: 0.578125 loss: 1.3847377300262451\n",
      "epoch: 5 batch: 67 train batch accuracy: 0.625 loss: 1.2604702711105347\n",
      "epoch: 5 batch: 68 train batch accuracy: 0.5625 loss: 1.3937872648239136\n",
      "epoch: 5 batch: 69 train batch accuracy: 0.59375 loss: 1.3227567672729492\n",
      "epoch: 5 batch: 70 train batch accuracy: 0.5625 loss: 1.5684893131256104\n",
      "epoch: 5 batch: 71 train batch accuracy: 0.609375 loss: 1.1550495624542236\n",
      "epoch: 5 batch: 72 train batch accuracy: 0.578125 loss: 1.4097455739974976\n",
      "epoch: 5 batch: 73 train batch accuracy: 0.578125 loss: 1.6155219078063965\n",
      "epoch: 5 batch: 74 train batch accuracy: 0.5625 loss: 1.3682942390441895\n",
      "epoch: 5 batch: 75 train batch accuracy: 0.609375 loss: 1.107111930847168\n",
      "epoch: 5 batch: 76 train batch accuracy: 0.65625 loss: 1.1311343908309937\n",
      "epoch: 5 batch: 77 train batch accuracy: 0.546875 loss: 1.3461081981658936\n",
      "epoch: 5 batch: 78 train batch accuracy: 0.609375 loss: 1.4349634647369385\n",
      "epoch: 5 batch: 79 train batch accuracy: 0.6875 loss: 1.0126919746398926\n",
      "epoch: 5 batch: 80 train batch accuracy: 0.65625 loss: 1.0435782670974731\n",
      "epoch: 5 batch: 81 train batch accuracy: 0.5625 loss: 1.529515027999878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 batch: 82 train batch accuracy: 0.625 loss: 1.2643120288848877\n",
      "epoch: 5 batch: 83 train batch accuracy: 0.578125 loss: 1.5112295150756836\n",
      "epoch: 5 batch: 84 train batch accuracy: 0.71875 loss: 1.2090742588043213\n",
      "epoch: 5 batch: 85 train batch accuracy: 0.640625 loss: 1.327030897140503\n",
      "epoch: 5 batch: 86 train batch accuracy: 0.703125 loss: 1.1772851943969727\n",
      "epoch: 5 batch: 87 train batch accuracy: 0.640625 loss: 1.3571268320083618\n",
      "epoch: 5 batch: 88 train batch accuracy: 0.578125 loss: 1.4818394184112549\n",
      "epoch: 5 batch: 89 train batch accuracy: 0.5625 loss: 1.6117873191833496\n",
      "epoch: 5 batch: 90 train batch accuracy: 0.671875 loss: 1.1722543239593506\n",
      "epoch: 5 batch: 91 train batch accuracy: 0.515625 loss: 1.7913906574249268\n",
      "epoch: 5 batch: 92 train batch accuracy: 0.609375 loss: 1.268625020980835\n",
      "epoch: 5 batch: 93 train batch accuracy: 0.640625 loss: 1.3058539628982544\n",
      "Epoch 6/1000  average cost 1.440265213\n",
      "Epoch 6/1000  Test cost 1.707000971\n",
      "准确率: 0.625\n",
      "Epoch 6/1000  模型保存成功\n",
      "epoch: 6 batch: 0 train batch accuracy: 0.6875 loss: 1.1308443546295166\n",
      "epoch: 6 batch: 1 train batch accuracy: 0.625 loss: 1.3523743152618408\n",
      "epoch: 6 batch: 2 train batch accuracy: 0.625 loss: 1.243546724319458\n",
      "epoch: 6 batch: 3 train batch accuracy: 0.625 loss: 1.353280782699585\n",
      "epoch: 6 batch: 4 train batch accuracy: 0.65625 loss: 1.1002333164215088\n",
      "epoch: 6 batch: 5 train batch accuracy: 0.546875 loss: 1.4747462272644043\n",
      "epoch: 6 batch: 6 train batch accuracy: 0.5 loss: 1.536885380744934\n",
      "epoch: 6 batch: 7 train batch accuracy: 0.671875 loss: 1.032597303390503\n",
      "epoch: 6 batch: 8 train batch accuracy: 0.703125 loss: 1.1592628955841064\n",
      "epoch: 6 batch: 9 train batch accuracy: 0.6875 loss: 1.1574516296386719\n",
      "epoch: 6 batch: 10 train batch accuracy: 0.578125 loss: 1.4817235469818115\n",
      "epoch: 6 batch: 11 train batch accuracy: 0.71875 loss: 1.1878957748413086\n",
      "epoch: 6 batch: 12 train batch accuracy: 0.609375 loss: 1.4611066579818726\n",
      "epoch: 6 batch: 13 train batch accuracy: 0.703125 loss: 0.9816422462463379\n",
      "epoch: 6 batch: 14 train batch accuracy: 0.734375 loss: 1.0307799577713013\n",
      "epoch: 6 batch: 15 train batch accuracy: 0.640625 loss: 1.2469180822372437\n",
      "epoch: 6 batch: 16 train batch accuracy: 0.5625 loss: 1.1871590614318848\n",
      "epoch: 6 batch: 17 train batch accuracy: 0.578125 loss: 1.5284757614135742\n",
      "epoch: 6 batch: 18 train batch accuracy: 0.65625 loss: 1.1368329524993896\n",
      "epoch: 6 batch: 19 train batch accuracy: 0.578125 loss: 1.3538037538528442\n",
      "epoch: 6 batch: 20 train batch accuracy: 0.6875 loss: 0.9944075345993042\n",
      "epoch: 6 batch: 21 train batch accuracy: 0.765625 loss: 1.0510246753692627\n",
      "epoch: 6 batch: 22 train batch accuracy: 0.71875 loss: 0.9279883503913879\n",
      "epoch: 6 batch: 23 train batch accuracy: 0.6875 loss: 1.2032655477523804\n",
      "epoch: 6 batch: 24 train batch accuracy: 0.6875 loss: 1.1687085628509521\n",
      "epoch: 6 batch: 25 train batch accuracy: 0.59375 loss: 1.246248483657837\n",
      "epoch: 6 batch: 26 train batch accuracy: 0.640625 loss: 1.347551941871643\n",
      "epoch: 6 batch: 27 train batch accuracy: 0.703125 loss: 1.1605100631713867\n",
      "epoch: 6 batch: 28 train batch accuracy: 0.59375 loss: 1.3510375022888184\n",
      "epoch: 6 batch: 29 train batch accuracy: 0.515625 loss: 1.4469046592712402\n",
      "epoch: 6 batch: 30 train batch accuracy: 0.578125 loss: 1.6131091117858887\n",
      "epoch: 6 batch: 31 train batch accuracy: 0.609375 loss: 1.2931041717529297\n",
      "epoch: 6 batch: 32 train batch accuracy: 0.671875 loss: 1.1561847925186157\n",
      "epoch: 6 batch: 33 train batch accuracy: 0.515625 loss: 1.7300816774368286\n",
      "epoch: 6 batch: 34 train batch accuracy: 0.625 loss: 1.4514870643615723\n",
      "epoch: 6 batch: 35 train batch accuracy: 0.671875 loss: 1.091576337814331\n",
      "epoch: 6 batch: 36 train batch accuracy: 0.484375 loss: 1.6153197288513184\n",
      "epoch: 6 batch: 37 train batch accuracy: 0.609375 loss: 1.4146039485931396\n",
      "epoch: 6 batch: 38 train batch accuracy: 0.71875 loss: 1.4695152044296265\n",
      "epoch: 6 batch: 39 train batch accuracy: 0.640625 loss: 1.2691869735717773\n",
      "epoch: 6 batch: 40 train batch accuracy: 0.671875 loss: 1.0840320587158203\n",
      "epoch: 6 batch: 41 train batch accuracy: 0.65625 loss: 1.0033881664276123\n",
      "epoch: 6 batch: 42 train batch accuracy: 0.71875 loss: 0.9686384201049805\n",
      "epoch: 6 batch: 43 train batch accuracy: 0.671875 loss: 1.1317943334579468\n",
      "epoch: 6 batch: 44 train batch accuracy: 0.609375 loss: 1.4176995754241943\n",
      "epoch: 6 batch: 45 train batch accuracy: 0.65625 loss: 1.092484951019287\n",
      "epoch: 6 batch: 46 train batch accuracy: 0.734375 loss: 1.0660514831542969\n",
      "epoch: 6 batch: 47 train batch accuracy: 0.6875 loss: 1.0087215900421143\n",
      "epoch: 6 batch: 48 train batch accuracy: 0.59375 loss: 1.1619690656661987\n",
      "epoch: 6 batch: 49 train batch accuracy: 0.671875 loss: 1.1766393184661865\n",
      "epoch: 6 batch: 50 train batch accuracy: 0.578125 loss: 1.3003917932510376\n",
      "epoch: 6 batch: 51 train batch accuracy: 0.703125 loss: 1.1814463138580322\n",
      "epoch: 6 batch: 52 train batch accuracy: 0.578125 loss: 1.5813413858413696\n",
      "epoch: 6 batch: 53 train batch accuracy: 0.609375 loss: 1.513155460357666\n",
      "epoch: 6 batch: 54 train batch accuracy: 0.65625 loss: 1.1197787523269653\n",
      "epoch: 6 batch: 55 train batch accuracy: 0.609375 loss: 1.4058952331542969\n",
      "epoch: 6 batch: 56 train batch accuracy: 0.6875 loss: 1.224266529083252\n",
      "epoch: 6 batch: 57 train batch accuracy: 0.5625 loss: 1.4078729152679443\n",
      "epoch: 6 batch: 58 train batch accuracy: 0.625 loss: 1.1822322607040405\n",
      "epoch: 6 batch: 59 train batch accuracy: 0.671875 loss: 1.0908479690551758\n",
      "epoch: 6 batch: 60 train batch accuracy: 0.609375 loss: 1.3321844339370728\n",
      "epoch: 6 batch: 61 train batch accuracy: 0.640625 loss: 1.0498614311218262\n",
      "epoch: 6 batch: 62 train batch accuracy: 0.5625 loss: 1.5129539966583252\n",
      "epoch: 6 batch: 63 train batch accuracy: 0.625 loss: 1.2427531480789185\n",
      "epoch: 6 batch: 64 train batch accuracy: 0.703125 loss: 1.058152675628662\n",
      "epoch: 6 batch: 65 train batch accuracy: 0.546875 loss: 1.4107542037963867\n",
      "epoch: 6 batch: 66 train batch accuracy: 0.703125 loss: 1.1299831867218018\n",
      "epoch: 6 batch: 67 train batch accuracy: 0.578125 loss: 1.50211501121521\n",
      "epoch: 6 batch: 68 train batch accuracy: 0.6875 loss: 1.0488715171813965\n",
      "epoch: 6 batch: 69 train batch accuracy: 0.71875 loss: 1.0520625114440918\n",
      "epoch: 6 batch: 70 train batch accuracy: 0.625 loss: 1.0670148134231567\n",
      "epoch: 6 batch: 71 train batch accuracy: 0.703125 loss: 0.981630265712738\n",
      "epoch: 6 batch: 72 train batch accuracy: 0.75 loss: 1.2019908428192139\n",
      "epoch: 6 batch: 73 train batch accuracy: 0.6875 loss: 1.134399652481079\n",
      "epoch: 6 batch: 74 train batch accuracy: 0.640625 loss: 1.1248778104782104\n",
      "epoch: 6 batch: 75 train batch accuracy: 0.71875 loss: 1.2880053520202637\n",
      "epoch: 6 batch: 76 train batch accuracy: 0.640625 loss: 1.2509660720825195\n",
      "epoch: 6 batch: 77 train batch accuracy: 0.703125 loss: 1.0385545492172241\n",
      "epoch: 6 batch: 78 train batch accuracy: 0.6875 loss: 1.0187726020812988\n",
      "epoch: 6 batch: 79 train batch accuracy: 0.734375 loss: 1.0592174530029297\n",
      "epoch: 6 batch: 80 train batch accuracy: 0.734375 loss: 0.8478058576583862\n",
      "epoch: 6 batch: 81 train batch accuracy: 0.609375 loss: 1.275005578994751\n",
      "epoch: 6 batch: 82 train batch accuracy: 0.703125 loss: 1.0130122900009155\n",
      "epoch: 6 batch: 83 train batch accuracy: 0.75 loss: 0.9842194318771362\n",
      "epoch: 6 batch: 84 train batch accuracy: 0.609375 loss: 1.1613237857818604\n",
      "epoch: 6 batch: 85 train batch accuracy: 0.625 loss: 1.1769940853118896\n",
      "epoch: 6 batch: 86 train batch accuracy: 0.65625 loss: 1.1736377477645874\n",
      "epoch: 6 batch: 87 train batch accuracy: 0.71875 loss: 1.1515358686447144\n",
      "epoch: 6 batch: 88 train batch accuracy: 0.703125 loss: 1.1472368240356445\n",
      "epoch: 6 batch: 89 train batch accuracy: 0.640625 loss: 1.1463510990142822\n",
      "epoch: 6 batch: 90 train batch accuracy: 0.578125 loss: 1.3345551490783691\n",
      "epoch: 6 batch: 91 train batch accuracy: 0.671875 loss: 1.03617525100708\n",
      "epoch: 6 batch: 92 train batch accuracy: 0.625 loss: 1.1847763061523438\n",
      "epoch: 6 batch: 93 train batch accuracy: 0.703125 loss: 0.9514556527137756\n",
      "Epoch 7/1000  average cost 1.216459905\n",
      "Epoch 7/1000  Test cost 1.552583814\n",
      "准确率: 0.546875\n",
      "Epoch 7/1000  模型保存成功\n",
      "epoch: 7 batch: 0 train batch accuracy: 0.765625 loss: 0.839572548866272\n",
      "epoch: 7 batch: 1 train batch accuracy: 0.765625 loss: 0.8144807815551758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 batch: 2 train batch accuracy: 0.703125 loss: 0.9530091285705566\n",
      "epoch: 7 batch: 3 train batch accuracy: 0.703125 loss: 1.2163915634155273\n",
      "epoch: 7 batch: 4 train batch accuracy: 0.65625 loss: 1.1736464500427246\n",
      "epoch: 7 batch: 5 train batch accuracy: 0.65625 loss: 1.230669617652893\n",
      "epoch: 7 batch: 6 train batch accuracy: 0.65625 loss: 1.2605271339416504\n",
      "epoch: 7 batch: 7 train batch accuracy: 0.796875 loss: 0.8835014700889587\n",
      "epoch: 7 batch: 8 train batch accuracy: 0.703125 loss: 1.0596872568130493\n",
      "epoch: 7 batch: 9 train batch accuracy: 0.65625 loss: 0.9664751291275024\n",
      "epoch: 7 batch: 10 train batch accuracy: 0.671875 loss: 1.081719160079956\n",
      "epoch: 7 batch: 11 train batch accuracy: 0.65625 loss: 1.2114559412002563\n",
      "epoch: 7 batch: 12 train batch accuracy: 0.640625 loss: 1.1427128314971924\n",
      "epoch: 7 batch: 13 train batch accuracy: 0.703125 loss: 1.133087158203125\n",
      "epoch: 7 batch: 14 train batch accuracy: 0.671875 loss: 1.1055189371109009\n",
      "epoch: 7 batch: 15 train batch accuracy: 0.734375 loss: 1.0697777271270752\n",
      "epoch: 7 batch: 16 train batch accuracy: 0.625 loss: 1.2468631267547607\n",
      "epoch: 7 batch: 17 train batch accuracy: 0.65625 loss: 1.0986324548721313\n",
      "epoch: 7 batch: 18 train batch accuracy: 0.6875 loss: 1.1286146640777588\n",
      "epoch: 7 batch: 19 train batch accuracy: 0.703125 loss: 0.9344231486320496\n",
      "epoch: 7 batch: 20 train batch accuracy: 0.84375 loss: 0.5870306491851807\n",
      "epoch: 7 batch: 21 train batch accuracy: 0.65625 loss: 1.2169636487960815\n",
      "epoch: 7 batch: 22 train batch accuracy: 0.6875 loss: 1.0427849292755127\n",
      "epoch: 7 batch: 23 train batch accuracy: 0.75 loss: 0.9636716842651367\n",
      "epoch: 7 batch: 24 train batch accuracy: 0.65625 loss: 1.235863208770752\n",
      "epoch: 7 batch: 25 train batch accuracy: 0.703125 loss: 1.0977234840393066\n",
      "epoch: 7 batch: 26 train batch accuracy: 0.703125 loss: 1.0178296566009521\n",
      "epoch: 7 batch: 27 train batch accuracy: 0.65625 loss: 1.1393871307373047\n",
      "epoch: 7 batch: 28 train batch accuracy: 0.65625 loss: 1.1533925533294678\n",
      "epoch: 7 batch: 29 train batch accuracy: 0.6875 loss: 0.9411875009536743\n",
      "epoch: 7 batch: 30 train batch accuracy: 0.671875 loss: 1.1229796409606934\n",
      "epoch: 7 batch: 31 train batch accuracy: 0.640625 loss: 1.1048173904418945\n",
      "epoch: 7 batch: 32 train batch accuracy: 0.703125 loss: 0.8971059918403625\n",
      "epoch: 7 batch: 33 train batch accuracy: 0.625 loss: 1.1992945671081543\n",
      "epoch: 7 batch: 34 train batch accuracy: 0.734375 loss: 0.9234495759010315\n",
      "epoch: 7 batch: 35 train batch accuracy: 0.625 loss: 1.1382427215576172\n",
      "epoch: 7 batch: 36 train batch accuracy: 0.734375 loss: 0.7563594579696655\n",
      "epoch: 7 batch: 37 train batch accuracy: 0.65625 loss: 1.21761953830719\n",
      "epoch: 7 batch: 38 train batch accuracy: 0.75 loss: 0.9790749549865723\n",
      "epoch: 7 batch: 39 train batch accuracy: 0.75 loss: 0.9105619192123413\n",
      "epoch: 7 batch: 40 train batch accuracy: 0.84375 loss: 0.7768416404724121\n",
      "epoch: 7 batch: 41 train batch accuracy: 0.640625 loss: 1.1243855953216553\n",
      "epoch: 7 batch: 42 train batch accuracy: 0.640625 loss: 0.9780900478363037\n",
      "epoch: 7 batch: 43 train batch accuracy: 0.671875 loss: 1.0535500049591064\n",
      "epoch: 7 batch: 44 train batch accuracy: 0.75 loss: 0.801276445388794\n",
      "epoch: 7 batch: 45 train batch accuracy: 0.734375 loss: 1.0852307081222534\n",
      "epoch: 7 batch: 46 train batch accuracy: 0.671875 loss: 1.2209588289260864\n",
      "epoch: 7 batch: 47 train batch accuracy: 0.6875 loss: 0.9864516854286194\n",
      "epoch: 7 batch: 48 train batch accuracy: 0.5625 loss: 1.388221025466919\n",
      "epoch: 7 batch: 49 train batch accuracy: 0.765625 loss: 0.8297538757324219\n",
      "epoch: 7 batch: 50 train batch accuracy: 0.59375 loss: 1.3682647943496704\n",
      "epoch: 7 batch: 51 train batch accuracy: 0.625 loss: 1.2157378196716309\n",
      "epoch: 7 batch: 52 train batch accuracy: 0.65625 loss: 1.072232961654663\n",
      "epoch: 7 batch: 53 train batch accuracy: 0.78125 loss: 0.7809745073318481\n",
      "epoch: 7 batch: 54 train batch accuracy: 0.6875 loss: 1.0570858716964722\n",
      "epoch: 7 batch: 55 train batch accuracy: 0.6875 loss: 1.0218384265899658\n",
      "epoch: 7 batch: 56 train batch accuracy: 0.734375 loss: 0.8632993698120117\n",
      "epoch: 7 batch: 57 train batch accuracy: 0.703125 loss: 1.0104846954345703\n",
      "epoch: 7 batch: 58 train batch accuracy: 0.765625 loss: 0.754065752029419\n",
      "epoch: 7 batch: 59 train batch accuracy: 0.78125 loss: 0.776265025138855\n",
      "epoch: 7 batch: 60 train batch accuracy: 0.59375 loss: 1.2685588598251343\n",
      "epoch: 7 batch: 61 train batch accuracy: 0.78125 loss: 0.7378599643707275\n",
      "epoch: 7 batch: 62 train batch accuracy: 0.6875 loss: 0.8890970945358276\n",
      "epoch: 7 batch: 63 train batch accuracy: 0.71875 loss: 1.0083069801330566\n",
      "epoch: 7 batch: 64 train batch accuracy: 0.71875 loss: 0.9460916519165039\n",
      "epoch: 7 batch: 65 train batch accuracy: 0.765625 loss: 0.6862933039665222\n",
      "epoch: 7 batch: 66 train batch accuracy: 0.6875 loss: 0.8397038578987122\n",
      "epoch: 7 batch: 67 train batch accuracy: 0.796875 loss: 0.7882013320922852\n",
      "epoch: 7 batch: 68 train batch accuracy: 0.6875 loss: 1.180191993713379\n",
      "epoch: 7 batch: 69 train batch accuracy: 0.59375 loss: 1.219003677368164\n",
      "epoch: 7 batch: 70 train batch accuracy: 0.6875 loss: 0.8550070524215698\n",
      "epoch: 7 batch: 71 train batch accuracy: 0.640625 loss: 1.1231331825256348\n",
      "epoch: 7 batch: 72 train batch accuracy: 0.8125 loss: 0.69150310754776\n",
      "epoch: 7 batch: 73 train batch accuracy: 0.765625 loss: 0.7843464612960815\n",
      "epoch: 7 batch: 74 train batch accuracy: 0.640625 loss: 1.0053097009658813\n",
      "epoch: 7 batch: 75 train batch accuracy: 0.796875 loss: 0.9190322160720825\n",
      "epoch: 7 batch: 76 train batch accuracy: 0.734375 loss: 0.8645574450492859\n",
      "epoch: 7 batch: 77 train batch accuracy: 0.609375 loss: 1.1798069477081299\n",
      "epoch: 7 batch: 78 train batch accuracy: 0.796875 loss: 0.694786787033081\n",
      "epoch: 7 batch: 79 train batch accuracy: 0.765625 loss: 0.8577994108200073\n",
      "epoch: 7 batch: 80 train batch accuracy: 0.71875 loss: 1.0495364665985107\n",
      "epoch: 7 batch: 81 train batch accuracy: 0.6875 loss: 1.0237693786621094\n",
      "epoch: 7 batch: 82 train batch accuracy: 0.734375 loss: 0.7442628741264343\n",
      "epoch: 7 batch: 83 train batch accuracy: 0.734375 loss: 0.8485552668571472\n",
      "epoch: 7 batch: 84 train batch accuracy: 0.6875 loss: 1.0094020366668701\n",
      "epoch: 7 batch: 85 train batch accuracy: 0.703125 loss: 0.7387828230857849\n",
      "epoch: 7 batch: 86 train batch accuracy: 0.578125 loss: 1.2285999059677124\n",
      "epoch: 7 batch: 87 train batch accuracy: 0.78125 loss: 0.6665213704109192\n",
      "epoch: 7 batch: 88 train batch accuracy: 0.671875 loss: 1.0350234508514404\n",
      "epoch: 7 batch: 89 train batch accuracy: 0.796875 loss: 0.8171588182449341\n",
      "epoch: 7 batch: 90 train batch accuracy: 0.71875 loss: 1.084416151046753\n",
      "epoch: 7 batch: 91 train batch accuracy: 0.75 loss: 0.7952802181243896\n",
      "epoch: 7 batch: 92 train batch accuracy: 0.609375 loss: 1.2028534412384033\n",
      "epoch: 7 batch: 93 train batch accuracy: 0.640625 loss: 1.3201515674591064\n",
      "Epoch 8/1000  average cost 1.004936386\n",
      "Epoch 8/1000  Test cost 1.832594395\n",
      "准确率: 0.5625\n",
      "Epoch 8/1000  模型保存成功\n",
      "epoch: 8 batch: 0 train batch accuracy: 0.765625 loss: 1.0254075527191162\n",
      "epoch: 8 batch: 1 train batch accuracy: 0.640625 loss: 1.1871485710144043\n",
      "epoch: 8 batch: 2 train batch accuracy: 0.71875 loss: 0.9109066128730774\n",
      "epoch: 8 batch: 3 train batch accuracy: 0.734375 loss: 0.9732598662376404\n",
      "epoch: 8 batch: 4 train batch accuracy: 0.75 loss: 0.9803604483604431\n",
      "epoch: 8 batch: 5 train batch accuracy: 0.75 loss: 0.9824912548065186\n",
      "epoch: 8 batch: 6 train batch accuracy: 0.796875 loss: 0.9442281723022461\n",
      "epoch: 8 batch: 7 train batch accuracy: 0.75 loss: 0.7317695617675781\n",
      "epoch: 8 batch: 8 train batch accuracy: 0.65625 loss: 0.9692062735557556\n",
      "epoch: 8 batch: 9 train batch accuracy: 0.703125 loss: 0.9421148300170898\n",
      "epoch: 8 batch: 10 train batch accuracy: 0.703125 loss: 0.8760949373245239\n",
      "epoch: 8 batch: 11 train batch accuracy: 0.5625 loss: 1.5891540050506592\n",
      "epoch: 8 batch: 12 train batch accuracy: 0.734375 loss: 0.8996060490608215\n",
      "epoch: 8 batch: 13 train batch accuracy: 0.640625 loss: 1.1236586570739746\n",
      "epoch: 8 batch: 14 train batch accuracy: 0.6875 loss: 1.0907764434814453\n",
      "epoch: 8 batch: 15 train batch accuracy: 0.703125 loss: 0.952226459980011\n",
      "epoch: 8 batch: 16 train batch accuracy: 0.625 loss: 1.291195273399353\n",
      "epoch: 8 batch: 17 train batch accuracy: 0.6875 loss: 0.9564491510391235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 batch: 18 train batch accuracy: 0.734375 loss: 0.8193056583404541\n",
      "epoch: 8 batch: 19 train batch accuracy: 0.65625 loss: 1.189291000366211\n",
      "epoch: 8 batch: 20 train batch accuracy: 0.640625 loss: 1.2484636306762695\n",
      "epoch: 8 batch: 21 train batch accuracy: 0.71875 loss: 0.9016121029853821\n",
      "epoch: 8 batch: 22 train batch accuracy: 0.546875 loss: 1.5805083513259888\n",
      "epoch: 8 batch: 23 train batch accuracy: 0.609375 loss: 1.2484071254730225\n",
      "epoch: 8 batch: 24 train batch accuracy: 0.71875 loss: 0.843453049659729\n",
      "epoch: 8 batch: 25 train batch accuracy: 0.78125 loss: 1.0471782684326172\n",
      "epoch: 8 batch: 26 train batch accuracy: 0.71875 loss: 1.009622573852539\n",
      "epoch: 8 batch: 27 train batch accuracy: 0.703125 loss: 0.9991689920425415\n",
      "epoch: 8 batch: 28 train batch accuracy: 0.828125 loss: 0.6389549970626831\n",
      "epoch: 8 batch: 29 train batch accuracy: 0.59375 loss: 1.1711313724517822\n",
      "epoch: 8 batch: 30 train batch accuracy: 0.71875 loss: 0.952825665473938\n",
      "epoch: 8 batch: 31 train batch accuracy: 0.75 loss: 0.9169994592666626\n",
      "epoch: 8 batch: 32 train batch accuracy: 0.6875 loss: 1.1602342128753662\n",
      "epoch: 8 batch: 33 train batch accuracy: 0.765625 loss: 0.9973939061164856\n",
      "epoch: 8 batch: 34 train batch accuracy: 0.75 loss: 0.9027028679847717\n",
      "epoch: 8 batch: 35 train batch accuracy: 0.703125 loss: 0.9123371243476868\n",
      "epoch: 8 batch: 36 train batch accuracy: 0.71875 loss: 0.8087320327758789\n",
      "epoch: 8 batch: 37 train batch accuracy: 0.671875 loss: 1.1405829191207886\n",
      "epoch: 8 batch: 38 train batch accuracy: 0.71875 loss: 0.8398226499557495\n",
      "epoch: 8 batch: 39 train batch accuracy: 0.734375 loss: 0.9432840347290039\n",
      "epoch: 8 batch: 40 train batch accuracy: 0.71875 loss: 1.1677511930465698\n",
      "epoch: 8 batch: 41 train batch accuracy: 0.765625 loss: 0.893944501876831\n",
      "epoch: 8 batch: 42 train batch accuracy: 0.71875 loss: 0.9346984624862671\n",
      "epoch: 8 batch: 43 train batch accuracy: 0.640625 loss: 1.1780545711517334\n",
      "epoch: 8 batch: 44 train batch accuracy: 0.8125 loss: 0.7630664110183716\n",
      "epoch: 8 batch: 45 train batch accuracy: 0.84375 loss: 0.7852368354797363\n",
      "epoch: 8 batch: 46 train batch accuracy: 0.8125 loss: 0.6868410110473633\n",
      "epoch: 8 batch: 47 train batch accuracy: 0.765625 loss: 1.0002226829528809\n",
      "epoch: 8 batch: 48 train batch accuracy: 0.703125 loss: 0.7981300354003906\n",
      "epoch: 8 batch: 49 train batch accuracy: 0.75 loss: 0.8011718392372131\n",
      "epoch: 8 batch: 50 train batch accuracy: 0.71875 loss: 0.8919682502746582\n",
      "epoch: 8 batch: 51 train batch accuracy: 0.78125 loss: 0.7103869915008545\n",
      "epoch: 8 batch: 52 train batch accuracy: 0.765625 loss: 0.9520732164382935\n",
      "epoch: 8 batch: 53 train batch accuracy: 0.671875 loss: 0.8797814249992371\n",
      "epoch: 8 batch: 54 train batch accuracy: 0.734375 loss: 0.8279152512550354\n",
      "epoch: 8 batch: 55 train batch accuracy: 0.734375 loss: 0.8127648234367371\n",
      "epoch: 8 batch: 56 train batch accuracy: 0.734375 loss: 0.9000401496887207\n",
      "epoch: 8 batch: 57 train batch accuracy: 0.765625 loss: 0.6459839940071106\n",
      "epoch: 8 batch: 58 train batch accuracy: 0.8125 loss: 0.6857894659042358\n",
      "epoch: 8 batch: 59 train batch accuracy: 0.703125 loss: 0.9911118745803833\n",
      "epoch: 8 batch: 60 train batch accuracy: 0.859375 loss: 0.7205111980438232\n",
      "epoch: 8 batch: 61 train batch accuracy: 0.796875 loss: 0.7804497480392456\n",
      "epoch: 8 batch: 62 train batch accuracy: 0.828125 loss: 0.5777974128723145\n",
      "epoch: 8 batch: 63 train batch accuracy: 0.734375 loss: 0.9019123315811157\n",
      "epoch: 8 batch: 64 train batch accuracy: 0.734375 loss: 0.8935326933860779\n",
      "epoch: 8 batch: 65 train batch accuracy: 0.671875 loss: 0.9794934988021851\n",
      "epoch: 8 batch: 66 train batch accuracy: 0.75 loss: 0.9599311947822571\n",
      "epoch: 8 batch: 67 train batch accuracy: 0.78125 loss: 0.7457342147827148\n",
      "epoch: 8 batch: 68 train batch accuracy: 0.6875 loss: 0.9532981514930725\n",
      "epoch: 8 batch: 69 train batch accuracy: 0.75 loss: 0.8242881894111633\n",
      "epoch: 8 batch: 70 train batch accuracy: 0.75 loss: 0.7224860191345215\n",
      "epoch: 8 batch: 71 train batch accuracy: 0.734375 loss: 1.1036243438720703\n",
      "epoch: 8 batch: 72 train batch accuracy: 0.71875 loss: 1.2284774780273438\n",
      "epoch: 8 batch: 73 train batch accuracy: 0.796875 loss: 0.6445711851119995\n",
      "epoch: 8 batch: 74 train batch accuracy: 0.796875 loss: 0.7041210532188416\n",
      "epoch: 8 batch: 75 train batch accuracy: 0.8125 loss: 0.7433102130889893\n",
      "epoch: 8 batch: 76 train batch accuracy: 0.65625 loss: 1.074355959892273\n",
      "epoch: 8 batch: 77 train batch accuracy: 0.734375 loss: 0.7270757555961609\n",
      "epoch: 8 batch: 78 train batch accuracy: 0.6875 loss: 0.8961788415908813\n",
      "epoch: 8 batch: 79 train batch accuracy: 0.71875 loss: 0.8913319706916809\n",
      "epoch: 8 batch: 80 train batch accuracy: 0.78125 loss: 0.8398765325546265\n",
      "epoch: 8 batch: 81 train batch accuracy: 0.734375 loss: 0.9065124988555908\n",
      "epoch: 8 batch: 82 train batch accuracy: 0.84375 loss: 0.5467483401298523\n",
      "epoch: 8 batch: 83 train batch accuracy: 0.78125 loss: 0.858269453048706\n",
      "epoch: 8 batch: 84 train batch accuracy: 0.75 loss: 0.756313681602478\n",
      "epoch: 8 batch: 85 train batch accuracy: 0.734375 loss: 0.8897400498390198\n",
      "epoch: 8 batch: 86 train batch accuracy: 0.78125 loss: 0.5865004658699036\n",
      "epoch: 8 batch: 87 train batch accuracy: 0.5625 loss: 1.1440119743347168\n",
      "epoch: 8 batch: 88 train batch accuracy: 0.765625 loss: 0.8530957698822021\n",
      "epoch: 8 batch: 89 train batch accuracy: 0.765625 loss: 0.9173682332038879\n",
      "epoch: 8 batch: 90 train batch accuracy: 0.796875 loss: 0.803299069404602\n",
      "epoch: 8 batch: 91 train batch accuracy: 0.703125 loss: 0.8018506169319153\n",
      "epoch: 8 batch: 92 train batch accuracy: 0.84375 loss: 0.7024498581886292\n",
      "epoch: 8 batch: 93 train batch accuracy: 0.65625 loss: 1.042452096939087\n",
      "Epoch 9/1000  average cost 0.922616694\n",
      "Epoch 9/1000  Test cost 1.850263000\n",
      "准确率: 0.5625\n",
      "Epoch 9/1000  模型保存成功\n",
      "epoch: 9 batch: 0 train batch accuracy: 0.71875 loss: 0.9241693019866943\n",
      "epoch: 9 batch: 1 train batch accuracy: 0.75 loss: 0.8367716073989868\n",
      "epoch: 9 batch: 2 train batch accuracy: 0.859375 loss: 0.7094482779502869\n",
      "epoch: 9 batch: 3 train batch accuracy: 0.703125 loss: 0.8623629212379456\n",
      "epoch: 9 batch: 4 train batch accuracy: 0.71875 loss: 0.9939607977867126\n",
      "epoch: 9 batch: 5 train batch accuracy: 0.8125 loss: 0.739035964012146\n",
      "epoch: 9 batch: 6 train batch accuracy: 0.796875 loss: 0.925918698310852\n",
      "epoch: 9 batch: 7 train batch accuracy: 0.75 loss: 0.7134407758712769\n",
      "epoch: 9 batch: 8 train batch accuracy: 0.84375 loss: 0.5140202641487122\n",
      "epoch: 9 batch: 9 train batch accuracy: 0.765625 loss: 0.8216652870178223\n",
      "epoch: 9 batch: 10 train batch accuracy: 0.78125 loss: 0.6357455849647522\n",
      "epoch: 9 batch: 11 train batch accuracy: 0.765625 loss: 0.6175130009651184\n",
      "epoch: 9 batch: 12 train batch accuracy: 0.71875 loss: 0.8026249408721924\n",
      "epoch: 9 batch: 13 train batch accuracy: 0.6875 loss: 0.7948096394538879\n",
      "epoch: 9 batch: 14 train batch accuracy: 0.765625 loss: 0.7833516001701355\n",
      "epoch: 9 batch: 15 train batch accuracy: 0.75 loss: 0.7942820191383362\n",
      "epoch: 9 batch: 16 train batch accuracy: 0.828125 loss: 0.6120693683624268\n",
      "epoch: 9 batch: 17 train batch accuracy: 0.71875 loss: 0.9122838973999023\n",
      "epoch: 9 batch: 18 train batch accuracy: 0.71875 loss: 0.7926363945007324\n",
      "epoch: 9 batch: 19 train batch accuracy: 0.65625 loss: 1.2683415412902832\n",
      "epoch: 9 batch: 20 train batch accuracy: 0.75 loss: 0.8811327219009399\n",
      "epoch: 9 batch: 21 train batch accuracy: 0.75 loss: 0.94626784324646\n",
      "epoch: 9 batch: 22 train batch accuracy: 0.78125 loss: 0.8238084316253662\n",
      "epoch: 9 batch: 23 train batch accuracy: 0.796875 loss: 0.7583644390106201\n",
      "epoch: 9 batch: 24 train batch accuracy: 0.734375 loss: 0.6347185969352722\n",
      "epoch: 9 batch: 25 train batch accuracy: 0.8125 loss: 0.6418671607971191\n",
      "epoch: 9 batch: 26 train batch accuracy: 0.625 loss: 1.1816256046295166\n",
      "epoch: 9 batch: 27 train batch accuracy: 0.734375 loss: 1.0176855325698853\n",
      "epoch: 9 batch: 28 train batch accuracy: 0.71875 loss: 0.9885307550430298\n",
      "epoch: 9 batch: 29 train batch accuracy: 0.6875 loss: 1.1351823806762695\n",
      "epoch: 9 batch: 30 train batch accuracy: 0.71875 loss: 0.7657771110534668\n",
      "epoch: 9 batch: 31 train batch accuracy: 0.71875 loss: 0.774728000164032\n",
      "epoch: 9 batch: 32 train batch accuracy: 0.8125 loss: 0.570631742477417\n",
      "epoch: 9 batch: 33 train batch accuracy: 0.65625 loss: 1.1141799688339233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 batch: 34 train batch accuracy: 0.703125 loss: 0.9715600609779358\n",
      "epoch: 9 batch: 35 train batch accuracy: 0.78125 loss: 0.6597692370414734\n",
      "epoch: 9 batch: 36 train batch accuracy: 0.78125 loss: 0.7527554035186768\n",
      "epoch: 9 batch: 37 train batch accuracy: 0.75 loss: 0.8144353032112122\n",
      "epoch: 9 batch: 38 train batch accuracy: 0.765625 loss: 0.7627550363540649\n",
      "epoch: 9 batch: 39 train batch accuracy: 0.75 loss: 0.9473843574523926\n",
      "epoch: 9 batch: 40 train batch accuracy: 0.921875 loss: 0.3988776206970215\n",
      "epoch: 9 batch: 41 train batch accuracy: 0.78125 loss: 0.6906844973564148\n",
      "epoch: 9 batch: 42 train batch accuracy: 0.703125 loss: 1.0002429485321045\n",
      "epoch: 9 batch: 43 train batch accuracy: 0.796875 loss: 0.7696971893310547\n",
      "epoch: 9 batch: 44 train batch accuracy: 0.71875 loss: 0.9559069871902466\n",
      "epoch: 9 batch: 45 train batch accuracy: 0.796875 loss: 0.9423698782920837\n",
      "epoch: 9 batch: 46 train batch accuracy: 0.734375 loss: 0.9440149664878845\n",
      "epoch: 9 batch: 47 train batch accuracy: 0.78125 loss: 0.6015913486480713\n",
      "epoch: 9 batch: 48 train batch accuracy: 0.765625 loss: 0.7377966642379761\n",
      "epoch: 9 batch: 49 train batch accuracy: 0.75 loss: 0.7061399817466736\n",
      "epoch: 9 batch: 50 train batch accuracy: 0.765625 loss: 0.8569725155830383\n",
      "epoch: 9 batch: 51 train batch accuracy: 0.8125 loss: 0.6564627885818481\n",
      "epoch: 9 batch: 52 train batch accuracy: 0.65625 loss: 0.898978054523468\n",
      "epoch: 9 batch: 53 train batch accuracy: 0.765625 loss: 0.7297493815422058\n",
      "epoch: 9 batch: 54 train batch accuracy: 0.78125 loss: 0.6907356977462769\n",
      "epoch: 9 batch: 55 train batch accuracy: 0.84375 loss: 0.6557275056838989\n",
      "epoch: 9 batch: 56 train batch accuracy: 0.84375 loss: 0.6019947528839111\n",
      "epoch: 9 batch: 57 train batch accuracy: 0.828125 loss: 0.6112205982208252\n",
      "epoch: 9 batch: 58 train batch accuracy: 0.796875 loss: 0.6636829972267151\n",
      "epoch: 9 batch: 59 train batch accuracy: 0.84375 loss: 0.5174746513366699\n",
      "epoch: 9 batch: 60 train batch accuracy: 0.75 loss: 0.629250705242157\n",
      "epoch: 9 batch: 61 train batch accuracy: 0.859375 loss: 0.438936322927475\n",
      "epoch: 9 batch: 62 train batch accuracy: 0.890625 loss: 0.4552307426929474\n",
      "epoch: 9 batch: 63 train batch accuracy: 0.703125 loss: 0.7810624241828918\n",
      "epoch: 9 batch: 64 train batch accuracy: 0.75 loss: 0.8203156590461731\n",
      "epoch: 9 batch: 65 train batch accuracy: 0.84375 loss: 0.4974352717399597\n",
      "epoch: 9 batch: 66 train batch accuracy: 0.859375 loss: 0.4481891989707947\n",
      "epoch: 9 batch: 67 train batch accuracy: 0.75 loss: 0.8577136993408203\n",
      "epoch: 9 batch: 68 train batch accuracy: 0.796875 loss: 0.719445526599884\n",
      "epoch: 9 batch: 69 train batch accuracy: 0.828125 loss: 0.5763846039772034\n",
      "epoch: 9 batch: 70 train batch accuracy: 0.78125 loss: 0.857524037361145\n",
      "epoch: 9 batch: 71 train batch accuracy: 0.78125 loss: 0.6921508312225342\n",
      "epoch: 9 batch: 72 train batch accuracy: 0.765625 loss: 0.6917891502380371\n",
      "epoch: 9 batch: 73 train batch accuracy: 0.78125 loss: 0.7423369884490967\n",
      "epoch: 9 batch: 74 train batch accuracy: 0.796875 loss: 0.703385591506958\n",
      "epoch: 9 batch: 75 train batch accuracy: 0.71875 loss: 1.021526575088501\n",
      "epoch: 9 batch: 76 train batch accuracy: 0.828125 loss: 0.5824462175369263\n",
      "epoch: 9 batch: 77 train batch accuracy: 0.734375 loss: 0.8653123378753662\n",
      "epoch: 9 batch: 78 train batch accuracy: 0.796875 loss: 0.8652231693267822\n",
      "epoch: 9 batch: 79 train batch accuracy: 0.84375 loss: 0.5965696573257446\n",
      "epoch: 9 batch: 80 train batch accuracy: 0.75 loss: 0.8163449764251709\n",
      "epoch: 9 batch: 81 train batch accuracy: 0.78125 loss: 0.6566072106361389\n",
      "epoch: 9 batch: 82 train batch accuracy: 0.796875 loss: 0.6659848093986511\n",
      "epoch: 9 batch: 83 train batch accuracy: 0.796875 loss: 0.6006110906600952\n",
      "epoch: 9 batch: 84 train batch accuracy: 0.8125 loss: 0.586597204208374\n",
      "epoch: 9 batch: 85 train batch accuracy: 0.796875 loss: 0.773206353187561\n",
      "epoch: 9 batch: 86 train batch accuracy: 0.828125 loss: 0.7680346965789795\n",
      "epoch: 9 batch: 87 train batch accuracy: 0.734375 loss: 0.7186164259910583\n",
      "epoch: 9 batch: 88 train batch accuracy: 0.796875 loss: 0.5729259252548218\n",
      "epoch: 9 batch: 89 train batch accuracy: 0.703125 loss: 0.97637540102005\n",
      "epoch: 9 batch: 90 train batch accuracy: 0.828125 loss: 0.6067236065864563\n",
      "epoch: 9 batch: 91 train batch accuracy: 0.796875 loss: 0.6906771063804626\n",
      "epoch: 9 batch: 92 train batch accuracy: 0.828125 loss: 0.5894302129745483\n",
      "epoch: 9 batch: 93 train batch accuracy: 0.734375 loss: 0.7982591986656189\n",
      "Epoch 10/1000  average cost 0.760537825\n",
      "Epoch 10/1000  Test cost 1.651795626\n",
      "准确率: 0.53125\n",
      "Epoch 10/1000  模型保存成功\n",
      "epoch: 10 batch: 0 train batch accuracy: 0.796875 loss: 0.6572020053863525\n",
      "epoch: 10 batch: 1 train batch accuracy: 0.78125 loss: 0.6243077516555786\n",
      "epoch: 10 batch: 2 train batch accuracy: 0.78125 loss: 0.7925043106079102\n",
      "epoch: 10 batch: 3 train batch accuracy: 0.75 loss: 0.768852710723877\n",
      "epoch: 10 batch: 4 train batch accuracy: 0.796875 loss: 0.5740352272987366\n",
      "epoch: 10 batch: 5 train batch accuracy: 0.703125 loss: 0.7934368848800659\n",
      "epoch: 10 batch: 6 train batch accuracy: 0.65625 loss: 1.1676645278930664\n",
      "epoch: 10 batch: 7 train batch accuracy: 0.765625 loss: 0.6399912238121033\n",
      "epoch: 10 batch: 8 train batch accuracy: 0.734375 loss: 0.8312629461288452\n",
      "epoch: 10 batch: 9 train batch accuracy: 0.734375 loss: 0.9960151314735413\n",
      "epoch: 10 batch: 10 train batch accuracy: 0.8125 loss: 0.6979148983955383\n",
      "epoch: 10 batch: 11 train batch accuracy: 0.796875 loss: 0.7788749933242798\n",
      "epoch: 10 batch: 12 train batch accuracy: 0.78125 loss: 0.7248691320419312\n",
      "epoch: 10 batch: 13 train batch accuracy: 0.8125 loss: 0.6372716426849365\n",
      "epoch: 10 batch: 14 train batch accuracy: 0.765625 loss: 0.7351840138435364\n",
      "epoch: 10 batch: 15 train batch accuracy: 0.84375 loss: 0.6397773623466492\n",
      "epoch: 10 batch: 16 train batch accuracy: 0.78125 loss: 0.7078608870506287\n",
      "epoch: 10 batch: 17 train batch accuracy: 0.78125 loss: 0.633472204208374\n",
      "epoch: 10 batch: 18 train batch accuracy: 0.765625 loss: 0.666163980960846\n",
      "epoch: 10 batch: 19 train batch accuracy: 0.734375 loss: 0.7029440402984619\n",
      "epoch: 10 batch: 20 train batch accuracy: 0.828125 loss: 0.5898717641830444\n",
      "epoch: 10 batch: 21 train batch accuracy: 0.875 loss: 0.5387805104255676\n",
      "epoch: 10 batch: 22 train batch accuracy: 0.78125 loss: 0.6942031979560852\n",
      "epoch: 10 batch: 23 train batch accuracy: 0.75 loss: 0.6541498899459839\n",
      "epoch: 10 batch: 24 train batch accuracy: 0.734375 loss: 0.9841077327728271\n",
      "epoch: 10 batch: 25 train batch accuracy: 0.796875 loss: 0.727474570274353\n",
      "epoch: 10 batch: 26 train batch accuracy: 0.75 loss: 0.6184787750244141\n",
      "epoch: 10 batch: 27 train batch accuracy: 0.640625 loss: 1.0391783714294434\n",
      "epoch: 10 batch: 28 train batch accuracy: 0.75 loss: 0.6945172548294067\n",
      "epoch: 10 batch: 29 train batch accuracy: 0.78125 loss: 0.7530462741851807\n",
      "epoch: 10 batch: 30 train batch accuracy: 0.734375 loss: 0.9340925812721252\n",
      "epoch: 10 batch: 31 train batch accuracy: 0.84375 loss: 0.5994794368743896\n",
      "epoch: 10 batch: 32 train batch accuracy: 0.8125 loss: 0.41994979977607727\n",
      "epoch: 10 batch: 33 train batch accuracy: 0.859375 loss: 0.6852011680603027\n",
      "epoch: 10 batch: 34 train batch accuracy: 0.75 loss: 0.9566729664802551\n",
      "epoch: 10 batch: 35 train batch accuracy: 0.828125 loss: 0.5417059659957886\n",
      "epoch: 10 batch: 36 train batch accuracy: 0.765625 loss: 0.6885355710983276\n",
      "epoch: 10 batch: 37 train batch accuracy: 0.8125 loss: 0.6112287044525146\n",
      "epoch: 10 batch: 38 train batch accuracy: 0.75 loss: 0.8389186859130859\n",
      "epoch: 10 batch: 39 train batch accuracy: 0.8125 loss: 0.7353683710098267\n",
      "epoch: 10 batch: 40 train batch accuracy: 0.796875 loss: 0.672518253326416\n",
      "epoch: 10 batch: 41 train batch accuracy: 0.765625 loss: 0.8016777634620667\n",
      "epoch: 10 batch: 42 train batch accuracy: 0.78125 loss: 0.7200032472610474\n",
      "epoch: 10 batch: 43 train batch accuracy: 0.6875 loss: 0.9835487604141235\n",
      "epoch: 10 batch: 44 train batch accuracy: 0.796875 loss: 0.6674737334251404\n",
      "epoch: 10 batch: 45 train batch accuracy: 0.796875 loss: 0.5871138572692871\n",
      "epoch: 10 batch: 46 train batch accuracy: 0.84375 loss: 0.7764527797698975\n",
      "epoch: 10 batch: 47 train batch accuracy: 0.828125 loss: 0.5361745357513428\n",
      "epoch: 10 batch: 48 train batch accuracy: 0.796875 loss: 0.6872035264968872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 batch: 49 train batch accuracy: 0.859375 loss: 0.4405142366886139\n",
      "epoch: 10 batch: 50 train batch accuracy: 0.78125 loss: 0.6665530204772949\n",
      "epoch: 10 batch: 51 train batch accuracy: 0.75 loss: 0.8550874590873718\n",
      "epoch: 10 batch: 52 train batch accuracy: 0.8125 loss: 0.5293329358100891\n",
      "epoch: 10 batch: 53 train batch accuracy: 0.796875 loss: 0.7006396055221558\n",
      "epoch: 10 batch: 54 train batch accuracy: 0.796875 loss: 0.6001558303833008\n",
      "epoch: 10 batch: 55 train batch accuracy: 0.734375 loss: 0.9724483489990234\n",
      "epoch: 10 batch: 56 train batch accuracy: 0.6875 loss: 0.912437915802002\n",
      "epoch: 10 batch: 57 train batch accuracy: 0.8125 loss: 0.5619128942489624\n",
      "epoch: 10 batch: 58 train batch accuracy: 0.859375 loss: 0.49039599299430847\n",
      "epoch: 10 batch: 59 train batch accuracy: 0.75 loss: 0.8940403461456299\n",
      "epoch: 10 batch: 60 train batch accuracy: 0.765625 loss: 0.6588209271430969\n",
      "epoch: 10 batch: 61 train batch accuracy: 0.828125 loss: 0.6673851013183594\n",
      "epoch: 10 batch: 62 train batch accuracy: 0.734375 loss: 0.7131942510604858\n",
      "epoch: 10 batch: 63 train batch accuracy: 0.8125 loss: 0.7507683038711548\n",
      "epoch: 10 batch: 64 train batch accuracy: 0.78125 loss: 0.8225613832473755\n",
      "epoch: 10 batch: 65 train batch accuracy: 0.71875 loss: 0.6934372186660767\n",
      "epoch: 10 batch: 66 train batch accuracy: 0.765625 loss: 0.6548991203308105\n",
      "epoch: 10 batch: 67 train batch accuracy: 0.796875 loss: 0.8288122415542603\n",
      "epoch: 10 batch: 68 train batch accuracy: 0.796875 loss: 0.7495763301849365\n",
      "epoch: 10 batch: 69 train batch accuracy: 0.859375 loss: 0.43861889839172363\n",
      "epoch: 10 batch: 70 train batch accuracy: 0.828125 loss: 0.5553261637687683\n",
      "epoch: 10 batch: 71 train batch accuracy: 0.875 loss: 0.4425565004348755\n",
      "epoch: 10 batch: 72 train batch accuracy: 0.75 loss: 0.7606309652328491\n",
      "epoch: 10 batch: 73 train batch accuracy: 0.71875 loss: 0.8702563643455505\n",
      "epoch: 10 batch: 74 train batch accuracy: 0.703125 loss: 0.8026026487350464\n",
      "epoch: 10 batch: 75 train batch accuracy: 0.78125 loss: 0.649861216545105\n",
      "epoch: 10 batch: 76 train batch accuracy: 0.734375 loss: 0.8267307281494141\n",
      "epoch: 10 batch: 77 train batch accuracy: 0.875 loss: 0.5278542041778564\n",
      "epoch: 10 batch: 78 train batch accuracy: 0.71875 loss: 0.8625078797340393\n",
      "epoch: 10 batch: 79 train batch accuracy: 0.75 loss: 0.794689416885376\n",
      "epoch: 10 batch: 80 train batch accuracy: 0.734375 loss: 0.8557082414627075\n",
      "epoch: 10 batch: 81 train batch accuracy: 0.78125 loss: 0.6367740035057068\n",
      "epoch: 10 batch: 82 train batch accuracy: 0.734375 loss: 0.7581250071525574\n",
      "epoch: 10 batch: 83 train batch accuracy: 0.703125 loss: 0.7777469158172607\n",
      "epoch: 10 batch: 84 train batch accuracy: 0.765625 loss: 0.6387218236923218\n",
      "epoch: 10 batch: 85 train batch accuracy: 0.75 loss: 0.7513218522071838\n",
      "epoch: 10 batch: 86 train batch accuracy: 0.84375 loss: 0.5440927743911743\n",
      "epoch: 10 batch: 87 train batch accuracy: 0.765625 loss: 0.6197082996368408\n",
      "epoch: 10 batch: 88 train batch accuracy: 0.84375 loss: 0.5422229170799255\n",
      "epoch: 10 batch: 89 train batch accuracy: 0.765625 loss: 0.8052470684051514\n",
      "epoch: 10 batch: 90 train batch accuracy: 0.765625 loss: 0.7388436198234558\n",
      "epoch: 10 batch: 91 train batch accuracy: 0.796875 loss: 0.5045939087867737\n",
      "epoch: 10 batch: 92 train batch accuracy: 0.71875 loss: 0.6401742100715637\n",
      "epoch: 10 batch: 93 train batch accuracy: 0.78125 loss: 0.6523004174232483\n",
      "Epoch 11/1000  average cost 0.709222590\n",
      "Epoch 11/1000  Test cost 1.415424109\n",
      "准确率: 0.59375\n",
      "Epoch 11/1000  模型保存成功\n",
      "epoch: 11 batch: 0 train batch accuracy: 0.84375 loss: 0.4918525815010071\n",
      "epoch: 11 batch: 1 train batch accuracy: 0.796875 loss: 0.5630512237548828\n",
      "epoch: 11 batch: 2 train batch accuracy: 0.796875 loss: 0.7450002431869507\n",
      "epoch: 11 batch: 3 train batch accuracy: 0.75 loss: 0.8366489410400391\n",
      "epoch: 11 batch: 4 train batch accuracy: 0.78125 loss: 0.6816518902778625\n",
      "epoch: 11 batch: 5 train batch accuracy: 0.78125 loss: 0.8010580539703369\n",
      "epoch: 11 batch: 6 train batch accuracy: 0.8125 loss: 0.7155009508132935\n",
      "epoch: 11 batch: 7 train batch accuracy: 0.84375 loss: 0.5124170780181885\n",
      "epoch: 11 batch: 8 train batch accuracy: 0.828125 loss: 0.5707964301109314\n",
      "epoch: 11 batch: 9 train batch accuracy: 0.890625 loss: 0.3822531998157501\n",
      "epoch: 11 batch: 10 train batch accuracy: 0.734375 loss: 0.7895071506500244\n",
      "epoch: 11 batch: 11 train batch accuracy: 0.703125 loss: 1.0566107034683228\n",
      "epoch: 11 batch: 12 train batch accuracy: 0.796875 loss: 0.7457331418991089\n",
      "epoch: 11 batch: 13 train batch accuracy: 0.828125 loss: 0.6389309167861938\n",
      "epoch: 11 batch: 14 train batch accuracy: 0.796875 loss: 0.6262560486793518\n",
      "epoch: 11 batch: 15 train batch accuracy: 0.859375 loss: 0.6238144040107727\n",
      "epoch: 11 batch: 16 train batch accuracy: 0.75 loss: 0.7849347591400146\n",
      "epoch: 11 batch: 17 train batch accuracy: 0.796875 loss: 0.552808403968811\n",
      "epoch: 11 batch: 18 train batch accuracy: 0.71875 loss: 0.7280057668685913\n",
      "epoch: 11 batch: 19 train batch accuracy: 0.734375 loss: 0.8849571943283081\n",
      "epoch: 11 batch: 20 train batch accuracy: 0.84375 loss: 0.6078053712844849\n",
      "epoch: 11 batch: 21 train batch accuracy: 0.890625 loss: 0.5804736614227295\n",
      "epoch: 11 batch: 22 train batch accuracy: 0.8125 loss: 0.7044169306755066\n",
      "epoch: 11 batch: 23 train batch accuracy: 0.875 loss: 0.4574331045150757\n",
      "epoch: 11 batch: 24 train batch accuracy: 0.8125 loss: 0.5241172313690186\n",
      "epoch: 11 batch: 25 train batch accuracy: 0.828125 loss: 0.6801885366439819\n",
      "epoch: 11 batch: 26 train batch accuracy: 0.8125 loss: 0.4341897964477539\n",
      "epoch: 11 batch: 27 train batch accuracy: 0.765625 loss: 0.6359266042709351\n",
      "epoch: 11 batch: 28 train batch accuracy: 0.828125 loss: 0.49175697565078735\n",
      "epoch: 11 batch: 29 train batch accuracy: 0.78125 loss: 0.7281219959259033\n",
      "epoch: 11 batch: 30 train batch accuracy: 0.828125 loss: 0.6688581705093384\n",
      "epoch: 11 batch: 31 train batch accuracy: 0.765625 loss: 0.726746678352356\n",
      "epoch: 11 batch: 32 train batch accuracy: 0.875 loss: 0.5907655954360962\n",
      "epoch: 11 batch: 33 train batch accuracy: 0.765625 loss: 0.7300649285316467\n",
      "epoch: 11 batch: 34 train batch accuracy: 0.765625 loss: 0.5967066287994385\n",
      "epoch: 11 batch: 35 train batch accuracy: 0.78125 loss: 0.6946132183074951\n",
      "epoch: 11 batch: 36 train batch accuracy: 0.8125 loss: 0.5234357118606567\n",
      "epoch: 11 batch: 37 train batch accuracy: 0.703125 loss: 0.7633333206176758\n",
      "epoch: 11 batch: 38 train batch accuracy: 0.828125 loss: 0.5455814599990845\n",
      "epoch: 11 batch: 39 train batch accuracy: 0.84375 loss: 0.6279135346412659\n",
      "epoch: 11 batch: 40 train batch accuracy: 0.6875 loss: 0.8103543519973755\n",
      "epoch: 11 batch: 41 train batch accuracy: 0.765625 loss: 0.690815806388855\n",
      "epoch: 11 batch: 42 train batch accuracy: 0.84375 loss: 0.6137255430221558\n",
      "epoch: 11 batch: 43 train batch accuracy: 0.8125 loss: 0.7406644821166992\n",
      "epoch: 11 batch: 44 train batch accuracy: 0.90625 loss: 0.43183863162994385\n",
      "epoch: 11 batch: 45 train batch accuracy: 0.859375 loss: 0.4745526611804962\n",
      "epoch: 11 batch: 46 train batch accuracy: 0.8125 loss: 0.6888887286186218\n",
      "epoch: 11 batch: 47 train batch accuracy: 0.8125 loss: 0.6306486129760742\n",
      "epoch: 11 batch: 48 train batch accuracy: 0.765625 loss: 0.808912456035614\n",
      "epoch: 11 batch: 49 train batch accuracy: 0.8125 loss: 0.6891109943389893\n",
      "epoch: 11 batch: 50 train batch accuracy: 0.90625 loss: 0.45425114035606384\n",
      "epoch: 11 batch: 51 train batch accuracy: 0.84375 loss: 0.4828505516052246\n",
      "epoch: 11 batch: 52 train batch accuracy: 0.796875 loss: 0.7450990676879883\n",
      "epoch: 11 batch: 53 train batch accuracy: 0.734375 loss: 0.6726648211479187\n",
      "epoch: 11 batch: 54 train batch accuracy: 0.78125 loss: 0.5445061326026917\n",
      "epoch: 11 batch: 55 train batch accuracy: 0.796875 loss: 0.5287808775901794\n",
      "epoch: 11 batch: 56 train batch accuracy: 0.8125 loss: 0.47491079568862915\n",
      "epoch: 11 batch: 57 train batch accuracy: 0.90625 loss: 0.5159994959831238\n",
      "epoch: 11 batch: 58 train batch accuracy: 0.78125 loss: 0.7448549270629883\n",
      "epoch: 11 batch: 59 train batch accuracy: 0.859375 loss: 0.48093682527542114\n",
      "epoch: 11 batch: 60 train batch accuracy: 0.875 loss: 0.5119191408157349\n",
      "epoch: 11 batch: 61 train batch accuracy: 0.859375 loss: 0.38062721490859985\n",
      "epoch: 11 batch: 62 train batch accuracy: 0.75 loss: 0.587238073348999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 batch: 63 train batch accuracy: 0.84375 loss: 0.6137896776199341\n",
      "epoch: 11 batch: 64 train batch accuracy: 0.90625 loss: 0.4178692102432251\n",
      "epoch: 11 batch: 65 train batch accuracy: 0.65625 loss: 1.0168657302856445\n",
      "epoch: 11 batch: 66 train batch accuracy: 0.796875 loss: 0.6073719263076782\n",
      "epoch: 11 batch: 67 train batch accuracy: 0.84375 loss: 0.5882563591003418\n",
      "epoch: 11 batch: 68 train batch accuracy: 0.828125 loss: 0.5623844861984253\n",
      "epoch: 11 batch: 69 train batch accuracy: 0.828125 loss: 0.5935470461845398\n",
      "epoch: 11 batch: 70 train batch accuracy: 0.84375 loss: 0.6145236492156982\n",
      "epoch: 11 batch: 71 train batch accuracy: 0.875 loss: 0.4655514657497406\n",
      "epoch: 11 batch: 72 train batch accuracy: 0.828125 loss: 0.5862442255020142\n",
      "epoch: 11 batch: 73 train batch accuracy: 0.796875 loss: 0.7183375358581543\n",
      "epoch: 11 batch: 74 train batch accuracy: 0.90625 loss: 0.43001896142959595\n",
      "epoch: 11 batch: 75 train batch accuracy: 0.828125 loss: 0.6175856590270996\n",
      "epoch: 11 batch: 76 train batch accuracy: 0.890625 loss: 0.3427778482437134\n",
      "epoch: 11 batch: 77 train batch accuracy: 0.890625 loss: 0.3921157121658325\n",
      "epoch: 11 batch: 78 train batch accuracy: 0.71875 loss: 0.7429424524307251\n",
      "epoch: 11 batch: 79 train batch accuracy: 0.8125 loss: 0.5187603235244751\n",
      "epoch: 11 batch: 80 train batch accuracy: 0.859375 loss: 0.4304867088794708\n",
      "epoch: 11 batch: 81 train batch accuracy: 0.796875 loss: 0.6088409423828125\n",
      "epoch: 11 batch: 82 train batch accuracy: 0.828125 loss: 0.6021633744239807\n",
      "epoch: 11 batch: 83 train batch accuracy: 0.859375 loss: 0.5083577632904053\n",
      "epoch: 11 batch: 84 train batch accuracy: 0.734375 loss: 0.8089902400970459\n",
      "epoch: 11 batch: 85 train batch accuracy: 0.875 loss: 0.3970831632614136\n",
      "epoch: 11 batch: 86 train batch accuracy: 0.8125 loss: 0.5999776721000671\n",
      "epoch: 11 batch: 87 train batch accuracy: 0.78125 loss: 0.5861502885818481\n",
      "epoch: 11 batch: 88 train batch accuracy: 0.75 loss: 0.8012462854385376\n",
      "epoch: 11 batch: 89 train batch accuracy: 0.84375 loss: 0.5158487558364868\n",
      "epoch: 11 batch: 90 train batch accuracy: 0.875 loss: 0.440035879611969\n",
      "epoch: 11 batch: 91 train batch accuracy: 0.78125 loss: 0.6755569577217102\n",
      "epoch: 11 batch: 92 train batch accuracy: 0.890625 loss: 0.5256633758544922\n",
      "epoch: 11 batch: 93 train batch accuracy: 0.859375 loss: 0.4665781855583191\n",
      "Epoch 12/1000  average cost 0.612173529\n",
      "Epoch 12/1000  Test cost 2.586447239\n",
      "准确率: 0.515625\n",
      "Epoch 12/1000  模型保存成功\n",
      "epoch: 12 batch: 0 train batch accuracy: 0.84375 loss: 0.6501384377479553\n",
      "epoch: 12 batch: 1 train batch accuracy: 0.90625 loss: 0.42778781056404114\n",
      "epoch: 12 batch: 2 train batch accuracy: 0.859375 loss: 0.4151599407196045\n",
      "epoch: 12 batch: 3 train batch accuracy: 0.8125 loss: 0.616761326789856\n",
      "epoch: 12 batch: 4 train batch accuracy: 0.859375 loss: 0.5972871780395508\n",
      "epoch: 12 batch: 5 train batch accuracy: 0.90625 loss: 0.296847403049469\n",
      "epoch: 12 batch: 6 train batch accuracy: 0.796875 loss: 0.6358584761619568\n",
      "epoch: 12 batch: 7 train batch accuracy: 0.8125 loss: 0.626906156539917\n",
      "epoch: 12 batch: 8 train batch accuracy: 0.8125 loss: 0.583220362663269\n",
      "epoch: 12 batch: 9 train batch accuracy: 0.828125 loss: 0.5553258061408997\n",
      "epoch: 12 batch: 10 train batch accuracy: 0.796875 loss: 0.5345264673233032\n",
      "epoch: 12 batch: 11 train batch accuracy: 0.84375 loss: 0.505303144454956\n",
      "epoch: 12 batch: 12 train batch accuracy: 0.90625 loss: 0.43206486105918884\n",
      "epoch: 12 batch: 13 train batch accuracy: 0.796875 loss: 0.6801833510398865\n",
      "epoch: 12 batch: 14 train batch accuracy: 0.890625 loss: 0.3814306855201721\n",
      "epoch: 12 batch: 15 train batch accuracy: 0.9375 loss: 0.2340487241744995\n",
      "epoch: 12 batch: 16 train batch accuracy: 0.890625 loss: 0.4827975630760193\n",
      "epoch: 12 batch: 17 train batch accuracy: 0.65625 loss: 0.9286867380142212\n",
      "epoch: 12 batch: 18 train batch accuracy: 0.734375 loss: 0.8339755535125732\n",
      "epoch: 12 batch: 19 train batch accuracy: 0.84375 loss: 0.5381458401679993\n",
      "epoch: 12 batch: 20 train batch accuracy: 0.828125 loss: 0.5819751024246216\n",
      "epoch: 12 batch: 21 train batch accuracy: 0.859375 loss: 0.4129348397254944\n",
      "epoch: 12 batch: 22 train batch accuracy: 0.84375 loss: 0.6388006210327148\n",
      "epoch: 12 batch: 23 train batch accuracy: 0.6875 loss: 0.9011781215667725\n",
      "epoch: 12 batch: 24 train batch accuracy: 0.828125 loss: 0.5315333008766174\n",
      "epoch: 12 batch: 25 train batch accuracy: 0.8125 loss: 0.6070053577423096\n",
      "epoch: 12 batch: 26 train batch accuracy: 0.90625 loss: 0.5210462808609009\n",
      "epoch: 12 batch: 27 train batch accuracy: 0.859375 loss: 0.4204844534397125\n",
      "epoch: 12 batch: 28 train batch accuracy: 0.765625 loss: 0.7385770082473755\n",
      "epoch: 12 batch: 29 train batch accuracy: 0.859375 loss: 0.5084699392318726\n",
      "epoch: 12 batch: 30 train batch accuracy: 0.859375 loss: 0.5324498414993286\n",
      "epoch: 12 batch: 31 train batch accuracy: 0.828125 loss: 0.4811386466026306\n",
      "epoch: 12 batch: 32 train batch accuracy: 0.8125 loss: 0.6305716037750244\n",
      "epoch: 12 batch: 33 train batch accuracy: 0.8125 loss: 0.5104999542236328\n",
      "epoch: 12 batch: 34 train batch accuracy: 0.8125 loss: 0.502223551273346\n",
      "epoch: 12 batch: 35 train batch accuracy: 0.796875 loss: 0.49157342314720154\n",
      "epoch: 12 batch: 36 train batch accuracy: 0.84375 loss: 0.604800820350647\n",
      "epoch: 12 batch: 37 train batch accuracy: 0.828125 loss: 0.798960268497467\n",
      "epoch: 12 batch: 38 train batch accuracy: 0.84375 loss: 0.6521635055541992\n",
      "epoch: 12 batch: 39 train batch accuracy: 0.8125 loss: 0.6801246404647827\n",
      "epoch: 12 batch: 40 train batch accuracy: 0.765625 loss: 0.7713372707366943\n",
      "epoch: 12 batch: 41 train batch accuracy: 0.859375 loss: 0.45529961585998535\n",
      "epoch: 12 batch: 42 train batch accuracy: 0.71875 loss: 0.7773436307907104\n",
      "epoch: 12 batch: 43 train batch accuracy: 0.75 loss: 0.6796393394470215\n",
      "epoch: 12 batch: 44 train batch accuracy: 0.875 loss: 0.46028923988342285\n",
      "epoch: 12 batch: 45 train batch accuracy: 0.828125 loss: 0.4671468138694763\n",
      "epoch: 12 batch: 46 train batch accuracy: 0.765625 loss: 0.897631049156189\n",
      "epoch: 12 batch: 47 train batch accuracy: 0.890625 loss: 0.4437456727027893\n",
      "epoch: 12 batch: 48 train batch accuracy: 0.796875 loss: 0.5696529150009155\n",
      "epoch: 12 batch: 49 train batch accuracy: 0.765625 loss: 0.5504347681999207\n",
      "epoch: 12 batch: 50 train batch accuracy: 0.828125 loss: 0.5580272078514099\n",
      "epoch: 12 batch: 51 train batch accuracy: 0.828125 loss: 0.5927008390426636\n",
      "epoch: 12 batch: 52 train batch accuracy: 0.8125 loss: 0.5582826733589172\n",
      "epoch: 12 batch: 53 train batch accuracy: 0.765625 loss: 0.6317120790481567\n",
      "epoch: 12 batch: 54 train batch accuracy: 0.765625 loss: 0.8775253295898438\n",
      "epoch: 12 batch: 55 train batch accuracy: 0.796875 loss: 0.7251604795455933\n",
      "epoch: 12 batch: 56 train batch accuracy: 0.84375 loss: 0.5415096282958984\n",
      "epoch: 12 batch: 57 train batch accuracy: 0.859375 loss: 0.4275662899017334\n",
      "epoch: 12 batch: 58 train batch accuracy: 0.75 loss: 0.848336398601532\n",
      "epoch: 12 batch: 59 train batch accuracy: 0.953125 loss: 0.27690306305885315\n",
      "epoch: 12 batch: 60 train batch accuracy: 0.84375 loss: 0.5131943821907043\n",
      "epoch: 12 batch: 61 train batch accuracy: 0.71875 loss: 0.8595845699310303\n",
      "epoch: 12 batch: 62 train batch accuracy: 0.84375 loss: 0.42139169573783875\n",
      "epoch: 12 batch: 63 train batch accuracy: 0.859375 loss: 0.5416818857192993\n",
      "epoch: 12 batch: 64 train batch accuracy: 0.8125 loss: 0.5940007567405701\n",
      "epoch: 12 batch: 65 train batch accuracy: 0.84375 loss: 0.502334475517273\n",
      "epoch: 12 batch: 66 train batch accuracy: 0.859375 loss: 0.475543737411499\n",
      "epoch: 12 batch: 67 train batch accuracy: 0.875 loss: 0.4702316224575043\n",
      "epoch: 12 batch: 68 train batch accuracy: 0.703125 loss: 0.9013862013816833\n",
      "epoch: 12 batch: 69 train batch accuracy: 0.78125 loss: 0.5893504619598389\n",
      "epoch: 12 batch: 70 train batch accuracy: 0.828125 loss: 0.5379637479782104\n",
      "epoch: 12 batch: 71 train batch accuracy: 0.828125 loss: 0.5134190320968628\n",
      "epoch: 12 batch: 72 train batch accuracy: 0.875 loss: 0.42424526810646057\n",
      "epoch: 12 batch: 73 train batch accuracy: 0.765625 loss: 0.6646518707275391\n",
      "epoch: 12 batch: 74 train batch accuracy: 0.78125 loss: 0.6873270273208618\n",
      "epoch: 12 batch: 75 train batch accuracy: 0.84375 loss: 0.5600520968437195\n",
      "epoch: 12 batch: 76 train batch accuracy: 0.84375 loss: 0.4902080297470093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 batch: 77 train batch accuracy: 0.8125 loss: 0.5313637852668762\n",
      "epoch: 12 batch: 78 train batch accuracy: 0.90625 loss: 0.25145411491394043\n",
      "epoch: 12 batch: 79 train batch accuracy: 0.875 loss: 0.6202021241188049\n",
      "epoch: 12 batch: 80 train batch accuracy: 0.875 loss: 0.5705337524414062\n",
      "epoch: 12 batch: 81 train batch accuracy: 0.828125 loss: 0.6916283965110779\n",
      "epoch: 12 batch: 82 train batch accuracy: 0.875 loss: 0.39760708808898926\n",
      "epoch: 12 batch: 83 train batch accuracy: 0.890625 loss: 0.4463907480239868\n",
      "epoch: 12 batch: 84 train batch accuracy: 0.890625 loss: 0.501579999923706\n",
      "epoch: 12 batch: 85 train batch accuracy: 0.8125 loss: 0.6532649993896484\n",
      "epoch: 12 batch: 86 train batch accuracy: 0.90625 loss: 0.4622269868850708\n",
      "epoch: 12 batch: 87 train batch accuracy: 0.859375 loss: 0.5535217523574829\n",
      "epoch: 12 batch: 88 train batch accuracy: 0.890625 loss: 0.5583847165107727\n",
      "epoch: 12 batch: 89 train batch accuracy: 0.828125 loss: 0.5769183039665222\n",
      "epoch: 12 batch: 90 train batch accuracy: 0.828125 loss: 0.5090775489807129\n",
      "epoch: 12 batch: 91 train batch accuracy: 0.890625 loss: 0.4187750518321991\n",
      "epoch: 12 batch: 92 train batch accuracy: 0.84375 loss: 0.44297072291374207\n",
      "epoch: 12 batch: 93 train batch accuracy: 0.890625 loss: 0.4413294792175293\n",
      "Epoch 13/1000  average cost 0.565819232\n",
      "Epoch 13/1000  Test cost 1.358582497\n",
      "准确率: 0.6875\n",
      "Epoch 13/1000  模型保存成功\n",
      "epoch: 13 batch: 0 train batch accuracy: 0.859375 loss: 0.47485488653182983\n",
      "epoch: 13 batch: 1 train batch accuracy: 0.84375 loss: 0.4172038435935974\n",
      "epoch: 13 batch: 2 train batch accuracy: 0.90625 loss: 0.2834278345108032\n",
      "epoch: 13 batch: 3 train batch accuracy: 0.890625 loss: 0.4085671901702881\n",
      "epoch: 13 batch: 4 train batch accuracy: 0.890625 loss: 0.3122021555900574\n",
      "epoch: 13 batch: 5 train batch accuracy: 0.828125 loss: 0.6368943452835083\n",
      "epoch: 13 batch: 6 train batch accuracy: 0.890625 loss: 0.42988261580467224\n",
      "epoch: 13 batch: 7 train batch accuracy: 0.859375 loss: 0.6721370816230774\n",
      "epoch: 13 batch: 8 train batch accuracy: 0.8125 loss: 0.5705733299255371\n",
      "epoch: 13 batch: 9 train batch accuracy: 0.875 loss: 0.5621684789657593\n",
      "epoch: 13 batch: 10 train batch accuracy: 0.859375 loss: 0.44311830401420593\n",
      "epoch: 13 batch: 11 train batch accuracy: 0.828125 loss: 0.49174365401268005\n",
      "epoch: 13 batch: 12 train batch accuracy: 0.859375 loss: 0.5297290086746216\n",
      "epoch: 13 batch: 13 train batch accuracy: 0.890625 loss: 0.49953606724739075\n",
      "epoch: 13 batch: 14 train batch accuracy: 0.84375 loss: 0.581528902053833\n",
      "epoch: 13 batch: 15 train batch accuracy: 0.859375 loss: 0.4927319288253784\n",
      "epoch: 13 batch: 16 train batch accuracy: 0.875 loss: 0.4552958011627197\n",
      "epoch: 13 batch: 17 train batch accuracy: 0.796875 loss: 0.6691494584083557\n",
      "epoch: 13 batch: 18 train batch accuracy: 0.890625 loss: 0.3234618902206421\n",
      "epoch: 13 batch: 19 train batch accuracy: 0.875 loss: 0.4504167437553406\n",
      "epoch: 13 batch: 20 train batch accuracy: 0.875 loss: 0.373208224773407\n",
      "epoch: 13 batch: 21 train batch accuracy: 0.84375 loss: 0.44961631298065186\n",
      "epoch: 13 batch: 22 train batch accuracy: 0.75 loss: 0.6817080974578857\n",
      "epoch: 13 batch: 23 train batch accuracy: 0.8125 loss: 0.6330274343490601\n",
      "epoch: 13 batch: 24 train batch accuracy: 0.875 loss: 0.44660648703575134\n",
      "epoch: 13 batch: 25 train batch accuracy: 0.828125 loss: 0.3952402174472809\n",
      "epoch: 13 batch: 26 train batch accuracy: 0.9375 loss: 0.3819401264190674\n",
      "epoch: 13 batch: 27 train batch accuracy: 0.859375 loss: 0.6038349270820618\n",
      "epoch: 13 batch: 28 train batch accuracy: 0.921875 loss: 0.37661734223365784\n",
      "epoch: 13 batch: 29 train batch accuracy: 0.828125 loss: 0.6799849271774292\n",
      "epoch: 13 batch: 30 train batch accuracy: 0.84375 loss: 0.5144270658493042\n",
      "epoch: 13 batch: 31 train batch accuracy: 0.875 loss: 0.4240131378173828\n",
      "epoch: 13 batch: 32 train batch accuracy: 0.828125 loss: 0.48308536410331726\n",
      "epoch: 13 batch: 33 train batch accuracy: 0.90625 loss: 0.3594495356082916\n",
      "epoch: 13 batch: 34 train batch accuracy: 0.890625 loss: 0.4297666549682617\n",
      "epoch: 13 batch: 35 train batch accuracy: 0.78125 loss: 0.6005277633666992\n",
      "epoch: 13 batch: 36 train batch accuracy: 0.828125 loss: 0.653805136680603\n",
      "epoch: 13 batch: 37 train batch accuracy: 0.796875 loss: 0.6668614149093628\n",
      "epoch: 13 batch: 38 train batch accuracy: 0.8125 loss: 0.5642844438552856\n",
      "epoch: 13 batch: 39 train batch accuracy: 0.78125 loss: 0.523929238319397\n",
      "epoch: 13 batch: 40 train batch accuracy: 0.8125 loss: 0.5618215799331665\n",
      "epoch: 13 batch: 41 train batch accuracy: 0.90625 loss: 0.23142115771770477\n",
      "epoch: 13 batch: 42 train batch accuracy: 0.796875 loss: 0.609783411026001\n",
      "epoch: 13 batch: 43 train batch accuracy: 0.859375 loss: 0.4749849736690521\n",
      "epoch: 13 batch: 44 train batch accuracy: 0.859375 loss: 0.5661384463310242\n",
      "epoch: 13 batch: 45 train batch accuracy: 0.765625 loss: 0.6790153384208679\n",
      "epoch: 13 batch: 46 train batch accuracy: 0.90625 loss: 0.3423996865749359\n",
      "epoch: 13 batch: 47 train batch accuracy: 0.859375 loss: 0.4067653715610504\n",
      "epoch: 13 batch: 48 train batch accuracy: 0.765625 loss: 0.6138566732406616\n",
      "epoch: 13 batch: 49 train batch accuracy: 0.84375 loss: 0.4387035369873047\n",
      "epoch: 13 batch: 50 train batch accuracy: 0.796875 loss: 0.5719737410545349\n",
      "epoch: 13 batch: 51 train batch accuracy: 0.828125 loss: 0.5237067937850952\n",
      "epoch: 13 batch: 52 train batch accuracy: 0.9375 loss: 0.33547621965408325\n",
      "epoch: 13 batch: 53 train batch accuracy: 0.796875 loss: 0.5167038440704346\n",
      "epoch: 13 batch: 54 train batch accuracy: 0.828125 loss: 0.5911469459533691\n",
      "epoch: 13 batch: 55 train batch accuracy: 0.765625 loss: 0.5675055980682373\n",
      "epoch: 13 batch: 56 train batch accuracy: 0.84375 loss: 0.5911867618560791\n",
      "epoch: 13 batch: 57 train batch accuracy: 0.890625 loss: 0.37924349308013916\n",
      "epoch: 13 batch: 58 train batch accuracy: 0.84375 loss: 0.5557507276535034\n",
      "epoch: 13 batch: 59 train batch accuracy: 0.8125 loss: 0.5318280458450317\n",
      "epoch: 13 batch: 60 train batch accuracy: 0.78125 loss: 0.5718159675598145\n",
      "epoch: 13 batch: 61 train batch accuracy: 0.859375 loss: 0.28971391916275024\n",
      "epoch: 13 batch: 62 train batch accuracy: 0.875 loss: 0.39636921882629395\n",
      "epoch: 13 batch: 63 train batch accuracy: 0.828125 loss: 0.7178138494491577\n",
      "epoch: 13 batch: 64 train batch accuracy: 0.84375 loss: 0.545601487159729\n",
      "epoch: 13 batch: 65 train batch accuracy: 0.828125 loss: 0.65569007396698\n",
      "epoch: 13 batch: 66 train batch accuracy: 0.8125 loss: 0.5313383340835571\n",
      "epoch: 13 batch: 67 train batch accuracy: 0.828125 loss: 0.5479673147201538\n",
      "epoch: 13 batch: 68 train batch accuracy: 0.875 loss: 0.4474847912788391\n",
      "epoch: 13 batch: 69 train batch accuracy: 0.84375 loss: 0.5580065250396729\n",
      "epoch: 13 batch: 70 train batch accuracy: 0.859375 loss: 0.4908366799354553\n",
      "epoch: 13 batch: 71 train batch accuracy: 0.890625 loss: 0.38991743326187134\n",
      "epoch: 13 batch: 72 train batch accuracy: 0.84375 loss: 0.4902400076389313\n",
      "epoch: 13 batch: 73 train batch accuracy: 0.84375 loss: 0.4735856056213379\n",
      "epoch: 13 batch: 74 train batch accuracy: 0.796875 loss: 0.6188502311706543\n",
      "epoch: 13 batch: 75 train batch accuracy: 0.828125 loss: 0.43551596999168396\n",
      "epoch: 13 batch: 76 train batch accuracy: 0.828125 loss: 0.5486181974411011\n",
      "epoch: 13 batch: 77 train batch accuracy: 0.8125 loss: 0.5036838054656982\n",
      "epoch: 13 batch: 78 train batch accuracy: 0.859375 loss: 0.35665372014045715\n",
      "epoch: 13 batch: 79 train batch accuracy: 0.78125 loss: 0.7874900102615356\n",
      "epoch: 13 batch: 80 train batch accuracy: 0.84375 loss: 0.4728550612926483\n",
      "epoch: 13 batch: 81 train batch accuracy: 0.859375 loss: 0.45398545265197754\n",
      "epoch: 13 batch: 82 train batch accuracy: 0.828125 loss: 0.4969421625137329\n",
      "epoch: 13 batch: 83 train batch accuracy: 0.859375 loss: 0.4215009808540344\n",
      "epoch: 13 batch: 84 train batch accuracy: 0.84375 loss: 0.4798402190208435\n",
      "epoch: 13 batch: 85 train batch accuracy: 0.890625 loss: 0.3838927149772644\n",
      "epoch: 13 batch: 86 train batch accuracy: 0.84375 loss: 0.4961612820625305\n",
      "epoch: 13 batch: 87 train batch accuracy: 0.828125 loss: 0.7369325160980225\n",
      "epoch: 13 batch: 88 train batch accuracy: 0.84375 loss: 0.5378322005271912\n",
      "epoch: 13 batch: 89 train batch accuracy: 0.84375 loss: 0.3911747336387634\n",
      "epoch: 13 batch: 90 train batch accuracy: 0.8125 loss: 0.5974620580673218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 batch: 91 train batch accuracy: 0.890625 loss: 0.28857603669166565\n",
      "epoch: 13 batch: 92 train batch accuracy: 0.859375 loss: 0.45195144414901733\n",
      "epoch: 13 batch: 93 train batch accuracy: 0.859375 loss: 0.3631824553012848\n",
      "Epoch 14/1000  average cost 0.499632470\n",
      "Epoch 14/1000  Test cost 1.882493496\n",
      "准确率: 0.5625\n",
      "Epoch 14/1000  模型保存成功\n",
      "epoch: 14 batch: 0 train batch accuracy: 0.9375 loss: 0.30530816316604614\n",
      "epoch: 14 batch: 1 train batch accuracy: 0.9375 loss: 0.3159695863723755\n",
      "epoch: 14 batch: 2 train batch accuracy: 0.8125 loss: 0.6090195178985596\n",
      "epoch: 14 batch: 3 train batch accuracy: 0.875 loss: 0.35018041729927063\n",
      "epoch: 14 batch: 4 train batch accuracy: 0.890625 loss: 0.45719218254089355\n",
      "epoch: 14 batch: 5 train batch accuracy: 0.953125 loss: 0.3359561562538147\n",
      "epoch: 14 batch: 6 train batch accuracy: 0.890625 loss: 0.4210435152053833\n",
      "epoch: 14 batch: 7 train batch accuracy: 0.828125 loss: 0.4740862250328064\n",
      "epoch: 14 batch: 8 train batch accuracy: 0.875 loss: 0.45964688062667847\n",
      "epoch: 14 batch: 9 train batch accuracy: 0.9375 loss: 0.2508203983306885\n",
      "epoch: 14 batch: 10 train batch accuracy: 0.828125 loss: 0.4930850565433502\n",
      "epoch: 14 batch: 11 train batch accuracy: 0.796875 loss: 0.42240166664123535\n",
      "epoch: 14 batch: 12 train batch accuracy: 0.859375 loss: 0.5443074703216553\n",
      "epoch: 14 batch: 13 train batch accuracy: 0.8125 loss: 0.7579522132873535\n",
      "epoch: 14 batch: 14 train batch accuracy: 0.859375 loss: 0.4288032054901123\n",
      "epoch: 14 batch: 15 train batch accuracy: 0.859375 loss: 0.40173834562301636\n",
      "epoch: 14 batch: 16 train batch accuracy: 0.875 loss: 0.3675670623779297\n",
      "epoch: 14 batch: 17 train batch accuracy: 0.90625 loss: 0.4183492660522461\n",
      "epoch: 14 batch: 18 train batch accuracy: 0.84375 loss: 0.553774356842041\n",
      "epoch: 14 batch: 19 train batch accuracy: 0.859375 loss: 0.5243620872497559\n",
      "epoch: 14 batch: 20 train batch accuracy: 0.9375 loss: 0.3859235942363739\n",
      "epoch: 14 batch: 21 train batch accuracy: 0.84375 loss: 0.5070714950561523\n",
      "epoch: 14 batch: 22 train batch accuracy: 0.765625 loss: 0.6527848243713379\n",
      "epoch: 14 batch: 23 train batch accuracy: 0.828125 loss: 0.4769577980041504\n",
      "epoch: 14 batch: 24 train batch accuracy: 0.84375 loss: 0.5318129658699036\n",
      "epoch: 14 batch: 25 train batch accuracy: 0.90625 loss: 0.25204238295555115\n",
      "epoch: 14 batch: 26 train batch accuracy: 0.90625 loss: 0.3550500273704529\n",
      "epoch: 14 batch: 27 train batch accuracy: 0.90625 loss: 0.30723246932029724\n",
      "epoch: 14 batch: 28 train batch accuracy: 0.78125 loss: 0.7846221923828125\n",
      "epoch: 14 batch: 29 train batch accuracy: 0.8125 loss: 0.5791527032852173\n",
      "epoch: 14 batch: 30 train batch accuracy: 0.90625 loss: 0.31935539841651917\n",
      "epoch: 14 batch: 31 train batch accuracy: 0.859375 loss: 0.33963343501091003\n",
      "epoch: 14 batch: 32 train batch accuracy: 0.84375 loss: 0.5331812500953674\n",
      "epoch: 14 batch: 33 train batch accuracy: 0.859375 loss: 0.39225953817367554\n",
      "epoch: 14 batch: 34 train batch accuracy: 0.984375 loss: 0.22015225887298584\n",
      "epoch: 14 batch: 35 train batch accuracy: 0.828125 loss: 0.6257902383804321\n",
      "epoch: 14 batch: 36 train batch accuracy: 0.875 loss: 0.44309335947036743\n",
      "epoch: 14 batch: 37 train batch accuracy: 0.953125 loss: 0.2781429886817932\n",
      "epoch: 14 batch: 38 train batch accuracy: 0.953125 loss: 0.22858044505119324\n",
      "epoch: 14 batch: 39 train batch accuracy: 0.84375 loss: 0.5423645973205566\n",
      "epoch: 14 batch: 40 train batch accuracy: 0.84375 loss: 0.4719347357749939\n",
      "epoch: 14 batch: 41 train batch accuracy: 0.828125 loss: 0.5479539632797241\n",
      "epoch: 14 batch: 42 train batch accuracy: 0.84375 loss: 0.6822677850723267\n",
      "epoch: 14 batch: 43 train batch accuracy: 0.84375 loss: 0.5052261352539062\n",
      "epoch: 14 batch: 44 train batch accuracy: 0.875 loss: 0.402059406042099\n",
      "epoch: 14 batch: 45 train batch accuracy: 0.90625 loss: 0.4013866186141968\n",
      "epoch: 14 batch: 46 train batch accuracy: 0.8125 loss: 0.4919498562812805\n",
      "epoch: 14 batch: 47 train batch accuracy: 0.90625 loss: 0.40014252066612244\n",
      "epoch: 14 batch: 48 train batch accuracy: 0.921875 loss: 0.49675387144088745\n",
      "epoch: 14 batch: 49 train batch accuracy: 0.921875 loss: 0.32513272762298584\n",
      "epoch: 14 batch: 50 train batch accuracy: 0.828125 loss: 0.5513858199119568\n",
      "epoch: 14 batch: 51 train batch accuracy: 0.90625 loss: 0.4651210904121399\n",
      "epoch: 14 batch: 52 train batch accuracy: 0.875 loss: 0.4398563504219055\n",
      "epoch: 14 batch: 53 train batch accuracy: 0.921875 loss: 0.37880241870880127\n",
      "epoch: 14 batch: 54 train batch accuracy: 0.84375 loss: 0.46144068241119385\n",
      "epoch: 14 batch: 55 train batch accuracy: 0.859375 loss: 0.409446656703949\n",
      "epoch: 14 batch: 56 train batch accuracy: 0.875 loss: 0.4064837396144867\n",
      "epoch: 14 batch: 57 train batch accuracy: 0.765625 loss: 0.7181904315948486\n",
      "epoch: 14 batch: 58 train batch accuracy: 0.828125 loss: 0.5520049929618835\n",
      "epoch: 14 batch: 59 train batch accuracy: 0.890625 loss: 0.3536520004272461\n",
      "epoch: 14 batch: 60 train batch accuracy: 0.84375 loss: 0.580350935459137\n",
      "epoch: 14 batch: 61 train batch accuracy: 0.921875 loss: 0.29295647144317627\n",
      "epoch: 14 batch: 62 train batch accuracy: 0.890625 loss: 0.3868247866630554\n",
      "epoch: 14 batch: 63 train batch accuracy: 0.921875 loss: 0.23537257313728333\n",
      "epoch: 14 batch: 64 train batch accuracy: 0.859375 loss: 0.38011297583580017\n",
      "epoch: 14 batch: 65 train batch accuracy: 0.875 loss: 0.3841618299484253\n",
      "epoch: 14 batch: 66 train batch accuracy: 0.875 loss: 0.46275436878204346\n",
      "epoch: 14 batch: 67 train batch accuracy: 0.859375 loss: 0.5325920581817627\n",
      "epoch: 14 batch: 68 train batch accuracy: 0.875 loss: 0.3802782893180847\n",
      "epoch: 14 batch: 69 train batch accuracy: 0.859375 loss: 0.37371185421943665\n",
      "epoch: 14 batch: 70 train batch accuracy: 0.859375 loss: 0.3103650212287903\n",
      "epoch: 14 batch: 71 train batch accuracy: 0.875 loss: 0.386417418718338\n",
      "epoch: 14 batch: 72 train batch accuracy: 0.890625 loss: 0.42859822511672974\n",
      "epoch: 14 batch: 73 train batch accuracy: 0.90625 loss: 0.3252609372138977\n",
      "epoch: 14 batch: 74 train batch accuracy: 0.953125 loss: 0.1785636991262436\n",
      "epoch: 14 batch: 75 train batch accuracy: 0.859375 loss: 0.4186113476753235\n",
      "epoch: 14 batch: 76 train batch accuracy: 0.875 loss: 0.33483338356018066\n",
      "epoch: 14 batch: 77 train batch accuracy: 0.875 loss: 0.5300472974777222\n",
      "epoch: 14 batch: 78 train batch accuracy: 0.84375 loss: 0.3934743404388428\n",
      "epoch: 14 batch: 79 train batch accuracy: 0.90625 loss: 0.25645631551742554\n",
      "epoch: 14 batch: 80 train batch accuracy: 0.890625 loss: 0.3032459020614624\n",
      "epoch: 14 batch: 81 train batch accuracy: 0.96875 loss: 0.14909158647060394\n",
      "epoch: 14 batch: 82 train batch accuracy: 0.875 loss: 0.43042808771133423\n",
      "epoch: 14 batch: 83 train batch accuracy: 0.875 loss: 0.31870707869529724\n",
      "epoch: 14 batch: 84 train batch accuracy: 0.90625 loss: 0.3370802104473114\n",
      "epoch: 14 batch: 85 train batch accuracy: 0.890625 loss: 0.4377341568470001\n",
      "epoch: 14 batch: 86 train batch accuracy: 0.828125 loss: 0.3642713725566864\n",
      "epoch: 14 batch: 87 train batch accuracy: 0.890625 loss: 0.31774088740348816\n",
      "epoch: 14 batch: 88 train batch accuracy: 0.8125 loss: 0.7195591926574707\n",
      "epoch: 14 batch: 89 train batch accuracy: 0.9375 loss: 0.20772796869277954\n",
      "epoch: 14 batch: 90 train batch accuracy: 0.90625 loss: 0.22133895754814148\n",
      "epoch: 14 batch: 91 train batch accuracy: 0.828125 loss: 0.5227152109146118\n",
      "epoch: 14 batch: 92 train batch accuracy: 0.78125 loss: 0.5297797918319702\n",
      "epoch: 14 batch: 93 train batch accuracy: 0.78125 loss: 0.6192865967750549\n",
      "Epoch 15/1000  average cost 0.427217135\n",
      "Epoch 15/1000  Test cost 1.737293959\n",
      "准确率: 0.640625\n",
      "Epoch 15/1000  模型保存成功\n",
      "epoch: 15 batch: 0 train batch accuracy: 0.875 loss: 0.3863244652748108\n",
      "epoch: 15 batch: 1 train batch accuracy: 0.875 loss: 0.3823714852333069\n",
      "epoch: 15 batch: 2 train batch accuracy: 0.8125 loss: 0.5543805360794067\n",
      "epoch: 15 batch: 3 train batch accuracy: 0.875 loss: 0.42875242233276367\n",
      "epoch: 15 batch: 4 train batch accuracy: 0.828125 loss: 0.49878785014152527\n",
      "epoch: 15 batch: 5 train batch accuracy: 0.890625 loss: 0.3842683434486389\n",
      "epoch: 15 batch: 6 train batch accuracy: 0.828125 loss: 0.5459825992584229\n",
      "epoch: 15 batch: 7 train batch accuracy: 0.828125 loss: 0.4650276303291321\n",
      "epoch: 15 batch: 8 train batch accuracy: 0.875 loss: 0.4514618515968323\n",
      "epoch: 15 batch: 9 train batch accuracy: 0.953125 loss: 0.23714837431907654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 batch: 10 train batch accuracy: 0.890625 loss: 0.22363299131393433\n",
      "epoch: 15 batch: 11 train batch accuracy: 0.734375 loss: 0.6670187711715698\n",
      "epoch: 15 batch: 12 train batch accuracy: 0.921875 loss: 0.2201882004737854\n",
      "epoch: 15 batch: 13 train batch accuracy: 0.859375 loss: 0.4788072109222412\n",
      "epoch: 15 batch: 14 train batch accuracy: 0.90625 loss: 0.30081549286842346\n",
      "epoch: 15 batch: 15 train batch accuracy: 0.90625 loss: 0.23790669441223145\n",
      "epoch: 15 batch: 16 train batch accuracy: 0.875 loss: 0.43355002999305725\n",
      "epoch: 15 batch: 17 train batch accuracy: 0.890625 loss: 0.4126602113246918\n",
      "epoch: 15 batch: 18 train batch accuracy: 0.859375 loss: 0.5578804016113281\n",
      "epoch: 15 batch: 19 train batch accuracy: 0.65625 loss: 0.9280272722244263\n",
      "epoch: 15 batch: 20 train batch accuracy: 0.921875 loss: 0.34328678250312805\n",
      "epoch: 15 batch: 21 train batch accuracy: 0.84375 loss: 0.377670019865036\n",
      "epoch: 15 batch: 22 train batch accuracy: 0.828125 loss: 0.4517036974430084\n",
      "epoch: 15 batch: 23 train batch accuracy: 0.890625 loss: 0.31025511026382446\n",
      "epoch: 15 batch: 24 train batch accuracy: 0.875 loss: 0.3549429476261139\n",
      "epoch: 15 batch: 25 train batch accuracy: 0.875 loss: 0.44742947816848755\n",
      "epoch: 15 batch: 26 train batch accuracy: 0.875 loss: 0.36374977231025696\n",
      "epoch: 15 batch: 27 train batch accuracy: 0.96875 loss: 0.23701715469360352\n",
      "epoch: 15 batch: 28 train batch accuracy: 0.84375 loss: 0.5917626619338989\n",
      "epoch: 15 batch: 29 train batch accuracy: 0.859375 loss: 0.4231131970882416\n",
      "epoch: 15 batch: 30 train batch accuracy: 0.796875 loss: 0.6578238606452942\n",
      "epoch: 15 batch: 31 train batch accuracy: 0.859375 loss: 0.3918116092681885\n",
      "epoch: 15 batch: 32 train batch accuracy: 0.9375 loss: 0.19736960530281067\n",
      "epoch: 15 batch: 33 train batch accuracy: 0.84375 loss: 0.4763433337211609\n",
      "epoch: 15 batch: 34 train batch accuracy: 0.859375 loss: 0.4155685603618622\n",
      "epoch: 15 batch: 35 train batch accuracy: 0.921875 loss: 0.2975000739097595\n",
      "epoch: 15 batch: 36 train batch accuracy: 0.859375 loss: 0.3922384977340698\n",
      "epoch: 15 batch: 37 train batch accuracy: 0.78125 loss: 0.6879488229751587\n",
      "epoch: 15 batch: 38 train batch accuracy: 0.8125 loss: 0.7002602815628052\n",
      "epoch: 15 batch: 39 train batch accuracy: 0.8125 loss: 0.40792638063430786\n",
      "epoch: 15 batch: 40 train batch accuracy: 0.796875 loss: 0.48098957538604736\n",
      "epoch: 15 batch: 41 train batch accuracy: 0.84375 loss: 0.42284825444221497\n",
      "epoch: 15 batch: 42 train batch accuracy: 0.84375 loss: 0.4930121600627899\n",
      "epoch: 15 batch: 43 train batch accuracy: 0.859375 loss: 0.4412705898284912\n",
      "epoch: 15 batch: 44 train batch accuracy: 0.953125 loss: 0.2864881753921509\n",
      "epoch: 15 batch: 45 train batch accuracy: 0.921875 loss: 0.25710660219192505\n",
      "epoch: 15 batch: 46 train batch accuracy: 0.84375 loss: 0.5591955184936523\n",
      "epoch: 15 batch: 47 train batch accuracy: 0.8125 loss: 0.622632622718811\n",
      "epoch: 15 batch: 48 train batch accuracy: 0.875 loss: 0.5018087029457092\n",
      "epoch: 15 batch: 49 train batch accuracy: 0.828125 loss: 0.45812875032424927\n",
      "epoch: 15 batch: 50 train batch accuracy: 0.84375 loss: 0.4815315902233124\n",
      "epoch: 15 batch: 51 train batch accuracy: 0.875 loss: 0.44426730275154114\n",
      "epoch: 15 batch: 52 train batch accuracy: 0.84375 loss: 0.45443230867385864\n",
      "epoch: 15 batch: 53 train batch accuracy: 0.984375 loss: 0.1263188123703003\n",
      "epoch: 15 batch: 54 train batch accuracy: 0.859375 loss: 0.3673539459705353\n",
      "epoch: 15 batch: 55 train batch accuracy: 0.828125 loss: 0.4260883927345276\n",
      "epoch: 15 batch: 56 train batch accuracy: 0.84375 loss: 0.46469807624816895\n",
      "epoch: 15 batch: 57 train batch accuracy: 0.890625 loss: 0.4497351050376892\n",
      "epoch: 15 batch: 58 train batch accuracy: 0.875 loss: 0.4974340796470642\n",
      "epoch: 15 batch: 59 train batch accuracy: 0.828125 loss: 0.4833680987358093\n",
      "epoch: 15 batch: 60 train batch accuracy: 0.875 loss: 0.38579198718070984\n",
      "epoch: 15 batch: 61 train batch accuracy: 0.9375 loss: 0.23843324184417725\n",
      "epoch: 15 batch: 62 train batch accuracy: 0.875 loss: 0.40566545724868774\n",
      "epoch: 15 batch: 63 train batch accuracy: 0.9375 loss: 0.2581102252006531\n",
      "epoch: 15 batch: 64 train batch accuracy: 0.9375 loss: 0.2800099849700928\n",
      "epoch: 15 batch: 65 train batch accuracy: 0.84375 loss: 0.40103837847709656\n",
      "epoch: 15 batch: 66 train batch accuracy: 0.859375 loss: 0.4726491868495941\n",
      "epoch: 15 batch: 67 train batch accuracy: 0.8125 loss: 0.4965006709098816\n",
      "epoch: 15 batch: 68 train batch accuracy: 0.8125 loss: 0.5744373202323914\n",
      "epoch: 15 batch: 69 train batch accuracy: 0.90625 loss: 0.2839711904525757\n",
      "epoch: 15 batch: 70 train batch accuracy: 0.921875 loss: 0.31178155541419983\n",
      "epoch: 15 batch: 71 train batch accuracy: 0.890625 loss: 0.34438443183898926\n",
      "epoch: 15 batch: 72 train batch accuracy: 0.890625 loss: 0.3188856244087219\n",
      "epoch: 15 batch: 73 train batch accuracy: 0.90625 loss: 0.33734866976737976\n",
      "epoch: 15 batch: 74 train batch accuracy: 0.875 loss: 0.46079587936401367\n",
      "epoch: 15 batch: 75 train batch accuracy: 0.78125 loss: 0.6208457946777344\n",
      "epoch: 15 batch: 76 train batch accuracy: 0.8125 loss: 0.4679120182991028\n",
      "epoch: 15 batch: 77 train batch accuracy: 0.921875 loss: 0.34618398547172546\n",
      "epoch: 15 batch: 78 train batch accuracy: 0.953125 loss: 0.18436726927757263\n",
      "epoch: 15 batch: 79 train batch accuracy: 0.921875 loss: 0.2876918911933899\n",
      "epoch: 15 batch: 80 train batch accuracy: 0.9375 loss: 0.2210565060377121\n",
      "epoch: 15 batch: 81 train batch accuracy: 0.9375 loss: 0.29259371757507324\n",
      "epoch: 15 batch: 82 train batch accuracy: 0.828125 loss: 0.4903694689273834\n",
      "epoch: 15 batch: 83 train batch accuracy: 0.84375 loss: 0.4644056558609009\n",
      "epoch: 15 batch: 84 train batch accuracy: 0.859375 loss: 0.33622175455093384\n",
      "epoch: 15 batch: 85 train batch accuracy: 0.90625 loss: 0.3725074529647827\n",
      "epoch: 15 batch: 86 train batch accuracy: 0.875 loss: 0.32503604888916016\n",
      "epoch: 15 batch: 87 train batch accuracy: 0.796875 loss: 0.4794559180736542\n",
      "epoch: 15 batch: 88 train batch accuracy: 0.859375 loss: 0.3885580897331238\n",
      "epoch: 15 batch: 89 train batch accuracy: 0.84375 loss: 0.3902803659439087\n",
      "epoch: 15 batch: 90 train batch accuracy: 0.890625 loss: 0.3145957887172699\n",
      "epoch: 15 batch: 91 train batch accuracy: 0.875 loss: 0.36416077613830566\n",
      "epoch: 15 batch: 92 train batch accuracy: 0.84375 loss: 0.4055880904197693\n",
      "epoch: 15 batch: 93 train batch accuracy: 0.90625 loss: 0.39585912227630615\n",
      "Epoch 16/1000  average cost 0.412307626\n",
      "Epoch 16/1000  Test cost 3.076350212\n",
      "准确率: 0.46875\n",
      "Epoch 16/1000  模型保存成功\n",
      "epoch: 16 batch: 0 train batch accuracy: 0.96875 loss: 0.155879408121109\n",
      "epoch: 16 batch: 1 train batch accuracy: 0.796875 loss: 0.719367504119873\n",
      "epoch: 16 batch: 2 train batch accuracy: 0.828125 loss: 0.491706907749176\n",
      "epoch: 16 batch: 3 train batch accuracy: 0.8125 loss: 0.4255739450454712\n",
      "epoch: 16 batch: 4 train batch accuracy: 0.859375 loss: 0.5103021264076233\n",
      "epoch: 16 batch: 5 train batch accuracy: 0.859375 loss: 0.46847110986709595\n",
      "epoch: 16 batch: 6 train batch accuracy: 0.9375 loss: 0.22090183198451996\n",
      "epoch: 16 batch: 7 train batch accuracy: 0.84375 loss: 0.4178609848022461\n",
      "epoch: 16 batch: 8 train batch accuracy: 0.765625 loss: 0.7016515731811523\n",
      "epoch: 16 batch: 9 train batch accuracy: 0.875 loss: 0.3884897530078888\n",
      "epoch: 16 batch: 10 train batch accuracy: 0.921875 loss: 0.2826972007751465\n",
      "epoch: 16 batch: 11 train batch accuracy: 0.890625 loss: 0.3681718111038208\n",
      "epoch: 16 batch: 12 train batch accuracy: 0.765625 loss: 0.7077972888946533\n",
      "epoch: 16 batch: 13 train batch accuracy: 0.875 loss: 0.48722490668296814\n",
      "epoch: 16 batch: 14 train batch accuracy: 0.9375 loss: 0.2761852741241455\n",
      "epoch: 16 batch: 15 train batch accuracy: 0.859375 loss: 0.4007524847984314\n",
      "epoch: 16 batch: 16 train batch accuracy: 0.9375 loss: 0.19129061698913574\n",
      "epoch: 16 batch: 17 train batch accuracy: 0.890625 loss: 0.37429630756378174\n",
      "epoch: 16 batch: 18 train batch accuracy: 0.875 loss: 0.555637538433075\n",
      "epoch: 16 batch: 19 train batch accuracy: 0.84375 loss: 0.37616652250289917\n",
      "epoch: 16 batch: 20 train batch accuracy: 0.78125 loss: 0.6803843975067139\n",
      "epoch: 16 batch: 21 train batch accuracy: 0.9375 loss: 0.33354949951171875\n",
      "epoch: 16 batch: 22 train batch accuracy: 0.796875 loss: 0.5056217908859253\n",
      "epoch: 16 batch: 23 train batch accuracy: 0.8125 loss: 0.513302743434906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 batch: 24 train batch accuracy: 0.84375 loss: 0.45889031887054443\n",
      "epoch: 16 batch: 25 train batch accuracy: 0.921875 loss: 0.2570948004722595\n",
      "epoch: 16 batch: 26 train batch accuracy: 0.921875 loss: 0.3158026337623596\n",
      "epoch: 16 batch: 27 train batch accuracy: 0.859375 loss: 0.4161135256290436\n",
      "epoch: 16 batch: 28 train batch accuracy: 0.9375 loss: 0.22894297540187836\n",
      "epoch: 16 batch: 29 train batch accuracy: 0.921875 loss: 0.24146747589111328\n",
      "epoch: 16 batch: 30 train batch accuracy: 0.9375 loss: 0.24924777448177338\n",
      "epoch: 16 batch: 31 train batch accuracy: 0.953125 loss: 0.3055519163608551\n",
      "epoch: 16 batch: 32 train batch accuracy: 0.9375 loss: 0.18158118426799774\n",
      "epoch: 16 batch: 33 train batch accuracy: 0.890625 loss: 0.2817528545856476\n",
      "epoch: 16 batch: 34 train batch accuracy: 0.890625 loss: 0.3008652925491333\n",
      "epoch: 16 batch: 35 train batch accuracy: 0.890625 loss: 0.32819706201553345\n",
      "epoch: 16 batch: 36 train batch accuracy: 0.875 loss: 0.38510704040527344\n",
      "epoch: 16 batch: 37 train batch accuracy: 0.9375 loss: 0.20845605432987213\n",
      "epoch: 16 batch: 38 train batch accuracy: 0.84375 loss: 0.6881664991378784\n",
      "epoch: 16 batch: 39 train batch accuracy: 0.921875 loss: 0.26160576939582825\n",
      "epoch: 16 batch: 40 train batch accuracy: 0.8125 loss: 0.5855693817138672\n",
      "epoch: 16 batch: 41 train batch accuracy: 0.84375 loss: 0.5231418609619141\n",
      "epoch: 16 batch: 42 train batch accuracy: 0.921875 loss: 0.33485206961631775\n",
      "epoch: 16 batch: 43 train batch accuracy: 0.859375 loss: 0.4555179476737976\n",
      "epoch: 16 batch: 44 train batch accuracy: 0.875 loss: 0.4813956618309021\n",
      "epoch: 16 batch: 45 train batch accuracy: 0.796875 loss: 0.6819062232971191\n",
      "epoch: 16 batch: 46 train batch accuracy: 0.875 loss: 0.4516414999961853\n",
      "epoch: 16 batch: 47 train batch accuracy: 0.875 loss: 0.3248969316482544\n",
      "epoch: 16 batch: 48 train batch accuracy: 0.9375 loss: 0.30774301290512085\n",
      "epoch: 16 batch: 49 train batch accuracy: 0.90625 loss: 0.2780570983886719\n",
      "epoch: 16 batch: 50 train batch accuracy: 0.90625 loss: 0.2991969585418701\n",
      "epoch: 16 batch: 51 train batch accuracy: 0.96875 loss: 0.19218137860298157\n",
      "epoch: 16 batch: 52 train batch accuracy: 0.84375 loss: 0.4199477434158325\n",
      "epoch: 16 batch: 53 train batch accuracy: 0.875 loss: 0.40764206647872925\n",
      "epoch: 16 batch: 54 train batch accuracy: 0.859375 loss: 0.42484205961227417\n",
      "epoch: 16 batch: 55 train batch accuracy: 0.9375 loss: 0.26930806040763855\n",
      "epoch: 16 batch: 56 train batch accuracy: 0.921875 loss: 0.3459463119506836\n",
      "epoch: 16 batch: 57 train batch accuracy: 0.84375 loss: 0.4216527044773102\n",
      "epoch: 16 batch: 58 train batch accuracy: 0.90625 loss: 0.3615747094154358\n",
      "epoch: 16 batch: 59 train batch accuracy: 0.875 loss: 0.3163851797580719\n",
      "epoch: 16 batch: 60 train batch accuracy: 0.8125 loss: 0.5114254951477051\n",
      "epoch: 16 batch: 61 train batch accuracy: 0.90625 loss: 0.3396327793598175\n",
      "epoch: 16 batch: 62 train batch accuracy: 0.875 loss: 0.4546985328197479\n",
      "epoch: 16 batch: 63 train batch accuracy: 0.90625 loss: 0.2853541970252991\n",
      "epoch: 16 batch: 64 train batch accuracy: 0.84375 loss: 0.5398930907249451\n",
      "epoch: 16 batch: 65 train batch accuracy: 0.921875 loss: 0.3457529544830322\n",
      "epoch: 16 batch: 66 train batch accuracy: 0.9375 loss: 0.2566048800945282\n",
      "epoch: 16 batch: 67 train batch accuracy: 0.9375 loss: 0.20706820487976074\n",
      "epoch: 16 batch: 68 train batch accuracy: 0.890625 loss: 0.26923584938049316\n",
      "epoch: 16 batch: 69 train batch accuracy: 0.9375 loss: 0.19819337129592896\n",
      "epoch: 16 batch: 70 train batch accuracy: 0.890625 loss: 0.4742830991744995\n",
      "epoch: 16 batch: 71 train batch accuracy: 0.921875 loss: 0.24971014261245728\n",
      "epoch: 16 batch: 72 train batch accuracy: 0.90625 loss: 0.31806236505508423\n",
      "epoch: 16 batch: 73 train batch accuracy: 0.9375 loss: 0.3474448621273041\n",
      "epoch: 16 batch: 74 train batch accuracy: 0.96875 loss: 0.152645081281662\n",
      "epoch: 16 batch: 75 train batch accuracy: 0.890625 loss: 0.3334561288356781\n",
      "epoch: 16 batch: 76 train batch accuracy: 0.96875 loss: 0.1554688960313797\n",
      "epoch: 16 batch: 77 train batch accuracy: 0.90625 loss: 0.28807684779167175\n",
      "epoch: 16 batch: 78 train batch accuracy: 0.828125 loss: 0.6713932156562805\n",
      "epoch: 16 batch: 79 train batch accuracy: 0.96875 loss: 0.12196924537420273\n",
      "epoch: 16 batch: 80 train batch accuracy: 0.953125 loss: 0.13139742612838745\n",
      "epoch: 16 batch: 81 train batch accuracy: 0.96875 loss: 0.1562747061252594\n",
      "epoch: 16 batch: 82 train batch accuracy: 0.953125 loss: 0.23830267786979675\n",
      "epoch: 16 batch: 83 train batch accuracy: 0.84375 loss: 0.3750517666339874\n",
      "epoch: 16 batch: 84 train batch accuracy: 0.828125 loss: 0.4683055579662323\n",
      "epoch: 16 batch: 85 train batch accuracy: 0.890625 loss: 0.3634718060493469\n",
      "epoch: 16 batch: 86 train batch accuracy: 0.90625 loss: 0.2287023812532425\n",
      "epoch: 16 batch: 87 train batch accuracy: 0.84375 loss: 0.41769862174987793\n",
      "epoch: 16 batch: 88 train batch accuracy: 0.90625 loss: 0.4645748436450958\n",
      "epoch: 16 batch: 89 train batch accuracy: 0.859375 loss: 0.38019275665283203\n",
      "epoch: 16 batch: 90 train batch accuracy: 0.84375 loss: 0.4574156105518341\n",
      "epoch: 16 batch: 91 train batch accuracy: 0.875 loss: 0.4830207824707031\n",
      "epoch: 16 batch: 92 train batch accuracy: 0.875 loss: 0.3659476041793823\n",
      "epoch: 16 batch: 93 train batch accuracy: 0.890625 loss: 0.43410974740982056\n",
      "Epoch 17/1000  average cost 0.372663416\n",
      "Epoch 17/1000  Test cost 1.614786863\n",
      "准确率: 0.578125\n",
      "Epoch 17/1000  模型保存成功\n",
      "epoch: 17 batch: 0 train batch accuracy: 0.8125 loss: 0.37413060665130615\n",
      "epoch: 17 batch: 1 train batch accuracy: 0.890625 loss: 0.32315361499786377\n",
      "epoch: 17 batch: 2 train batch accuracy: 0.875 loss: 0.37369009852409363\n",
      "epoch: 17 batch: 3 train batch accuracy: 0.84375 loss: 0.44345951080322266\n",
      "epoch: 17 batch: 4 train batch accuracy: 0.828125 loss: 0.5052616596221924\n",
      "epoch: 17 batch: 5 train batch accuracy: 0.84375 loss: 0.3745225965976715\n",
      "epoch: 17 batch: 6 train batch accuracy: 0.921875 loss: 0.3047558069229126\n",
      "epoch: 17 batch: 7 train batch accuracy: 0.875 loss: 0.41366046667099\n",
      "epoch: 17 batch: 8 train batch accuracy: 0.921875 loss: 0.22392109036445618\n",
      "epoch: 17 batch: 9 train batch accuracy: 0.875 loss: 0.3779611587524414\n",
      "epoch: 17 batch: 10 train batch accuracy: 0.921875 loss: 0.2714473605155945\n",
      "epoch: 17 batch: 11 train batch accuracy: 0.921875 loss: 0.25795862078666687\n",
      "epoch: 17 batch: 12 train batch accuracy: 0.90625 loss: 0.308124303817749\n",
      "epoch: 17 batch: 13 train batch accuracy: 0.8125 loss: 0.4651813209056854\n",
      "epoch: 17 batch: 14 train batch accuracy: 0.921875 loss: 0.2396819293498993\n",
      "epoch: 17 batch: 15 train batch accuracy: 0.84375 loss: 0.42662620544433594\n",
      "epoch: 17 batch: 16 train batch accuracy: 0.90625 loss: 0.2823947072029114\n",
      "epoch: 17 batch: 17 train batch accuracy: 0.90625 loss: 0.3853505849838257\n",
      "epoch: 17 batch: 18 train batch accuracy: 0.890625 loss: 0.31111466884613037\n",
      "epoch: 17 batch: 19 train batch accuracy: 0.9375 loss: 0.20767515897750854\n",
      "epoch: 17 batch: 20 train batch accuracy: 0.875 loss: 0.480316698551178\n",
      "epoch: 17 batch: 21 train batch accuracy: 0.90625 loss: 0.22718766331672668\n",
      "epoch: 17 batch: 22 train batch accuracy: 0.90625 loss: 0.24022655189037323\n",
      "epoch: 17 batch: 23 train batch accuracy: 0.890625 loss: 0.3813076913356781\n",
      "epoch: 17 batch: 24 train batch accuracy: 0.90625 loss: 0.36350536346435547\n",
      "epoch: 17 batch: 25 train batch accuracy: 0.90625 loss: 0.30782443284988403\n",
      "epoch: 17 batch: 26 train batch accuracy: 0.921875 loss: 0.37990906834602356\n",
      "epoch: 17 batch: 27 train batch accuracy: 0.875 loss: 0.3097527325153351\n",
      "epoch: 17 batch: 28 train batch accuracy: 0.96875 loss: 0.128788560628891\n",
      "epoch: 17 batch: 29 train batch accuracy: 0.875 loss: 0.35210609436035156\n",
      "epoch: 17 batch: 30 train batch accuracy: 0.875 loss: 0.2849058508872986\n",
      "epoch: 17 batch: 31 train batch accuracy: 0.9375 loss: 0.17856355011463165\n",
      "epoch: 17 batch: 32 train batch accuracy: 0.90625 loss: 0.3592815101146698\n",
      "epoch: 17 batch: 33 train batch accuracy: 0.921875 loss: 0.24058501422405243\n",
      "epoch: 17 batch: 34 train batch accuracy: 0.90625 loss: 0.31666409969329834\n",
      "epoch: 17 batch: 35 train batch accuracy: 0.859375 loss: 0.4384237229824066\n",
      "epoch: 17 batch: 36 train batch accuracy: 0.9375 loss: 0.12215165048837662\n",
      "epoch: 17 batch: 37 train batch accuracy: 0.921875 loss: 0.1890271008014679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 batch: 38 train batch accuracy: 0.9375 loss: 0.22011306881904602\n",
      "epoch: 17 batch: 39 train batch accuracy: 0.828125 loss: 0.5509326457977295\n",
      "epoch: 17 batch: 40 train batch accuracy: 0.875 loss: 0.4737092852592468\n",
      "epoch: 17 batch: 41 train batch accuracy: 0.875 loss: 0.3262169361114502\n",
      "epoch: 17 batch: 42 train batch accuracy: 0.9375 loss: 0.1449447125196457\n",
      "epoch: 17 batch: 43 train batch accuracy: 0.90625 loss: 0.41324907541275024\n",
      "epoch: 17 batch: 44 train batch accuracy: 0.9375 loss: 0.1411159783601761\n",
      "epoch: 17 batch: 45 train batch accuracy: 0.875 loss: 0.3061140179634094\n",
      "epoch: 17 batch: 46 train batch accuracy: 0.90625 loss: 0.2805890440940857\n",
      "epoch: 17 batch: 47 train batch accuracy: 0.890625 loss: 0.3647463321685791\n",
      "epoch: 17 batch: 48 train batch accuracy: 0.890625 loss: 0.3292909860610962\n",
      "epoch: 17 batch: 49 train batch accuracy: 0.890625 loss: 0.29342013597488403\n",
      "epoch: 17 batch: 50 train batch accuracy: 0.953125 loss: 0.2297920286655426\n",
      "epoch: 17 batch: 51 train batch accuracy: 0.84375 loss: 0.4738956391811371\n",
      "epoch: 17 batch: 52 train batch accuracy: 0.90625 loss: 0.32082945108413696\n",
      "epoch: 17 batch: 53 train batch accuracy: 0.890625 loss: 0.29384589195251465\n",
      "epoch: 17 batch: 54 train batch accuracy: 0.890625 loss: 0.22666776180267334\n",
      "epoch: 17 batch: 55 train batch accuracy: 0.828125 loss: 0.4724649488925934\n",
      "epoch: 17 batch: 56 train batch accuracy: 0.90625 loss: 0.19747094810009003\n",
      "epoch: 17 batch: 57 train batch accuracy: 0.9375 loss: 0.25035014748573303\n",
      "epoch: 17 batch: 58 train batch accuracy: 0.859375 loss: 0.47281932830810547\n",
      "epoch: 17 batch: 59 train batch accuracy: 0.875 loss: 0.3536219596862793\n",
      "epoch: 17 batch: 60 train batch accuracy: 0.890625 loss: 0.3140978217124939\n",
      "epoch: 17 batch: 61 train batch accuracy: 0.90625 loss: 0.3115374445915222\n",
      "epoch: 17 batch: 62 train batch accuracy: 0.84375 loss: 0.4108315110206604\n",
      "epoch: 17 batch: 63 train batch accuracy: 0.875 loss: 0.357855886220932\n",
      "epoch: 17 batch: 64 train batch accuracy: 0.90625 loss: 0.27993330359458923\n",
      "epoch: 17 batch: 65 train batch accuracy: 0.84375 loss: 0.4940635859966278\n",
      "epoch: 17 batch: 66 train batch accuracy: 0.859375 loss: 0.4646947979927063\n",
      "epoch: 17 batch: 67 train batch accuracy: 0.859375 loss: 0.42585569620132446\n",
      "epoch: 17 batch: 68 train batch accuracy: 0.8125 loss: 0.5210352540016174\n",
      "epoch: 17 batch: 69 train batch accuracy: 0.90625 loss: 0.3285619020462036\n",
      "epoch: 17 batch: 70 train batch accuracy: 0.875 loss: 0.3917170464992523\n",
      "epoch: 17 batch: 71 train batch accuracy: 0.84375 loss: 0.5303239822387695\n",
      "epoch: 17 batch: 72 train batch accuracy: 0.859375 loss: 0.509720504283905\n",
      "epoch: 17 batch: 73 train batch accuracy: 0.90625 loss: 0.30384886264801025\n",
      "epoch: 17 batch: 74 train batch accuracy: 0.859375 loss: 0.45047521591186523\n",
      "epoch: 17 batch: 75 train batch accuracy: 0.875 loss: 0.45501241087913513\n",
      "epoch: 17 batch: 76 train batch accuracy: 0.875 loss: 0.40590745210647583\n",
      "epoch: 17 batch: 77 train batch accuracy: 0.84375 loss: 0.47451189160346985\n",
      "epoch: 17 batch: 78 train batch accuracy: 0.875 loss: 0.41928631067276\n",
      "epoch: 17 batch: 79 train batch accuracy: 0.890625 loss: 0.24266871809959412\n",
      "epoch: 17 batch: 80 train batch accuracy: 0.8125 loss: 0.5729391574859619\n",
      "epoch: 17 batch: 81 train batch accuracy: 0.890625 loss: 0.33383333683013916\n",
      "epoch: 17 batch: 82 train batch accuracy: 0.890625 loss: 0.39877843856811523\n",
      "epoch: 17 batch: 83 train batch accuracy: 0.8125 loss: 0.5448442697525024\n",
      "epoch: 17 batch: 84 train batch accuracy: 0.890625 loss: 0.31355804204940796\n",
      "epoch: 17 batch: 85 train batch accuracy: 0.890625 loss: 0.30520352721214294\n",
      "epoch: 17 batch: 86 train batch accuracy: 0.8125 loss: 0.5427066087722778\n",
      "epoch: 17 batch: 87 train batch accuracy: 0.859375 loss: 0.5951799154281616\n",
      "epoch: 17 batch: 88 train batch accuracy: 0.859375 loss: 0.4598952829837799\n",
      "epoch: 17 batch: 89 train batch accuracy: 0.859375 loss: 0.33253639936447144\n",
      "epoch: 17 batch: 90 train batch accuracy: 0.9375 loss: 0.2715846002101898\n",
      "epoch: 17 batch: 91 train batch accuracy: 0.890625 loss: 0.30715692043304443\n",
      "epoch: 17 batch: 92 train batch accuracy: 0.875 loss: 0.4377990961074829\n",
      "epoch: 17 batch: 93 train batch accuracy: 0.984375 loss: 0.17446380853652954\n",
      "Epoch 18/1000  average cost 0.350949129\n",
      "Epoch 18/1000  Test cost 1.849395990\n",
      "准确率: 0.625\n",
      "Epoch 18/1000  模型保存成功\n",
      "epoch: 18 batch: 0 train batch accuracy: 0.859375 loss: 0.29260915517807007\n",
      "epoch: 18 batch: 1 train batch accuracy: 0.9375 loss: 0.253665030002594\n",
      "epoch: 18 batch: 2 train batch accuracy: 0.890625 loss: 0.38807129859924316\n",
      "epoch: 18 batch: 3 train batch accuracy: 0.84375 loss: 0.3971756100654602\n",
      "epoch: 18 batch: 4 train batch accuracy: 0.84375 loss: 0.43585190176963806\n",
      "epoch: 18 batch: 5 train batch accuracy: 0.90625 loss: 0.4659339487552643\n",
      "epoch: 18 batch: 6 train batch accuracy: 0.875 loss: 0.3952379524707794\n",
      "epoch: 18 batch: 7 train batch accuracy: 0.921875 loss: 0.216707244515419\n",
      "epoch: 18 batch: 8 train batch accuracy: 0.875 loss: 0.46497684717178345\n",
      "epoch: 18 batch: 9 train batch accuracy: 0.875 loss: 0.28865718841552734\n",
      "epoch: 18 batch: 10 train batch accuracy: 0.890625 loss: 0.43219098448753357\n",
      "epoch: 18 batch: 11 train batch accuracy: 0.84375 loss: 0.6093292236328125\n",
      "epoch: 18 batch: 12 train batch accuracy: 0.90625 loss: 0.42370814085006714\n",
      "epoch: 18 batch: 13 train batch accuracy: 0.921875 loss: 0.33076128363609314\n",
      "epoch: 18 batch: 14 train batch accuracy: 0.890625 loss: 0.42153400182724\n",
      "epoch: 18 batch: 15 train batch accuracy: 0.890625 loss: 0.6264820694923401\n",
      "epoch: 18 batch: 16 train batch accuracy: 0.90625 loss: 0.3836863934993744\n",
      "epoch: 18 batch: 17 train batch accuracy: 0.921875 loss: 0.3369385898113251\n",
      "epoch: 18 batch: 18 train batch accuracy: 0.859375 loss: 0.40746572613716125\n",
      "epoch: 18 batch: 19 train batch accuracy: 0.796875 loss: 0.4393872618675232\n",
      "epoch: 18 batch: 20 train batch accuracy: 0.90625 loss: 0.3444027900695801\n",
      "epoch: 18 batch: 21 train batch accuracy: 0.90625 loss: 0.40620118379592896\n",
      "epoch: 18 batch: 22 train batch accuracy: 0.84375 loss: 0.4770483076572418\n",
      "epoch: 18 batch: 23 train batch accuracy: 0.921875 loss: 0.37819522619247437\n",
      "epoch: 18 batch: 24 train batch accuracy: 0.875 loss: 0.36128494143486023\n",
      "epoch: 18 batch: 25 train batch accuracy: 0.859375 loss: 0.34748607873916626\n",
      "epoch: 18 batch: 26 train batch accuracy: 0.859375 loss: 0.3736358880996704\n",
      "epoch: 18 batch: 27 train batch accuracy: 0.953125 loss: 0.20690356194972992\n",
      "epoch: 18 batch: 28 train batch accuracy: 0.875 loss: 0.6616623997688293\n",
      "epoch: 18 batch: 29 train batch accuracy: 0.8125 loss: 0.7432444095611572\n",
      "epoch: 18 batch: 30 train batch accuracy: 0.90625 loss: 0.23315264284610748\n",
      "epoch: 18 batch: 31 train batch accuracy: 0.859375 loss: 0.32815057039260864\n",
      "epoch: 18 batch: 32 train batch accuracy: 0.890625 loss: 0.33960962295532227\n",
      "epoch: 18 batch: 33 train batch accuracy: 0.96875 loss: 0.17569902539253235\n",
      "epoch: 18 batch: 34 train batch accuracy: 0.90625 loss: 0.24146807193756104\n",
      "epoch: 18 batch: 35 train batch accuracy: 0.96875 loss: 0.1414770781993866\n",
      "epoch: 18 batch: 36 train batch accuracy: 0.765625 loss: 0.5863206386566162\n",
      "epoch: 18 batch: 37 train batch accuracy: 0.9375 loss: 0.35696864128112793\n",
      "epoch: 18 batch: 38 train batch accuracy: 0.90625 loss: 0.2467775195837021\n",
      "epoch: 18 batch: 39 train batch accuracy: 0.953125 loss: 0.25948309898376465\n",
      "epoch: 18 batch: 40 train batch accuracy: 0.875 loss: 0.35112348198890686\n",
      "epoch: 18 batch: 41 train batch accuracy: 0.859375 loss: 0.5926460027694702\n",
      "epoch: 18 batch: 42 train batch accuracy: 0.921875 loss: 0.2359965592622757\n",
      "epoch: 18 batch: 43 train batch accuracy: 0.890625 loss: 0.4279325008392334\n",
      "epoch: 18 batch: 44 train batch accuracy: 0.953125 loss: 0.21277765929698944\n",
      "epoch: 18 batch: 45 train batch accuracy: 0.90625 loss: 0.36059850454330444\n",
      "epoch: 18 batch: 46 train batch accuracy: 0.921875 loss: 0.2038123458623886\n",
      "epoch: 18 batch: 47 train batch accuracy: 0.890625 loss: 0.3757208585739136\n",
      "epoch: 18 batch: 48 train batch accuracy: 0.953125 loss: 0.17388030886650085\n",
      "epoch: 18 batch: 49 train batch accuracy: 0.921875 loss: 0.27054035663604736\n",
      "epoch: 18 batch: 50 train batch accuracy: 0.859375 loss: 0.3051784336566925\n",
      "epoch: 18 batch: 51 train batch accuracy: 0.890625 loss: 0.3207891881465912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 batch: 52 train batch accuracy: 0.90625 loss: 0.3631214499473572\n",
      "epoch: 18 batch: 53 train batch accuracy: 0.921875 loss: 0.2246159315109253\n",
      "epoch: 18 batch: 54 train batch accuracy: 0.953125 loss: 0.26360368728637695\n",
      "epoch: 18 batch: 55 train batch accuracy: 0.921875 loss: 0.3040531873703003\n",
      "epoch: 18 batch: 56 train batch accuracy: 0.9375 loss: 0.21070387959480286\n",
      "epoch: 18 batch: 57 train batch accuracy: 0.921875 loss: 0.3034963011741638\n",
      "epoch: 18 batch: 58 train batch accuracy: 0.953125 loss: 0.24590972065925598\n",
      "epoch: 18 batch: 59 train batch accuracy: 0.84375 loss: 0.6230030655860901\n",
      "epoch: 18 batch: 60 train batch accuracy: 0.890625 loss: 0.36760279536247253\n",
      "epoch: 18 batch: 61 train batch accuracy: 0.90625 loss: 0.26192182302474976\n",
      "epoch: 18 batch: 62 train batch accuracy: 0.921875 loss: 0.1883954405784607\n",
      "epoch: 18 batch: 63 train batch accuracy: 0.953125 loss: 0.22242942452430725\n",
      "epoch: 18 batch: 64 train batch accuracy: 0.890625 loss: 0.24600878357887268\n",
      "epoch: 18 batch: 65 train batch accuracy: 0.8125 loss: 0.6490226984024048\n",
      "epoch: 18 batch: 66 train batch accuracy: 0.890625 loss: 0.2440893054008484\n",
      "epoch: 18 batch: 67 train batch accuracy: 0.953125 loss: 0.2344120740890503\n",
      "epoch: 18 batch: 68 train batch accuracy: 0.921875 loss: 0.2606673836708069\n",
      "epoch: 18 batch: 69 train batch accuracy: 0.9375 loss: 0.1874796748161316\n",
      "epoch: 18 batch: 70 train batch accuracy: 0.90625 loss: 0.3439699709415436\n",
      "epoch: 18 batch: 71 train batch accuracy: 0.859375 loss: 0.3746209144592285\n",
      "epoch: 18 batch: 72 train batch accuracy: 0.921875 loss: 0.2791680693626404\n",
      "epoch: 18 batch: 73 train batch accuracy: 0.859375 loss: 0.40854597091674805\n",
      "epoch: 18 batch: 74 train batch accuracy: 0.90625 loss: 0.3825126886367798\n",
      "epoch: 18 batch: 75 train batch accuracy: 0.90625 loss: 0.359014630317688\n",
      "epoch: 18 batch: 76 train batch accuracy: 0.953125 loss: 0.1907917857170105\n",
      "epoch: 18 batch: 77 train batch accuracy: 0.9375 loss: 0.24924308061599731\n",
      "epoch: 18 batch: 78 train batch accuracy: 0.90625 loss: 0.25019776821136475\n",
      "epoch: 18 batch: 79 train batch accuracy: 0.921875 loss: 0.32995861768722534\n",
      "epoch: 18 batch: 80 train batch accuracy: 0.9375 loss: 0.2325371354818344\n",
      "epoch: 18 batch: 81 train batch accuracy: 0.921875 loss: 0.24680620431900024\n",
      "epoch: 18 batch: 82 train batch accuracy: 0.859375 loss: 0.4790910482406616\n",
      "epoch: 18 batch: 83 train batch accuracy: 0.859375 loss: 0.3940509855747223\n",
      "epoch: 18 batch: 84 train batch accuracy: 0.90625 loss: 0.2853977084159851\n",
      "epoch: 18 batch: 85 train batch accuracy: 0.84375 loss: 0.4009867310523987\n",
      "epoch: 18 batch: 86 train batch accuracy: 0.921875 loss: 0.2887610197067261\n",
      "epoch: 18 batch: 87 train batch accuracy: 0.875 loss: 0.34510108828544617\n",
      "epoch: 18 batch: 88 train batch accuracy: 0.90625 loss: 0.292278528213501\n",
      "epoch: 18 batch: 89 train batch accuracy: 0.90625 loss: 0.374126136302948\n",
      "epoch: 18 batch: 90 train batch accuracy: 0.796875 loss: 0.5836789608001709\n",
      "epoch: 18 batch: 91 train batch accuracy: 0.90625 loss: 0.36755040287971497\n",
      "epoch: 18 batch: 92 train batch accuracy: 0.921875 loss: 0.2863418757915497\n",
      "epoch: 18 batch: 93 train batch accuracy: 0.875 loss: 0.2565351724624634\n",
      "Epoch 19/1000  average cost 0.345237669\n",
      "Epoch 19/1000  Test cost 1.990280867\n",
      "准确率: 0.546875\n",
      "Epoch 19/1000  模型保存成功\n",
      "epoch: 19 batch: 0 train batch accuracy: 0.828125 loss: 0.6355977058410645\n",
      "epoch: 19 batch: 1 train batch accuracy: 0.90625 loss: 0.36940306425094604\n",
      "epoch: 19 batch: 2 train batch accuracy: 0.84375 loss: 0.5368701219558716\n",
      "epoch: 19 batch: 3 train batch accuracy: 0.875 loss: 0.41266581416130066\n",
      "epoch: 19 batch: 4 train batch accuracy: 0.890625 loss: 0.3192785680294037\n",
      "epoch: 19 batch: 5 train batch accuracy: 0.90625 loss: 0.3701099157333374\n",
      "epoch: 19 batch: 6 train batch accuracy: 0.921875 loss: 0.23797544836997986\n",
      "epoch: 19 batch: 7 train batch accuracy: 0.84375 loss: 0.4920252561569214\n",
      "epoch: 19 batch: 8 train batch accuracy: 0.859375 loss: 0.3544803261756897\n",
      "epoch: 19 batch: 9 train batch accuracy: 0.96875 loss: 0.1761297583580017\n",
      "epoch: 19 batch: 10 train batch accuracy: 0.875 loss: 0.24612967669963837\n",
      "epoch: 19 batch: 11 train batch accuracy: 0.828125 loss: 0.4188702404499054\n",
      "epoch: 19 batch: 12 train batch accuracy: 0.921875 loss: 0.19528266787528992\n",
      "epoch: 19 batch: 13 train batch accuracy: 0.90625 loss: 0.2198435664176941\n",
      "epoch: 19 batch: 14 train batch accuracy: 0.9375 loss: 0.27539271116256714\n",
      "epoch: 19 batch: 15 train batch accuracy: 0.859375 loss: 0.4383179247379303\n",
      "epoch: 19 batch: 16 train batch accuracy: 0.890625 loss: 0.3545205295085907\n",
      "epoch: 19 batch: 17 train batch accuracy: 0.9375 loss: 0.30997800827026367\n",
      "epoch: 19 batch: 18 train batch accuracy: 0.875 loss: 0.47171226143836975\n",
      "epoch: 19 batch: 19 train batch accuracy: 0.84375 loss: 0.3935035169124603\n",
      "epoch: 19 batch: 20 train batch accuracy: 0.890625 loss: 0.2921281158924103\n",
      "epoch: 19 batch: 21 train batch accuracy: 0.921875 loss: 0.252364844083786\n",
      "epoch: 19 batch: 22 train batch accuracy: 0.875 loss: 0.23804356157779694\n",
      "epoch: 19 batch: 23 train batch accuracy: 0.890625 loss: 0.25890833139419556\n",
      "epoch: 19 batch: 24 train batch accuracy: 0.890625 loss: 0.27509865164756775\n",
      "epoch: 19 batch: 25 train batch accuracy: 0.90625 loss: 0.2912486791610718\n",
      "epoch: 19 batch: 26 train batch accuracy: 0.859375 loss: 0.4221786856651306\n",
      "epoch: 19 batch: 27 train batch accuracy: 0.859375 loss: 0.47968554496765137\n",
      "epoch: 19 batch: 28 train batch accuracy: 0.890625 loss: 0.3539091944694519\n",
      "epoch: 19 batch: 29 train batch accuracy: 0.890625 loss: 0.3379242420196533\n",
      "epoch: 19 batch: 30 train batch accuracy: 0.875 loss: 0.4134231209754944\n",
      "epoch: 19 batch: 31 train batch accuracy: 0.921875 loss: 0.2769433856010437\n",
      "epoch: 19 batch: 32 train batch accuracy: 0.875 loss: 0.3381304144859314\n",
      "epoch: 19 batch: 33 train batch accuracy: 0.90625 loss: 0.2846967577934265\n",
      "epoch: 19 batch: 34 train batch accuracy: 0.921875 loss: 0.3116329610347748\n",
      "epoch: 19 batch: 35 train batch accuracy: 0.875 loss: 0.4149700999259949\n",
      "epoch: 19 batch: 36 train batch accuracy: 0.90625 loss: 0.2315472960472107\n",
      "epoch: 19 batch: 37 train batch accuracy: 0.9375 loss: 0.2521933317184448\n",
      "epoch: 19 batch: 38 train batch accuracy: 0.84375 loss: 0.38716891407966614\n",
      "epoch: 19 batch: 39 train batch accuracy: 0.921875 loss: 0.26750436425209045\n",
      "epoch: 19 batch: 40 train batch accuracy: 0.953125 loss: 0.2179301381111145\n",
      "epoch: 19 batch: 41 train batch accuracy: 0.875 loss: 0.38496121764183044\n",
      "epoch: 19 batch: 42 train batch accuracy: 0.84375 loss: 0.46795403957366943\n",
      "epoch: 19 batch: 43 train batch accuracy: 0.921875 loss: 0.25920021533966064\n",
      "epoch: 19 batch: 44 train batch accuracy: 0.890625 loss: 0.33539682626724243\n",
      "epoch: 19 batch: 45 train batch accuracy: 0.953125 loss: 0.19489985704421997\n",
      "epoch: 19 batch: 46 train batch accuracy: 0.875 loss: 0.3606022298336029\n",
      "epoch: 19 batch: 47 train batch accuracy: 0.90625 loss: 0.29326876997947693\n",
      "epoch: 19 batch: 48 train batch accuracy: 0.890625 loss: 0.49966177344322205\n",
      "epoch: 19 batch: 49 train batch accuracy: 0.921875 loss: 0.34332793951034546\n",
      "epoch: 19 batch: 50 train batch accuracy: 0.9375 loss: 0.191036194562912\n",
      "epoch: 19 batch: 51 train batch accuracy: 0.875 loss: 0.34367430210113525\n",
      "epoch: 19 batch: 52 train batch accuracy: 0.859375 loss: 0.3397340178489685\n",
      "epoch: 19 batch: 53 train batch accuracy: 0.859375 loss: 0.33148816227912903\n",
      "epoch: 19 batch: 54 train batch accuracy: 0.90625 loss: 0.3096391558647156\n",
      "epoch: 19 batch: 55 train batch accuracy: 0.890625 loss: 0.3012102544307709\n",
      "epoch: 19 batch: 56 train batch accuracy: 0.921875 loss: 0.29034867882728577\n",
      "epoch: 19 batch: 57 train batch accuracy: 0.859375 loss: 0.39834660291671753\n",
      "epoch: 19 batch: 58 train batch accuracy: 0.828125 loss: 0.6253235936164856\n",
      "epoch: 19 batch: 59 train batch accuracy: 0.890625 loss: 0.3061041831970215\n",
      "epoch: 19 batch: 60 train batch accuracy: 0.9375 loss: 0.2854682207107544\n",
      "epoch: 19 batch: 61 train batch accuracy: 0.90625 loss: 0.3665386438369751\n",
      "epoch: 19 batch: 62 train batch accuracy: 0.96875 loss: 0.21232560276985168\n",
      "epoch: 19 batch: 63 train batch accuracy: 0.859375 loss: 0.4581805467605591\n",
      "epoch: 19 batch: 64 train batch accuracy: 0.90625 loss: 0.31949347257614136\n",
      "epoch: 19 batch: 65 train batch accuracy: 0.90625 loss: 0.19887825846672058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 batch: 66 train batch accuracy: 0.875 loss: 0.40202945470809937\n",
      "epoch: 19 batch: 67 train batch accuracy: 0.90625 loss: 0.34166252613067627\n",
      "epoch: 19 batch: 68 train batch accuracy: 0.9375 loss: 0.1798204928636551\n",
      "epoch: 19 batch: 69 train batch accuracy: 0.921875 loss: 0.19530189037322998\n",
      "epoch: 19 batch: 70 train batch accuracy: 0.859375 loss: 0.3420848250389099\n",
      "epoch: 19 batch: 71 train batch accuracy: 0.953125 loss: 0.17470404505729675\n",
      "epoch: 19 batch: 72 train batch accuracy: 0.9375 loss: 0.2231922149658203\n",
      "epoch: 19 batch: 73 train batch accuracy: 0.90625 loss: 0.4045405089855194\n",
      "epoch: 19 batch: 74 train batch accuracy: 0.953125 loss: 0.18714967370033264\n",
      "epoch: 19 batch: 75 train batch accuracy: 0.90625 loss: 0.31080037355422974\n",
      "epoch: 19 batch: 76 train batch accuracy: 0.921875 loss: 0.274804025888443\n",
      "epoch: 19 batch: 77 train batch accuracy: 0.875 loss: 0.3208746314048767\n",
      "epoch: 19 batch: 78 train batch accuracy: 0.9375 loss: 0.15432360768318176\n",
      "epoch: 19 batch: 79 train batch accuracy: 0.9375 loss: 0.20344164967536926\n",
      "epoch: 19 batch: 80 train batch accuracy: 0.875 loss: 0.3103773593902588\n",
      "epoch: 19 batch: 81 train batch accuracy: 0.96875 loss: 0.23839041590690613\n",
      "epoch: 19 batch: 82 train batch accuracy: 0.84375 loss: 0.3144788146018982\n",
      "epoch: 19 batch: 83 train batch accuracy: 0.90625 loss: 0.23421436548233032\n",
      "epoch: 19 batch: 84 train batch accuracy: 0.9375 loss: 0.1682816743850708\n",
      "epoch: 19 batch: 85 train batch accuracy: 0.875 loss: 0.2811950147151947\n",
      "epoch: 19 batch: 86 train batch accuracy: 0.875 loss: 0.47767776250839233\n",
      "epoch: 19 batch: 87 train batch accuracy: 0.9375 loss: 0.2554316818714142\n",
      "epoch: 19 batch: 88 train batch accuracy: 0.953125 loss: 0.1571274995803833\n",
      "epoch: 19 batch: 89 train batch accuracy: 0.875 loss: 0.3450639545917511\n",
      "epoch: 19 batch: 90 train batch accuracy: 0.953125 loss: 0.16114260256290436\n",
      "epoch: 19 batch: 91 train batch accuracy: 0.90625 loss: 0.30417948961257935\n",
      "epoch: 19 batch: 92 train batch accuracy: 0.875 loss: 0.3220536708831787\n",
      "epoch: 19 batch: 93 train batch accuracy: 0.9375 loss: 0.21589550375938416\n",
      "Epoch 20/1000  average cost 0.316415109\n",
      "Epoch 20/1000  Test cost 1.647852898\n",
      "准确率: 0.625\n",
      "Epoch 20/1000  模型保存成功\n",
      "epoch: 20 batch: 0 train batch accuracy: 0.921875 loss: 0.20480674505233765\n",
      "epoch: 20 batch: 1 train batch accuracy: 0.9375 loss: 0.2765033543109894\n",
      "epoch: 20 batch: 2 train batch accuracy: 0.84375 loss: 0.5919882655143738\n",
      "epoch: 20 batch: 3 train batch accuracy: 0.90625 loss: 0.4387437701225281\n",
      "epoch: 20 batch: 4 train batch accuracy: 0.9375 loss: 0.20308023691177368\n",
      "epoch: 20 batch: 5 train batch accuracy: 0.9375 loss: 0.2391861379146576\n",
      "epoch: 20 batch: 6 train batch accuracy: 0.890625 loss: 0.2075648158788681\n",
      "epoch: 20 batch: 7 train batch accuracy: 0.9375 loss: 0.24932658672332764\n",
      "epoch: 20 batch: 8 train batch accuracy: 0.9375 loss: 0.29779452085494995\n",
      "epoch: 20 batch: 9 train batch accuracy: 0.953125 loss: 0.18848711252212524\n",
      "epoch: 20 batch: 10 train batch accuracy: 0.90625 loss: 0.2526242733001709\n",
      "epoch: 20 batch: 11 train batch accuracy: 0.96875 loss: 0.18414005637168884\n",
      "epoch: 20 batch: 12 train batch accuracy: 0.90625 loss: 0.27808690071105957\n",
      "epoch: 20 batch: 13 train batch accuracy: 0.875 loss: 0.35981491208076477\n",
      "epoch: 20 batch: 14 train batch accuracy: 0.96875 loss: 0.1699470579624176\n",
      "epoch: 20 batch: 15 train batch accuracy: 0.953125 loss: 0.2098623812198639\n",
      "epoch: 20 batch: 16 train batch accuracy: 0.875 loss: 0.4122311472892761\n",
      "epoch: 20 batch: 17 train batch accuracy: 0.96875 loss: 0.16054174304008484\n",
      "epoch: 20 batch: 18 train batch accuracy: 0.953125 loss: 0.16515277326107025\n",
      "epoch: 20 batch: 19 train batch accuracy: 0.90625 loss: 0.3923566937446594\n",
      "epoch: 20 batch: 20 train batch accuracy: 0.96875 loss: 0.1362820267677307\n",
      "epoch: 20 batch: 21 train batch accuracy: 0.828125 loss: 0.3504734933376312\n",
      "epoch: 20 batch: 22 train batch accuracy: 0.921875 loss: 0.2887285649776459\n",
      "epoch: 20 batch: 23 train batch accuracy: 0.921875 loss: 0.24487940967082977\n",
      "epoch: 20 batch: 24 train batch accuracy: 0.90625 loss: 0.29794350266456604\n",
      "epoch: 20 batch: 25 train batch accuracy: 0.9375 loss: 0.21016936004161835\n",
      "epoch: 20 batch: 26 train batch accuracy: 0.953125 loss: 0.14065727591514587\n",
      "epoch: 20 batch: 27 train batch accuracy: 0.84375 loss: 0.4406997859477997\n",
      "epoch: 20 batch: 28 train batch accuracy: 0.90625 loss: 0.289883017539978\n",
      "epoch: 20 batch: 29 train batch accuracy: 0.859375 loss: 0.31551313400268555\n",
      "epoch: 20 batch: 30 train batch accuracy: 0.890625 loss: 0.3541465997695923\n",
      "epoch: 20 batch: 31 train batch accuracy: 0.890625 loss: 0.31707999110221863\n",
      "epoch: 20 batch: 32 train batch accuracy: 0.890625 loss: 0.3893001079559326\n",
      "epoch: 20 batch: 33 train batch accuracy: 0.890625 loss: 0.42597460746765137\n",
      "epoch: 20 batch: 34 train batch accuracy: 0.84375 loss: 0.3756978213787079\n",
      "epoch: 20 batch: 35 train batch accuracy: 0.90625 loss: 0.27872931957244873\n",
      "epoch: 20 batch: 36 train batch accuracy: 0.875 loss: 0.3490132689476013\n",
      "epoch: 20 batch: 37 train batch accuracy: 0.90625 loss: 0.28024595975875854\n",
      "epoch: 20 batch: 38 train batch accuracy: 0.9375 loss: 0.20052868127822876\n",
      "epoch: 20 batch: 39 train batch accuracy: 0.828125 loss: 0.5224788784980774\n",
      "epoch: 20 batch: 40 train batch accuracy: 0.921875 loss: 0.23961731791496277\n",
      "epoch: 20 batch: 41 train batch accuracy: 0.90625 loss: 0.283759206533432\n",
      "epoch: 20 batch: 42 train batch accuracy: 0.921875 loss: 0.2836378216743469\n",
      "epoch: 20 batch: 43 train batch accuracy: 0.953125 loss: 0.299923300743103\n",
      "epoch: 20 batch: 44 train batch accuracy: 0.9375 loss: 0.20429804921150208\n",
      "epoch: 20 batch: 45 train batch accuracy: 0.953125 loss: 0.30743372440338135\n",
      "epoch: 20 batch: 46 train batch accuracy: 0.9375 loss: 0.22508543729782104\n",
      "epoch: 20 batch: 47 train batch accuracy: 0.9375 loss: 0.16242876648902893\n",
      "epoch: 20 batch: 48 train batch accuracy: 0.84375 loss: 0.40722987055778503\n",
      "epoch: 20 batch: 49 train batch accuracy: 0.953125 loss: 0.255420446395874\n",
      "epoch: 20 batch: 50 train batch accuracy: 0.890625 loss: 0.2623322010040283\n",
      "epoch: 20 batch: 51 train batch accuracy: 0.90625 loss: 0.2998582720756531\n",
      "epoch: 20 batch: 52 train batch accuracy: 0.9375 loss: 0.13686183094978333\n",
      "epoch: 20 batch: 53 train batch accuracy: 0.890625 loss: 0.36566591262817383\n",
      "epoch: 20 batch: 54 train batch accuracy: 0.984375 loss: 0.09354998171329498\n",
      "epoch: 20 batch: 55 train batch accuracy: 0.921875 loss: 0.2328857034444809\n",
      "epoch: 20 batch: 56 train batch accuracy: 0.921875 loss: 0.2982688546180725\n",
      "epoch: 20 batch: 57 train batch accuracy: 0.90625 loss: 0.30893194675445557\n",
      "epoch: 20 batch: 58 train batch accuracy: 0.859375 loss: 0.4830106496810913\n",
      "epoch: 20 batch: 59 train batch accuracy: 0.90625 loss: 0.29855382442474365\n",
      "epoch: 20 batch: 60 train batch accuracy: 0.9375 loss: 0.24914853274822235\n",
      "epoch: 20 batch: 61 train batch accuracy: 0.953125 loss: 0.1880699247121811\n",
      "epoch: 20 batch: 62 train batch accuracy: 0.9375 loss: 0.1543143391609192\n",
      "epoch: 20 batch: 63 train batch accuracy: 0.9375 loss: 0.3107495605945587\n",
      "epoch: 20 batch: 64 train batch accuracy: 0.9375 loss: 0.19120050966739655\n",
      "epoch: 20 batch: 65 train batch accuracy: 0.9375 loss: 0.20325878262519836\n",
      "epoch: 20 batch: 66 train batch accuracy: 0.953125 loss: 0.22145721316337585\n",
      "epoch: 20 batch: 67 train batch accuracy: 0.96875 loss: 0.14026418328285217\n",
      "epoch: 20 batch: 68 train batch accuracy: 0.953125 loss: 0.1309678852558136\n",
      "epoch: 20 batch: 69 train batch accuracy: 0.96875 loss: 0.08592857420444489\n",
      "epoch: 20 batch: 70 train batch accuracy: 0.9375 loss: 0.17975524067878723\n",
      "epoch: 20 batch: 71 train batch accuracy: 0.859375 loss: 0.27537116408348083\n",
      "epoch: 20 batch: 72 train batch accuracy: 0.9375 loss: 0.22528834640979767\n",
      "epoch: 20 batch: 73 train batch accuracy: 0.9375 loss: 0.2139904499053955\n",
      "epoch: 20 batch: 74 train batch accuracy: 0.890625 loss: 0.3027742803096771\n",
      "epoch: 20 batch: 75 train batch accuracy: 0.90625 loss: 0.2218703031539917\n",
      "epoch: 20 batch: 76 train batch accuracy: 0.9375 loss: 0.2015828788280487\n",
      "epoch: 20 batch: 77 train batch accuracy: 0.921875 loss: 0.36693814396858215\n",
      "epoch: 20 batch: 78 train batch accuracy: 0.859375 loss: 0.42684853076934814\n",
      "epoch: 20 batch: 79 train batch accuracy: 0.9375 loss: 0.1884274184703827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 batch: 80 train batch accuracy: 0.90625 loss: 0.24234530329704285\n",
      "epoch: 20 batch: 81 train batch accuracy: 0.96875 loss: 0.15579254925251007\n",
      "epoch: 20 batch: 82 train batch accuracy: 0.90625 loss: 0.25911861658096313\n",
      "epoch: 20 batch: 83 train batch accuracy: 0.90625 loss: 0.3182986378669739\n",
      "epoch: 20 batch: 84 train batch accuracy: 0.890625 loss: 0.35189586877822876\n",
      "epoch: 20 batch: 85 train batch accuracy: 0.953125 loss: 0.1716003715991974\n",
      "epoch: 20 batch: 86 train batch accuracy: 0.859375 loss: 0.45583826303482056\n",
      "epoch: 20 batch: 87 train batch accuracy: 0.9375 loss: 0.18900850415229797\n",
      "epoch: 20 batch: 88 train batch accuracy: 0.859375 loss: 0.5286474823951721\n",
      "epoch: 20 batch: 89 train batch accuracy: 0.9375 loss: 0.16382841765880585\n",
      "epoch: 20 batch: 90 train batch accuracy: 0.921875 loss: 0.2888340950012207\n",
      "epoch: 20 batch: 91 train batch accuracy: 0.953125 loss: 0.21941149234771729\n",
      "epoch: 20 batch: 92 train batch accuracy: 0.984375 loss: 0.09324516355991364\n",
      "epoch: 20 batch: 93 train batch accuracy: 0.953125 loss: 0.1984633505344391\n",
      "Epoch 21/1000  average cost 0.268659062\n",
      "Epoch 21/1000  Test cost 2.583993196\n",
      "准确率: 0.5\n",
      "Epoch 21/1000  模型保存成功\n",
      "epoch: 21 batch: 0 train batch accuracy: 0.9375 loss: 0.13760298490524292\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-afc90f64aeb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_gen_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfull_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimage_holder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_holder\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[0mtotal_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch: {} batch: {} train batch accuracy: {} loss: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_epochs = 1000\n",
    "\n",
    "learning_rate = 1e-4\n",
    "display_epoch = 1\n",
    "'''\n",
    "演示一个VGG16的例子 \n",
    "微调 这里只调整VGG16最后一层全连接层，把1000类改为5类 \n",
    "对网络进行训练   使用slim库简化代码\n",
    "'''    \n",
    "def loss(logits, labels):\n",
    "\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=labels, name='cross_entropy_per_example')\n",
    "\n",
    "    return tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "\n",
    "\n",
    "#用于保存微调后的检查点文件和日志文件路径\n",
    "train_log_dir = './vgg_16_2016_08_28/slim_fine_tune'\n",
    "train_log_file = 'birds_fine_tune.ckpt'\n",
    "\n",
    "#官方下载的检查点文件路径\n",
    "checkpoint_file = './vgg_16_2016_08_28/vgg_16.ckpt'\n",
    "\n",
    "if not tf.gfile.Exists(train_log_dir):\n",
    "    tf.gfile.MakeDirs(train_log_dir)\n",
    "\n",
    "#创建一个图，作为当前图\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    #加载数据\n",
    "    image_holder = tf.placeholder(tf.float32, [None, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "    label_holder = tf.placeholder(tf.int32, [None,]) \n",
    "    is_training = tf.placeholder(dtype = tf.bool)\n",
    "\n",
    "\n",
    "    #创建vgg16网络  如果想冻结所有层，可以指定slim.conv2d中的 trainable=False\n",
    "    logits,end_points =  vgg.vgg_16(image_holder, is_training=is_training, num_classes = num_classes)  \n",
    "    print(logits.shape)\n",
    "\n",
    "    # 获取fc8初始化函数\n",
    "    fc8_variables = tf.contrib.framework.get_variables('vgg_16/fc8')\n",
    "    # Restore only the convolutional layers: 从检查点载入当前图除了fc8层之外所有变量的参数\n",
    "    params = slim.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "    #用于恢复模型  如果使用这个保存或者恢复的话，只会保存或者恢复指定的变量\n",
    "    restorer = tf.train.Saver(params) \n",
    "\n",
    "    #预测标签\n",
    "    pred = tf.cast(tf.argmax(logits,axis=1),tf.int32)\n",
    "\n",
    "    '''\n",
    "    定义代价函数和优化器\n",
    "    '''   \n",
    "\n",
    "    #代价函数\n",
    "    cost = loss(logits, label_holder)\n",
    "  \n",
    "    #设置优化器\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost,var_list=fc8_variables)\n",
    "    full_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    #预测结果评估        \n",
    "    correct = tf.equal(pred, label_holder)                    #返回一个数组 表示统计预测正确或者错误 \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))                #求准确率\n",
    "\n",
    "    num_batch = int(np.ceil(x_train.shape[0] / batch_size))\n",
    "\n",
    "    #用于保存检查点文件 \n",
    "    save = tf.train.Saver(max_to_keep=1) \n",
    "\n",
    "    #恢复模型\n",
    "    with tf.Session() as sess:      \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #检查最近的检查点文件\n",
    "        ckpt = tf.train.latest_checkpoint(train_log_dir)\n",
    "        if ckpt != None:\n",
    "            save.restore(sess,ckpt)\n",
    "            print('从上次训练保存后的模型继续训练！')\n",
    "        else:\n",
    "            restorer.restore(sess, checkpoint_file)                \n",
    "            print('从官方模型加载训练！')\n",
    "\n",
    "\n",
    "\n",
    "        print('开始训练！')\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            total_cost = 0.0                \n",
    "            for i in range(num_batch):\n",
    "                image_batch, label_batch = next(data_gen_train.flow(x_train, y_train, batch_size=batch_size))                                               \n",
    "                _,loss,acc = sess.run([full_optimizer,cost,accuracy],feed_dict={image_holder:image_batch,label_holder:label_batch,is_training:True})\n",
    "                total_cost += loss\n",
    "                print('epoch: {} batch: {} train batch accuracy: {} loss: {}'.format(epoch, i, acc, loss))\n",
    "                \n",
    "\n",
    "            #打印信息\n",
    "            if epoch % display_epoch == 0:\n",
    "                print('Epoch {}/{}  average cost {:.9f}'.format(epoch+1,training_epochs,total_cost/num_batch))\n",
    "\n",
    "            #进行预测处理\n",
    "            image_batch, label_batch = next(data_gen_test)                                                                 \n",
    "            cost_values,accuracy_value = sess.run([cost,accuracy],feed_dict = {image_holder:image_batch,label_holder:label_batch,is_training:False})\n",
    "            print('Epoch {}/{}  Test cost {:.9f}'.format(epoch+1,training_epochs,cost_values))\n",
    "            print('准确率:',accuracy_value)\n",
    "\n",
    "\n",
    "            #保存模型\n",
    "            save.save(sess,os.path.join(train_log_dir,train_log_file),global_step = epoch)\n",
    "            print('Epoch {}/{}  模型保存成功'.format(epoch+1,training_epochs))\n",
    "\n",
    "            \n",
    "        print('训练完成')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
